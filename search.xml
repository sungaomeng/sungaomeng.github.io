<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>使用Argocd进行持续部署</title>
      <link href="/argocd/install-argocd/"/>
      <url>/argocd/install-argocd/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argo-dashboard.png" alt="argo-dashboard"></p><blockquote><p>之前做过Gitlab的CI，但k8s上的CD一直没有做，所有上线均三方在线手工操作，目前计划增加CD功能</p><p>以下是整个Argo CD 的安装和测试记录</p><p>这里只验证了CD部分，CI由Gitlab实现后期会做结合</p></blockquote><h2 id="了解Argocd"><a href="#了解Argocd" class="headerlink" title="了解Argocd"></a>了解Argocd</h2><ul><li><p>Argo CD是一个基于Kubernetes的声明式的GitOps工具</p></li><li><p>大致逻辑为 kubernetes的Deployment/SVC等yaml文件存放于Git仓库中，研发更新Git仓库中的Image版本即可完成发布（Argocd会监听对比Git和Kubernetes中的Yaml，不一致将会推送覆盖）</p></li></ul><h2 id="安装Argocd"><a href="#安装Argocd" class="headerlink" title="安装Argocd"></a>安装Argocd</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul><li>kubernetes v1.20.4 集群</li><li>argocd latest (v2.6.1)</li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="官方安装方法"><a href="#官方安装方法" class="headerlink" title="官方安装方法:"></a>官方安装方法:</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create namespace argocd</span><br><span class="line">kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml</span><br></pre></td></tr></table></figure><h4 id="查看被安装的资源"><a href="#查看被安装的资源" class="headerlink" title="查看被安装的资源"></a>查看被安装的资源</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 system]<span class="comment"># kubectl -n argocd get all</span></span><br><span class="line">NAME                                                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/argocd-application-controller-0                     1/1     Running   0          41h</span><br><span class="line">pod/argocd-applicationset-controller-7b5f77c495-sqqkm   1/1     Running   0          41h</span><br><span class="line">pod/argocd-dex-server-58df896df-64c4d                   1/1     Running   0          41h</span><br><span class="line">pod/argocd-notifications-controller-5dcb877fd8-vnlqk    1/1     Running   0          42h</span><br><span class="line">pod/argocd-redis-58654b9b4b-xkdj5                       1/1     Running   0          41h</span><br><span class="line">pod/argocd-repo-server-7459b57cd-xfbgx                  1/1     Running   0          41h</span><br><span class="line">pod/argocd-server-67545b758b-d8js7                      1/1     Running   0          42h</span><br><span class="line"></span><br><span class="line">NAME                                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">service/argocd-applicationset-controller          ClusterIP   10.254.58.14    &lt;none&gt;        7000/TCP,8080/TCP            2d</span><br><span class="line">service/argocd-dex-server                         ClusterIP   10.254.59.220   &lt;none&gt;        5556/TCP,5557/TCP,5558/TCP   2d</span><br><span class="line">service/argocd-metrics                            ClusterIP   10.254.35.183   &lt;none&gt;        8082/TCP                     2d</span><br><span class="line">service/argocd-notifications-controller-metrics   ClusterIP   10.254.35.247   &lt;none&gt;        9001/TCP                     2d</span><br><span class="line">service/argocd-redis                              ClusterIP   10.254.35.102   &lt;none&gt;        6379/TCP                     2d</span><br><span class="line">service/argocd-repo-server                        ClusterIP   10.254.21.22    &lt;none&gt;        8081/TCP,8084/TCP            2d</span><br><span class="line">service/argocd-server                             ClusterIP   10.254.27.164   &lt;none&gt;        80/TCP,443/TCP               2d</span><br><span class="line">service/argocd-server-metrics                     ClusterIP   10.254.35.168   &lt;none&gt;        8083/TCP                     2d</span><br><span class="line"></span><br><span class="line">NAME                                               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/argocd-applicationset-controller   1/1     1            1           2d</span><br><span class="line">deployment.apps/argocd-dex-server                  1/1     1            1           2d</span><br><span class="line">deployment.apps/argocd-notifications-controller    1/1     1            1           2d</span><br><span class="line">deployment.apps/argocd-redis                       1/1     1            1           2d</span><br><span class="line">deployment.apps/argocd-repo-server                 1/1     1            1           2d</span><br><span class="line">deployment.apps/argocd-server                      1/1     1            1           2d</span><br><span class="line"></span><br><span class="line">NAME                                                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/argocd-applicationset-controller-688c5855db   0         0         0       2d</span><br><span class="line">replicaset.apps/argocd-applicationset-controller-7b5f77c495   1         1         1       41h</span><br><span class="line">replicaset.apps/argocd-dex-server-58df896df                   1         1         1       41h</span><br><span class="line">replicaset.apps/argocd-dex-server-6dbbc6c548                  0         0         0       2d</span><br><span class="line">replicaset.apps/argocd-notifications-controller-5dcb877fd8    1         1         1       42h</span><br><span class="line">replicaset.apps/argocd-notifications-controller-6769d68cc6    0         0         0       2d</span><br><span class="line">replicaset.apps/argocd-redis-58654b9b4b                       1         1         1       41h</span><br><span class="line">replicaset.apps/argocd-redis-689cb75c98                       0         0         0       2d</span><br><span class="line">replicaset.apps/argocd-repo-server-5d66c4c699                 0         0         0       47h</span><br><span class="line">replicaset.apps/argocd-repo-server-7459b57cd                  1         1         1       41h</span><br><span class="line">replicaset.apps/argocd-repo-server-88d94bc9c                  0         0         0       2d</span><br><span class="line">replicaset.apps/argocd-server-5d9f577d6c                      0         0         0       2d</span><br><span class="line">replicaset.apps/argocd-server-67545b758b                      1         1         1       42h</span><br><span class="line"></span><br><span class="line">NAME                                             READY   AGE</span><br><span class="line">statefulset.apps/argocd-application-controller   1/1     2d</span><br></pre></td></tr></table></figure><h4 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 system]# kubectl -n argocd logs -f pod&#x2F;argocd-repo-server-7459b57cd-xfbgx</span><br><span class="line">time&#x3D;&quot;2023-02-16T14:15:51Z&quot; level&#x3D;info msg&#x3D;&quot;ArgoCD Repository Server is starting&quot; built&#x3D;&quot;2023-02-16T17:14:51Z&quot; commit&#x3D;2bf51f401d6700f8e8b9565d9fc3f66dcf60a0b6 port&#x3D;8081 version&#x3D;v2.5.0-rc1+2bf51f4</span><br><span class="line">time&#x3D;&quot;2023-02-16T14:15:51Z&quot; level&#x3D;info msg&#x3D;&quot;Generating self-signed TLS certificate for this session&quot;</span><br><span class="line">time&#x3D;&quot;2023-02-16T14:15:51Z&quot; level&#x3D;info msg&#x3D;&quot;Initializing GnuPG keyring at &#x2F;app&#x2F;config&#x2F;gpg&#x2F;keys&quot;</span><br><span class="line">time&#x3D;&quot;2023-02-16T14:15:51Z&quot; level&#x3D;info msg&#x3D;&quot;gpg --no-permission-warning --logger-fd 1 --batch --gen-key &#x2F;tmp&#x2F;gpg-key-recipe735869143&quot; dir&#x3D; execID&#x3D;30201</span><br><span class="line">time&#x3D;&quot;2023-02-16T14:15:57Z&quot; level&#x3D;error msg&#x3D;&quot;&#96;gpg --no-permission-warning --logger-fd 1 --batch --gen-key &#x2F;tmp&#x2F;gpg-key-recipe735869143&#96; failed exit status 2&quot; execID&#x3D;30201</span><br><span class="line">time&#x3D;&quot;2023-02-16T14:15:57Z&quot; level&#x3D;info msg&#x3D;Trace args&#x3D;&quot;[gpg --no-permission-warning --logger-fd 1 --batch --gen-key &#x2F;tmp&#x2F;gpg-key-recipe735869143]&quot; dir&#x3D; operation_name&#x3D;&quot;exec gpg&quot; time_ms&#x3D;6010.954976</span><br></pre></td></tr></table></figure><p>解决方法</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n argocd edit deploy argocd-repo-server</span><br><span class="line">/spec/template/spec/containers/0/securityContext/seccompProfile/typeby的值改为Unconfined</span><br><span class="line"></span><br><span class="line">          seccompProfile:</span><br><span class="line">            <span class="built_in">type</span>: Unconfined</span><br></pre></td></tr></table></figure><h3 id="访问Argocd"><a href="#访问Argocd" class="headerlink" title="访问Argocd"></a>访问Argocd</h3><p>访问Argocd的方法有两种</p><ul><li>Web UI</li><li>Argocd CLI</li></ul><h4 id="Web-UI访问"><a href="#Web-UI访问" class="headerlink" title="Web UI访问"></a>Web UI访问</h4><p>配置Ingress</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment">#  kubectl -n argocd get ingress argocd-server-ingress -o yaml</span></span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: nginx</span><br><span class="line">    kubernetes.io/tls-acme: <span class="string">"true"</span></span><br><span class="line">    nginx.ingress.kubernetes.io/backend-protocol: HTTPS</span><br><span class="line">    nginx.ingress.kubernetes.io/force-ssl-redirect: <span class="string">"true"</span></span><br><span class="line">    nginx.ingress.kubernetes.io/ssl-passthrough: <span class="string">"true"</span></span><br><span class="line">  name: argocd-server-ingress</span><br><span class="line">  namespace: argocd</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: argocd.roobo.net</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          service:</span><br><span class="line">            name: argocd-server</span><br><span class="line">            port:</span><br><span class="line">              name: https</span><br><span class="line">        path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line">  tls:</span><br><span class="line">  - hosts:</span><br><span class="line">    - argocd.roobo.net</span><br><span class="line">    secretName: roobo.net</span><br></pre></td></tr></table></figure><p>获取admin密码</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=<span class="string">"&#123;.data.password&#125;"</span> | base64 -d &amp;&amp; <span class="built_in">echo</span></span><br></pre></td></tr></table></figure><p>使用admin/密码即可通过Ingress端口访问Argocd Web UI。</p><h4 id="Argocd-CLI访问"><a href="#Argocd-CLI访问" class="headerlink" title="Argocd CLI访问"></a>Argocd CLI访问</h4><p>下载客户端</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://github.com/argoproj/argo-cd/releases/download/v2.6.1/argocd-linux-amd64</span><br><span class="line"></span><br><span class="line">sudo cp argocd-linux-amd64 /usr/<span class="built_in">local</span>/bin/argocd</span><br><span class="line"></span><br><span class="line">sudo chmod 777 /usr/<span class="built_in">local</span>/bin/argocd</span><br></pre></td></tr></table></figure><p>登录</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">argocd login &lt;argocd-server&gt; --grpc-web</span><br><span class="line"></span><br><span class="line">一键登录</span><br><span class="line">argocd login &lt;argocd-server&gt; --username admin --password $(kubectl  --kubeconfig=<span class="variable">$KCONFIG</span> -n argocd get secret argocd-initial-admin-secret -o jsonpath=<span class="string">"&#123;.data.password&#125;"</span> | base64 -d )  --insecure --grpc-web</span><br></pre></td></tr></table></figure><p>修改密码</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">argocd login &lt;argocd-server&gt;</span><br><span class="line">argocd account list</span><br><span class="line">argocd account update-password \</span><br><span class="line">  --account &lt;name&gt; \</span><br><span class="line">  --current-password &lt;current-admin&gt; \</span><br><span class="line">  --new-password &lt;new-user-password&gt;</span><br></pre></td></tr></table></figure><h2 id="使用CLI创建测试应用"><a href="#使用CLI创建测试应用" class="headerlink" title="使用CLI创建测试应用"></a>使用CLI创建测试应用</h2><h3 id="创建Argocd应用"><a href="#创建Argocd应用" class="headerlink" title="创建Argocd应用"></a>创建Argocd应用</h3><p>Web方式大家都很熟悉，这里以Cli 命令行方式创建演示<br>更多命令行说明可参考<a href="https://argo-cd.readthedocs.io/en/stable/user-guide/" target="_blank" rel="noopener">官网文档</a></p><h4 id="添加kubernetes集群"><a href="#添加kubernetes集群" class="headerlink" title="添加kubernetes集群"></a>添加kubernetes集群</h4><p>默认情况下Argocd已经将当前k8s集群添加到了Clusters列表中，如果想CD到其他集群需要执行命令添加</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1. 首先把目标肌群的kube.config下载下来</span><br><span class="line">2. <span class="variable">$clustername</span> 是 kube.config 中/contexts/name 字段的值 (集群名称)</span><br><span class="line">argocd cluster add <span class="variable">$clustername</span> --kubeconfig kube.config</span><br><span class="line"></span><br><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># argocd cluster add 266043569625004212-c7ded9566e35f4533b4dd76e1abdae02a --kubeconfig server-k8s.kube.config </span></span><br><span class="line">WARNING: This will create a service account `argocd-manager` on the cluster referenced by context `266043569625004212-c7ded9566e35f4533b4dd76e1abdae02a` with full cluster level privileges. Do you want to <span class="built_in">continue</span> [y/N]? y</span><br><span class="line">INFO[0001] ServiceAccount <span class="string">"argocd-manager"</span> already exists <span class="keyword">in</span> namespace <span class="string">"kube-system"</span> </span><br><span class="line">INFO[0001] ClusterRole <span class="string">"argocd-manager-role"</span> updated    </span><br><span class="line">INFO[0001] ClusterRoleBinding <span class="string">"argocd-manager-role-binding"</span> updated </span><br><span class="line">Cluster <span class="string">'https://182.92.***.***:6443'</span> added</span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># argocd cluster list</span></span><br><span class="line">SERVER                          NAME                                                  VERSION  STATUS      MESSAGE                                                  PROJECT</span><br><span class="line">https://182.92.***.***:6443     266043569625004212-c7ded9566e35f4533b4dd76e1abdae02a           Unknown     Cluster has no applications and is not being monitored.  </span><br><span class="line">https://kubernetes.default.svc  <span class="keyword">in</span>-cluster                                            1.20     Successful</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argocd-addcluster.png" alt="argocd-addcluster"></p><h4 id="添加Repositories"><a href="#添加Repositories" class="headerlink" title="添加Repositories"></a>添加Repositories</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># argocd repo add http://git.******.com/op/devops-argocd-test.git --username sungaomeng --password ******</span></span><br><span class="line">Repository <span class="string">'http://git.******.com/op/devops-argocd-test.git'</span> added</span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># argocd repo list</span></span><br><span class="line">TYPE  NAME  REPO                                                 INSECURE  OCI    LFS    CREDS  STATUS      MESSAGE  PROJECT</span><br><span class="line">git         http://git.******.com/op/devops-argocd-test.git  <span class="literal">false</span>     <span class="literal">false</span>  <span class="literal">false</span>  <span class="literal">true</span>   Successful</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argocd-addrepo.png" alt="argocd-addrepo"></p><h4 id="添加Applications"><a href="#添加Applications" class="headerlink" title="添加Applications"></a>添加Applications</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># cat test.yaml </span></span><br><span class="line">apiVersion: argoproj.io/v1alpha1</span><br><span class="line">kind: Application</span><br><span class="line">metadata:</span><br><span class="line">  name: devops-argocd-test</span><br><span class="line">  namespace: argocd</span><br><span class="line">spec:</span><br><span class="line">  project: default <span class="comment"># 定义的项目名</span></span><br><span class="line">  <span class="built_in">source</span>:</span><br><span class="line">    repoURL: http://git.******.com/op/devops-argocd-test.git <span class="comment"># git地址</span></span><br><span class="line">    targetRevision: master <span class="comment"># git分支</span></span><br><span class="line">    path: manifests  <span class="comment"># git路径对应到目录下的配置</span></span><br><span class="line">  destination:</span><br><span class="line">    server: https://182.92.***.***:6443 <span class="comment"># k8s api</span></span><br><span class="line">    namespace: my-app <span class="comment"># 名称空间</span></span><br><span class="line">    </span><br><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># kubectl apply -f test.yaml </span></span><br><span class="line">application.argoproj.io/devops-argocd-test created</span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># argocd app list</span></span><br><span class="line">NAME                       CLUSTER                      NAMESPACE  PROJECT  STATUS     HEALTH   SYNCPOLICY  CONDITIONS  REPO                                                 PATH       TARGET</span><br><span class="line">argocd/devops-argocd-test  https://182.92.234.138:6443  my-app     default  OutOfSync  Missing  &lt;none&gt;      &lt;none&gt;      http://git.365jiating.com/op/devops-argocd-test.git  manifests  master</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argocd-addapplications.png" alt="argocd-addapplications"></p><h4 id="devops-argocd-test-模板"><a href="#devops-argocd-test-模板" class="headerlink" title="devops-argocd-test 模板"></a>devops-argocd-test 模板</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">❯ find manifests</span><br><span class="line">manifests</span><br><span class="line">manifests/deployment.yaml</span><br><span class="line">❯ cat manifests/deployment.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    run: argocd-test-app</span><br><span class="line">  name: argocd-test-app</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: argocd-test-app</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: argocd-test-app</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: registry.cn-hangzhou.aliyuncs.com/rookieops/argocd-test-app:v1</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        name: argocd-test-app</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    run: argocd-test-app</span><br><span class="line">  name: argocd-test-app</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: tcp-8080</span><br><span class="line">    port: 8080</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    run: argocd-test-app</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br></pre></td></tr></table></figure><h4 id="同步Applications"><a href="#同步Applications" class="headerlink" title="同步Applications"></a>同步Applications</h4><p>添加应用后，默认需要手动sync下</p><p>可以使用Web UI 点击SYNC同步，或者使用命令行同步</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># argocd app list</span></span><br><span class="line">NAME                       CLUSTER                      NAMESPACE  PROJECT  STATUS     HEALTH   SYNCPOLICY  CONDITIONS  REPO                                                 PATH       TARGET</span><br><span class="line">argocd/devops-argocd-test  https://182.92.***.***:6443  my-app     default  OutOfSync  Missing  &lt;none&gt;      &lt;none&gt;      http://git.******.com/op/devops-argocd-test.git  manifests  master</span><br><span class="line">[root@prod-public-runner-k8s-node01 ~]<span class="comment"># argocd app sync devops-argocd-test</span></span><br><span class="line">TIMESTAMP                  GROUP        KIND   NAMESPACE                  NAME    STATUS    HEALTH        HOOK  MESSAGE</span><br><span class="line">2023-02-17T14:30:55+08:00            Service      my-app       argocd-test-app  OutOfSync  Missing              </span><br><span class="line">2023-02-17T14:30:55+08:00   apps  Deployment      my-app       argocd-test-app  OutOfSync  Missing              </span><br><span class="line">2023-02-17T14:30:56+08:00            Service      my-app       argocd-test-app    Synced  Healthy              </span><br><span class="line">2023-02-17T14:30:56+08:00            Service      my-app       argocd-test-app    Synced   Healthy              service/argocd-test-app created</span><br><span class="line">2023-02-17T14:30:56+08:00   apps  Deployment      my-app       argocd-test-app  OutOfSync  Missing              deployment.apps/argocd-test-app created</span><br><span class="line">2023-02-17T14:30:56+08:00   apps  Deployment      my-app       argocd-test-app    Synced  Progressing              deployment.apps/argocd-test-app created</span><br><span class="line"></span><br><span class="line">Name:               argocd/devops-argocd-test</span><br><span class="line">Project:            default</span><br><span class="line">Server:             https://182.92.***.***:6443</span><br><span class="line">Namespace:          my-app</span><br><span class="line">URL:                https://argocd.roobo.net/applications/devops-argocd-test</span><br><span class="line">Repo:               http://git.******.com/op/devops-argocd-test.git</span><br><span class="line">Target:             master</span><br><span class="line">Path:               manifests</span><br><span class="line">SyncWindow:         Sync Allowed</span><br><span class="line">Sync Policy:        &lt;none&gt;</span><br><span class="line">Sync Status:        Synced to master (18be256)</span><br><span class="line">Health Status:      Progressing</span><br><span class="line"></span><br><span class="line">Operation:          Sync</span><br><span class="line">Sync Revision:      18be2568288fff0143a4c3a127ea0866cb39a583</span><br><span class="line">Phase:              Succeeded</span><br><span class="line">Start:              2023-02-17 14:30:55 +0800 CST</span><br><span class="line">Finished:           2023-02-17 14:30:56 +0800 CST</span><br><span class="line">Duration:           1s</span><br><span class="line">Message:            successfully synced (all tasks run)</span><br><span class="line"></span><br><span class="line">GROUP  KIND        NAMESPACE  NAME             STATUS  HEALTH       HOOK  MESSAGE</span><br><span class="line">       Service     my-app     argocd-test-app  Synced  Healthy            service/argocd-test-app created</span><br><span class="line">apps   Deployment  my-app     argocd-test-app  Synced  Progressing        deployment.apps/argocd-test-app created</span><br></pre></td></tr></table></figure><p>Web UI 此时显示绿色状态</p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argocd-applicationssync.png" alt="argocd-applicationssync"></p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argocd-applicationssyncstatus.png" alt="argocd-applicationssyncstatus"></p><p>在目标集群查看应用状态</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-server-k8s0155010node ~]<span class="comment"># kubelet -n my-app get all</span></span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/argocd-test-app-86d78cd54c-jpmjx   1/1     Running   0          3m21s</span><br><span class="line"></span><br><span class="line">NAME                      TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/argocd-test-app   NodePort   172.31.0.27   &lt;none&gt;        8080:30573/TCP   3m21s</span><br><span class="line"></span><br><span class="line">NAME                              READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/argocd-test-app   1/1     1            1           3m21s</span><br><span class="line"></span><br><span class="line">NAME                                         DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/argocd-test-app-86d78cd54c   1         1         1       3m21s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@prod-server-k8s0155010node ~]<span class="comment"># kubectl -n my-app get svc</span></span><br><span class="line">NAME              TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">argocd-test-app   NodePort   172.31.0.27   &lt;none&gt;        8080:30573/TCP   8m35s</span><br><span class="line"></span><br><span class="line">[root@prod-server-k8s0155010node ~]<span class="comment"># curl 172.31.0.27:8080</span></span><br><span class="line">&#123;<span class="string">"data"</span>:<span class="string">"这是第一版，Hello Joker"</span>,<span class="string">"version"</span>:<span class="string">"v1"</span>&#125;</span><br></pre></td></tr></table></figure><p>此时应用版本为 “version”:”v1”</p><h2 id="验证CD功能"><a href="#验证CD功能" class="headerlink" title="验证CD功能"></a>验证CD功能</h2><h3 id="测试CD流程"><a href="#测试CD流程" class="headerlink" title="测试CD流程"></a>测试CD流程</h3><p>Argo CD 默认情况下每 3 分钟会检测 Git 仓库一次，用于判断应用实际状态是否和 Git 中声明的期望状态一致，如果不一致，状态就转换为 OutOfSync。默认情况下并不会触发更新，除非通过 syncPolicy 配置了自动同步。</p><p>如果嫌周期性同步太慢了，也可以通过设置 Webhook 来使 Git 仓库更新时立即触发同步。具体的使用方式会放到后续的教程中，本文不再赘述。</p><h4 id="手动触发-SYNC"><a href="#手动触发-SYNC" class="headerlink" title="手动触发(SYNC)"></a>手动触发(SYNC)</h4><ol><li>devops-argocd-test 仓库将manifests/deployment.yaml中 image 由v1改为v2 并提交master分支</li><li>3分钟左右agrocd会检测到，并将App状态转换为OutOfSync</li><li>此时就需要手动点击SYNC 将更改同步到目标集群</li></ol><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argocd-app-outoofsync.png" alt="argocd-app-outoofsync"></p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argocd-app-outoofsyncstatus.png" alt="argocd-app-outoofsyncstatus"></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 kube-config]<span class="comment"># argocd app list</span></span><br><span class="line">NAME                       CLUSTER                      NAMESPACE  PROJECT  STATUS     HEALTH   SYNCPOLICY  CONDITIONS  REPO                                                 PATH       TARGET</span><br><span class="line">argocd/devops-argocd-test  https://182.92.***.***:6443  my-app     default  OutOfSync  Healthy  &lt;none&gt;      &lt;none&gt;      http://git.******.com/op/devops-argocd-test.git  manifests  master</span><br><span class="line"></span><br><span class="line">[root@prod-public-runner-k8s-node01 kube-config]<span class="comment"># argocd app sync devops-argocd-test</span></span><br><span class="line">TIMESTAMP                  GROUP        KIND   NAMESPACE                  NAME    STATUS    HEALTH        HOOK  MESSAGE</span><br><span class="line">2023-02-17T14:53:25+08:00            Service      my-app       argocd-test-app    Synced   Healthy              </span><br><span class="line">2023-02-17T14:53:25+08:00   apps  Deployment      my-app       argocd-test-app  OutOfSync  Healthy              </span><br><span class="line"></span><br><span class="line">Name:               argocd/devops-argocd-test</span><br><span class="line">Project:            default</span><br><span class="line">Server:             https://182.92.***.***:6443</span><br><span class="line">Namespace:          my-app</span><br><span class="line">URL:                https://argocd.roobo.net/applications/devops-argocd-test</span><br><span class="line">Repo:               http://git.******.com/op/devops-argocd-test.git</span><br><span class="line">Target:             master</span><br><span class="line">Path:               manifests</span><br><span class="line">SyncWindow:         Sync Allowed</span><br><span class="line">Sync Policy:        &lt;none&gt;</span><br><span class="line">Sync Status:        Synced to master (1c52f4d)</span><br><span class="line">Health Status:      Progressing</span><br><span class="line"></span><br><span class="line">Operation:          Sync</span><br><span class="line">Sync Revision:      1c52f4d2c229361cbdfa30f36f723e2795855fd1</span><br><span class="line">Phase:              Succeeded</span><br><span class="line">Start:              2023-02-17 14:53:25 +0800 CST</span><br><span class="line">Finished:           2023-02-17 14:53:25 +0800 CST</span><br><span class="line">Duration:           0s</span><br><span class="line">Message:            successfully synced (all tasks run)</span><br><span class="line"></span><br><span class="line">GROUP  KIND        NAMESPACE  NAME             STATUS  HEALTH       HOOK  MESSAGE</span><br><span class="line">       Service     my-app     argocd-test-app  Synced  Healthy            service/argocd-test-app unchanged</span><br><span class="line">apps   Deployment  my-app     argocd-test-app  Synced  Progressing        deployment.apps/argocd-test-app configured</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@prod-public-runner-k8s-node01 kube-config]<span class="comment"># argocd app list</span></span><br><span class="line">NAME                       CLUSTER                      NAMESPACE  PROJECT  STATUS  HEALTH   SYNCPOLICY  CONDITIONS  REPO                                                 PATH       TARGET</span><br><span class="line">argocd/devops-argocd-test  https://182.92.***.***:6443  my-app     default  Synced  Healthy  &lt;none&gt;      &lt;none&gt;      http://git.365jiating.com/op/devops-argocd-test.git  manifests  master</span><br></pre></td></tr></table></figure><p>在目标集群查看应用状态</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-server-k8s0155010node ~]<span class="comment"># kubectl -n my-app get all</span></span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/argocd-test-app-68546f4f4b-tt6kq   1/1     Running   0          2m15s</span><br><span class="line"></span><br><span class="line">NAME                      TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/argocd-test-app   NodePort   172.31.0.27   &lt;none&gt;        8080:30573/TCP   20m</span><br><span class="line"></span><br><span class="line">NAME                              READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/argocd-test-app   1/1     1            1           20m</span><br><span class="line"></span><br><span class="line">NAME                                         DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/argocd-test-app-68546f4f4b   1         1         1       2m15s</span><br><span class="line">replicaset.apps/argocd-test-app-86d78cd54c   0         0         0       20m</span><br><span class="line">[root@prod-server-k8s0155010node ~]<span class="comment"># curl 172.31.0.27:8080</span></span><br><span class="line">&#123;<span class="string">"data"</span>:<span class="string">"这是第二版，Hello JackMa"</span>,<span class="string">"version"</span>:<span class="string">"v2"</span>&#125;</span><br></pre></td></tr></table></figure><p>此时应用版本为 “version”:”v2”</p><h4 id="自动触发"><a href="#自动触发" class="headerlink" title="自动触发"></a>自动触发</h4><p>为应用开启自动同步，开启后检测到状态不一致将会自动同步，无需手动sync</p><p>配置自动同步运行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">argocd app <span class="built_in">set</span> devops-argocd-test --sync-policy automated</span><br></pre></td></tr></table></figure><p>或者 kubectl -n argocd edit app devops-argocd-test</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spec:</span><br><span class="line">  syncPolicy:</span><br><span class="line">    automated: &#123;&#125;</span><br></pre></td></tr></table></figure><p>测试下</p><ol><li>devops-argocd-test 仓库将manifests/deployment.yaml中 image 由v2改回v1，并将replicas改为2 ，提交master分支</li><li>3分钟左右agrocd会检测到，并自动同步到目标集群</li></ol><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/argocd/argocd-applicationsautosyncstatus.png" alt="argocd-applicationsautosyncstatus"></p><p>在目标集群查看应用状态</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-server-k8s0155010node ~]<span class="comment"># kubectl -n my-app get all</span></span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/argocd-test-app-86d78cd54c-84bf5   1/1     Running   0          13m</span><br><span class="line">pod/argocd-test-app-86d78cd54c-ffpr8   1/1     Running   0          13m</span><br><span class="line"></span><br><span class="line">NAME                      TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/argocd-test-app   NodePort   172.31.0.27   &lt;none&gt;        8080:30573/TCP   44m</span><br><span class="line"></span><br><span class="line">NAME                              READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/argocd-test-app   2/2     2            2           44m</span><br><span class="line"></span><br><span class="line">NAME                                         DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/argocd-test-app-68546f4f4b   0         0         0       26m</span><br><span class="line">replicaset.apps/argocd-test-app-86d78cd54c   2         2         2       44m</span><br><span class="line">[root@prod-server-k8s0155010node ~]<span class="comment">#</span></span><br><span class="line">[root@prod-server-k8s0155010node ~]<span class="comment"># curl 172.31.0.27:8080</span></span><br><span class="line">&#123;<span class="string">"data"</span>:<span class="string">"这是第一版，Hello Joker"</span>,<span class="string">"version"</span>:<span class="string">"v1"</span>&#125;</span><br></pre></td></tr></table></figure><p>此时应用版本为 “version”:”v1” ，副本为2</p>]]></content>
      
      
      <categories>
          
          <category> CICD </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CICD </tag>
            
            <tag> Argocd </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubernetes由v1.11升级到v1.20</title>
      <link href="/k8s/kubernetes-upgrade-v1.11tov1.20/"/>
      <url>/k8s/kubernetes-upgrade-v1.11tov1.20/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2018年写了一套ansible一键安装kubernetes v1.11版本集群，后基于此在公司测试环境搭建了一套集群，目前版本比较低，计划升级，记录下升级过程</p><p>ansbile v1.11安装见<a href="https://github.com/see-sgm/ansible-kubernetes.git" target="_blank" rel="noopener">GitHub</a></p></blockquote><h3 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h3><h4 id="1-下载新版本文件"><a href="#1-下载新版本文件" class="headerlink" title="1. 下载新版本文件"></a>1. 下载新版本文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir /root/v1.20</span><br><span class="line">wget -P /root/v1.20/ https://storage.googleapis.com/kubernetes-release/release/v1.20.4/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">wget -P /root/v1.20/ https://storage.googleapis.com/kubernetes-release/release/v1.20.4/kubernetes-client-linux-amd64.tar.gz</span><br><span class="line"><span class="built_in">cd</span> /root/v1.20</span><br><span class="line">tar zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">tar zxvf kubernetes-client-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><h4 id="2-备份"><a href="#2-备份" class="headerlink" title="2. 备份"></a>2. 备份</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir /root/v1.11</span><br><span class="line">cp -a /usr/<span class="built_in">local</span>/bin /root/v1.11/</span><br><span class="line">cp -a /etc/systemd/system/kube* /root/v1.11/</span><br></pre></td></tr></table></figure><h3 id="二、升级"><a href="#二、升级" class="headerlink" title="二、升级"></a>二、升级</h3><h4 id="1-升级kubectl"><a href="#1-升级kubectl" class="headerlink" title="1. 升级kubectl"></a>1. 升级kubectl</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp -a /root/v1.20/kubernetes/client/bin/kubectl /usr/<span class="built_in">local</span>/bin/</span><br></pre></td></tr></table></figure><h4 id="2-升级master组件"><a href="#2-升级master组件" class="headerlink" title="2. 升级master组件"></a>2. 升级master组件</h4><h5 id="apiserver"><a href="#apiserver" class="headerlink" title="apiserver"></a>apiserver</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop kube-apiserver</span><br><span class="line">systemctl stop kube-controller-manager</span><br><span class="line">systemctl stop kube-scheduler</span><br><span class="line"></span><br><span class="line">cp -a /root/v1.20/kubernetes/server/bin/&#123;kube-controller-manager,kube-scheduler,kubeadm&#125; /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">systemctl start kube-apiserver</span><br><span class="line">journalctl -fu kube-apiserver</span><br></pre></td></tr></table></figure><p>可以查看到etcd中的数据说明kube-apiserver没有问题</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node02 ~]<span class="comment"># kubectl  get cs</span></span><br><span class="line">Warning: v1 ComponentStatus is deprecated <span class="keyword">in</span> v1.19+</span><br><span class="line">NAME                 STATUS      MESSAGE                                                                                       ERROR</span><br><span class="line">scheduler            Unhealthy   Get <span class="string">"http://127.0.0.1:10251/healthz"</span>: dial tcp 127.0.0.1:10251: connect: connection refused   </span><br><span class="line">controller-manager   Unhealthy   Get <span class="string">"http://127.0.0.1:10252/healthz"</span>: dial tcp 127.0.0.1:10252: connect: connection refused   </span><br><span class="line">etcd-0               Healthy     &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;                                                                            </span><br><span class="line">etcd-1               Healthy     &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;                                                                            </span><br><span class="line">etcd-2               Healthy     &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;</span><br></pre></td></tr></table></figure><p>遇到的错误</p><blockquote><p>错误1</p><p>logs : kube-apiserver: Error: invalid port value 8080: only zero is allowed</p><p>解决方法：/etc/systemd/system/kube-apiserver.service 中删除–insecure-port=8080</p><p>错误2</p><p>logs : Error: [service-account-issuer is a required flag, –service-account-signing-key-file and –service-account-issuer are required flags]</p><p>解决方法：/etc/systemd/system/kube-apiserver.service 中增加以下三行</p><p> –service-account-issuer=<a href="https://kubernetes.default.svc.cluster.local" target="_blank" rel="noopener">https://kubernetes.default.svc.cluster.local</a> \</p><p> –service-account-key-file=/etc/kubernetes/ssl/ca-key.pem \</p><p> –service-account-signing-key-file=/etc/kubernetes/ssl/ca-key.pem \</p></blockquote><h5 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start kube-controller-manager</span><br></pre></td></tr></table></figure><p>遇到的错误</p><blockquote><p>错误1</p><p>kube-controller-manager: E0214 16:39:32.487623   31964 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: Get “<a href="http://127.0.0.1:8080/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager?timeout=10s&quot;" target="_blank" rel="noopener">http://127.0.0.1:8080/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager?timeout=10s&quot;</a>: dial tcp 127.0.0.1:8080: connect: connection refused</p><p>解决方法：/etc/systemd/system/kube-controller-manager.service 中–master=<a href="http://127.0.0.1:8080改为--master=https://127.0.0.1:6443">http://127.0.0.1:8080改为--master=https://127.0.0.1:6443</a> , 并且增加 –kubeconfig=/root/.kube/config</p></blockquote><h5 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start kube-scheduler</span><br></pre></td></tr></table></figure><p>遇到的错误</p><blockquote><p>错误1</p><p>kube-scheduler: E0214 16:45:43.294168  32693 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get “<a href="http://127.0.0.1:8080/apis/apps/v1/replicasets?limit=500&amp;resourceVersion=0&quot;" target="_blank" rel="noopener">http://127.0.0.1:8080/apis/apps/v1/replicasets?limit=500&amp;resourceVersion=0&quot;</a>: dial tcp 127.0.0.1:8080: connect: connection refused</p><p>解决方法：/etc/systemd/system/kube-controller-manager.service 中–master=<a href="http://127.0.0.1:8080改为--master=https://127.0.0.1:6443">http://127.0.0.1:8080改为--master=https://127.0.0.1:6443</a> , 并且增加 –kubeconfig=/root/.kube/config</p></blockquote><p>查看启动状态,此时kubernetes集群已经恢复</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node02 ~]<span class="comment"># kubectl  get cs</span></span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">scheduler            Healthy   ok                   </span><br><span class="line">controller-manager   Healthy   ok                   </span><br><span class="line">etcd-0               Healthy   &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;</span><br></pre></td></tr></table></figure><h4 id="3-升级node组件"><a href="#3-升级node组件" class="headerlink" title="3. 升级node组件"></a>3. 升级node组件</h4><h5 id="kubelet-kube-proxy"><a href="#kubelet-kube-proxy" class="headerlink" title="kubelet/kube-proxy"></a>kubelet/kube-proxy</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop kubelet</span><br><span class="line">systemctl stop kube-proxy</span><br><span class="line"></span><br><span class="line">cp -a /root/v1.20/kubernetes/server/bin/&#123;kubelet,kube-proxy&#125; /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">systemctl start kubelet</span><br><span class="line">journalctl -fu kubelet</span><br></pre></td></tr></table></figure><p>kubelet 启动后稍等一会 node就会Ready，否则根据日志排错</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 system]<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME                            STATUS   ROLES    AGE      VERSION</span><br><span class="line">prod-public-runner-k8s-node01   Ready    &lt;none&gt;   4y107d   v1.20.4</span><br><span class="line">prod-public-runner-k8s-node02   Ready    &lt;none&gt;   4y107d   v1.20.4</span><br><span class="line">prod-public-runner-k8s-node03   Ready    &lt;none&gt;   4y107d   v1.20.4</span><br></pre></td></tr></table></figure><p>最后启动systemctl start kube-proxy</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop kube-proxy</span><br></pre></td></tr></table></figure><h3 id="三、结果验证"><a href="#三、结果验证" class="headerlink" title="三、结果验证"></a>三、结果验证</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@prod-public-runner-k8s-node01 ~]#  kubectl cluster-info </span><br><span class="line">Kubernetes control plane is running at https:&#x2F;&#x2F;127.0.0.1:6443</span><br><span class="line">CoreDNS is running at https:&#x2F;&#x2F;127.0.0.1:6443&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-system&#x2F;services&#x2F;kube-dns:dns&#x2F;proxy</span><br><span class="line"></span><br><span class="line">To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.</span><br><span class="line">[root@prod-public-runner-k8s-node01 ~]# kubectl get node</span><br><span class="line">NAME                            STATUS   ROLES    AGE      VERSION</span><br><span class="line">prod-public-runner-k8s-node01   Ready    &lt;none&gt;   4y107d   v1.20.4</span><br><span class="line">prod-public-runner-k8s-node02   Ready    &lt;none&gt;   4y107d   v1.20.4</span><br><span class="line">prod-public-runner-k8s-node03   Ready    &lt;none&gt;   4y107d   v1.20.4</span><br><span class="line">[root@prod-public-runner-k8s-node01 ~]# kubectl get cs</span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">scheduler            Healthy   ok                   </span><br><span class="line">controller-manager   Healthy   ok                   </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="最后贴下所有配置文件"><a href="#最后贴下所有配置文件" class="headerlink" title="最后贴下所有配置文件"></a>最后贴下所有配置文件</h3><h4 id="kube-apiserver-service"><a href="#kube-apiserver-service" class="headerlink" title="kube-apiserver.service"></a>kube-apiserver.service</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=root</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/kube-apiserver \</span><br><span class="line">  --<span class="built_in">enable</span>-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \</span><br><span class="line">  --anonymous-auth=<span class="literal">false</span> \</span><br><span class="line">  --advertise-address=172.17.254.185 \</span><br><span class="line">  --allow-privileged=<span class="literal">true</span> \</span><br><span class="line">  --apiserver-count=3 \</span><br><span class="line">  --audit-policy-file=/etc/kubernetes/audit-policy.yaml \</span><br><span class="line">  --audit-log-maxage=30 \</span><br><span class="line">  --audit-log-maxbackup=3 \</span><br><span class="line">  --audit-log-maxsize=100 \</span><br><span class="line">  --audit-log-path=/var/<span class="built_in">log</span>/kubernetes/audit.log \</span><br><span class="line">  --authorization-mode=Node,RBAC \</span><br><span class="line">  --<span class="built_in">bind</span>-address=0.0.0.0 \</span><br><span class="line">  --secure-port=6443 \</span><br><span class="line">  --client-ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --kubelet-client-certificate=/etc/kubernetes/ssl/kubernetes.pem \</span><br><span class="line">  --kubelet-client-key=/etc/kubernetes/ssl/kubernetes-key.pem \</span><br><span class="line">  --etcd-cafile=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --etcd-certfile=/etc/kubernetes/ssl/etcd.pem \</span><br><span class="line">  --etcd-keyfile=/etc/kubernetes/ssl/etcd-key.pem \</span><br><span class="line">  --etcd-servers=https://172.17.254.186:2379,https://172.17.254.187:2379,https://172.17.254.185:2379 \</span><br><span class="line">  --event-ttl=1h \</span><br><span class="line">  --service-cluster-ip-range=10.254.0.0/18 \</span><br><span class="line">  --service-node-port-range=30000-32000 \</span><br><span class="line">  --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem \</span><br><span class="line">  --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \</span><br><span class="line">  --<span class="built_in">enable</span>-bootstrap-token-auth=<span class="literal">true</span> \</span><br><span class="line">  --<span class="built_in">log</span>-dir=/var/<span class="built_in">log</span>/kubernetes \</span><br><span class="line">  --v=1 \</span><br><span class="line">  --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">  --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --service-account-signing-key-file=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --experimental-encryption-provider-config=/etc/kubernetes/encryption.yaml \</span><br><span class="line">  --feature-gates=RemoveSelfLink=<span class="literal">false</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h4 id="kube-controller-manager-service"><a href="#kube-controller-manager-service" class="headerlink" title="kube-controller-manager.service"></a>kube-controller-manager.service</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/kube-controller-manager \</span><br><span class="line">  --allocate-node-cidrs=<span class="literal">true</span> \</span><br><span class="line">  --master=https://127.0.0.1:6443 \</span><br><span class="line">  --service-cluster-ip-range=10.254.0.0/18 \</span><br><span class="line">  --cluster-cidr=10.254.64.0/18 \</span><br><span class="line">  --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --controllers=*,tokencleaner,bootstrapsigner \</span><br><span class="line">  --cluster-name=kubernetes \</span><br><span class="line">  --service-account-private-key-file=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --root-ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --leader-elect=<span class="literal">true</span> \</span><br><span class="line">  --v=2 \</span><br><span class="line">  --use-service-account-credentials=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=/root/.kube/config</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h4 id="kube-scheduler-service"><a href="#kube-scheduler-service" class="headerlink" title="kube-scheduler.service"></a>kube-scheduler.service</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/kube-scheduler \</span><br><span class="line">  --<span class="built_in">bind</span>-address=0.0.0.0 \</span><br><span class="line">  --leader-elect \</span><br><span class="line">  --v=2 \</span><br><span class="line">  --kubeconfig=/root/.kube/config</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h4 id="kubelet-service"><a href="#kubelet-service" class="headerlink" title="kubelet.service"></a>kubelet.service</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/kubelet \</span><br><span class="line">  --hostname-override=prod-public-runner-k8s-node01 \</span><br><span class="line">  --pod-infra-container-image=registry.cn-beijing.aliyuncs.com/roobo/pause-amd64:3.1 \</span><br><span class="line">  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">  --config=/etc/kubernetes/kubelet.config.json \</span><br><span class="line">  --cert-dir=/etc/kubernetes/ssl \</span><br><span class="line">  --logtostderr=<span class="literal">true</span> \</span><br><span class="line">  --v=2 \</span><br><span class="line">  --allowed-unsafe-sysctls=net.*</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h4 id="kube-proxy-service"><a href="#kube-proxy-service" class="headerlink" title="kube-proxy.service"></a>kube-proxy.service</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube-Proxy Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kube-proxy</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy.config.yaml \</span><br><span class="line">  --logtostderr=<span class="literal">true</span> \</span><br><span class="line">  --v=1</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何调试nidejs代码</title>
      <link href="/nodejs/debug-nodejs/"/>
      <url>/nodejs/debug-nodejs/</url>
      
        <content type="html"><![CDATA[<blockquote><p>nodejs由于没有界面，调试起来比较困难。本文介绍一种最方便的调试nodejs的方法和工具：用chrome调试nodejs。</p></blockquote><h3 id="安装Chrome-DevTools"><a href="#安装Chrome-DevTools" class="headerlink" title="安装Chrome DevTools"></a>安装<a href="https://github.com/ChromeDevTools/devtools-frontend" target="_blank" rel="noopener">Chrome DevTools</a></h3><ol><li><p>科学上网后打开<a href="https://chrome.google.com/webstore/detail/nim-node-inspector-manage/gnhhdgbaldcilmgcpfddgdbkhjohddkj" target="_blank" rel="noopener">链接 </a>添加至Chrome</p></li><li><p>在Chrome浏览器打开 chrome://inspect 点击 Configure 按钮，确定host和端口在列表中。</p></li><li><p>从下述host和端口/json/list复制 devtoolsFrontendUrl 或 inspect 提示信息，并复制到Chrome.</p></li></ol><ul><li>用浏览器打开类似如下的地址。替换UUID。NIM的插件可以自动打开该地址。 <code>chrome-devtools://devtools/bundled/inspector.html?experiments=true&amp;v8only=true&amp;ws=localhost:9229/53e58257-2137-43c5-97e0-f5d785cfd31b</code></li></ul><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">❯ node inspect comment.js</span><br><span class="line">&lt; Debugger listening on ws://127.0.0.1:9229/53e58257-2137-43c5-97e0-f5d785cfd31b</span><br><span class="line">&lt; For <span class="built_in">help</span>, see: https://nodejs.org/en/docs/inspector</span><br><span class="line">&lt; Debugger attached.</span><br><span class="line">Break on start <span class="keyword">in</span> comment.js:2</span><br><span class="line">  1 <span class="comment">#!/usr/bin/env node</span></span><br><span class="line">&gt; 2 const request = require(<span class="string">"request"</span>);</span><br><span class="line">  3 const fs = require(<span class="string">"fs"</span>);</span><br><span class="line">  4 const path = require(<span class="string">"path"</span>);</span><br><span class="line">debug&gt;</span><br></pre></td></tr></table></figure><p>53e58257-2137-43c5-97e0-f5d785cfd31b是进程的唯一UUID;</p><p>inspect 让nodejs支持<a href="https://chromedevtools.github.io/debugger-protocol-viewer/v8/" target="_blank" rel="noopener">inspector协议</a>，监听websocket端口。缺省127.0.0.1:9229;</p><p>Inspector 协议还提供一个Http端点，以获取 WebSocket URL, UUID, 和 Chrome DevTools URL。 地址是 <code>http://[host:port]/json/list</code></p><p>访问 <a href="http://127.0.0.1:9229/json/list" target="_blank" rel="noopener">http://127.0.0.1:9229/json/list</a></p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">[</span> <span class="string">&#123;</span></span><br><span class="line">  <span class="attr">"description":</span> <span class="string">"node.js instance"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">"devtoolsFrontendUrl":</span> <span class="string">"chrome-devtools://devtools/bundled/js_app.html?experiments=true&amp;v8only=true&amp;ws=127.0.0.1:9229/53e58257-2137-43c5-97e0-f5d785cfd31b"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">"devtoolsFrontendUrlCompat":</span> <span class="string">"chrome-devtools://devtools/bundled/inspector.html?experiments=true&amp;v8only=true&amp;ws=127.0.0.1:9229/53e58257-2137-43c5-97e0-f5d785cfd31b"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">"faviconUrl":</span> <span class="string">"https://nodejs.org/static/images/favicons/favicon.ico"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">"id":</span> <span class="string">"53e58257-2137-43c5-97e0-f5d785cfd31b"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">"title":</span> <span class="string">"comment.js"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">"type":</span> <span class="string">"node"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">"url":</span> <span class="string">"file:///Users/see/roobo/work/git/blog/comment.js"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">"webSocketDebuggerUrl":</span> <span class="string">"ws://127.0.0.1:9229/53e58257-2137-43c5-97e0-f5d785cfd31b"</span></span><br><span class="line"><span class="string">&#125;</span> <span class="string">]</span></span><br></pre></td></tr></table></figure><p>以上安装完成后 Chrome浏览器打开<code>devtools://devtools/bundled/js_app.html?experiments=true&amp;v8only=true&amp;ws=127.0.0.1:9229/53e58257-2137-43c5-97e0-f5d785cfd31b</code> 即可自动跳转至调试界面</p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/nodejs/debug-nodejs-chrom-devtools.png" alt="debug-nodejs-chrom-devtools"></p>]]></content>
      
      
      <categories>
          
          <category> Nodejs </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重置Consumer的Offset到指定时间点</title>
      <link href="/kafka/reset-consumer-offset-to-specified-time-point/"/>
      <url>/kafka/reset-consumer-offset-to-specified-time-point/</url>
      
        <content type="html"><![CDATA[<p>   有些情况下需要从指定时间点开始重新消费kafka，下面记录两种方法</p><h4 id="一、直接指定时间重置Offset"><a href="#一、直接指定时间重置Offset" class="headerlink" title="一、直接指定时间重置Offset"></a>一、直接指定时间重置Offset</h4><blockquote><p>新版本(2.*)的kafka才支持 –reset-offsets 参数</p></blockquote><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka/bin/kafka-consumer-groups.sh --bootstrap-server 192.168.72.16:9092 --group elk-logstash --reset-offsets  --to-datetime <span class="string">'2020-07-20T00:00:00.000'</span>  --topic request-php-log --execute</span><br><span class="line"></span><br><span class="line"><span class="comment"># --all-topics 指定所有topic</span></span><br></pre></td></tr></table></figure><h4 id="二、查找指定时间的offset并手动重置"><a href="#二、查找指定时间的offset并手动重置" class="headerlink" title="二、查找指定时间的offset并手动重置"></a>二、查找指定时间的offset并手动重置</h4><blockquote><p>0.*版本的只能用这种笨方法</p><p>前提是生产进topic的message 需要有时间字段，例如：”2020-07-20 00:10:23 test messages.”</p></blockquote><ul><li><p>查看topic的offset最大值</p><blockquote><p>–time -1 查找offset最大值</p><p>–time -2 查找offset最小值</p></blockquote><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/roobo/server/kafka/bin/kafka-run-class.sh kafka.tools.GetOffsetShell  --broker-list 192.168.72.16:9092 --topic request-php-log --time -1</span><br></pre></td></tr></table></figure></li><li><p>指定offset消费topic</p><blockquote><p> 根据日志内容的时间判断offset是不是自己想要的时间点</p><p> 如果不是就增大或者减小offset值，直至找到自己想要的时间点的日志，并记录下offset</p></blockquote><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./kafka-simple-consumer-shell.sh --broker-list 192.168.72.16:9092 --topic request-php-log --max-messages 10 --partition 1 --<span class="built_in">print</span>-offsets --offset 1522801500</span><br></pre></td></tr></table></figure></li><li><p>修改zookeeper里的offset偏移量</p><blockquote><p>记录下offset后 需要手动去zookeeper里修改consumer-group的消费偏移量</p></blockquote><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./zkCli.sh</span><br><span class="line"><span class="built_in">set</span> /consumers/<span class="built_in">test</span>-consumer-group/offsets/request-php-log/1 1522810500</span><br></pre></td></tr></table></figure></li></ul><p>这时再次启动test-consumer-group的消费端即可从指定的offset处开始消费</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>等保三级 - Linux 合规基线检查整改项</title>
      <link href="/dengbao/centos-baseline-inspection/"/>
      <url>/dengbao/centos-baseline-inspection/</url>
      
        <content type="html"><![CDATA[<p>#等保三级 -  Linux 合规基线检查整改项</p><p><strong>1、检查项目 : 设置密码复杂度及长度</strong></p><p>加固建议：长度不少于<code>8</code>位, 复杂度包括：<code>大小写字母、数字、特殊字符</code>，<code>4选3</code></p><p>Centos7 修改<code>/etc/security/pwquality.conf</code></p><p>Ubuntu 修改<code>/etc/pam.d/common-password</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># retry= N：定义登录/修改密码失败时，可以重试的次数；</span></span><br><span class="line"><span class="comment"># difok= N：定义新密码中必须有几个字符要与旧密码不同。但是如果新密码中有1/2以上的字符与旧密码不同时，该新密码将被接受；</span></span><br><span class="line"><span class="comment"># minlen = N：定义用户密码的最小长度；</span></span><br><span class="line"><span class="comment"># dcredit = N：定义用户密码中必须包含多少个数字；</span></span><br><span class="line"><span class="comment"># ucredit = N：定义用户密码中必须包含多少个大写字母；</span></span><br><span class="line"><span class="comment"># lcredit = N：定义用户密码中必须包含多少个小些字母；</span></span><br><span class="line"><span class="comment"># ocredit = N：定义用户密码中必须包含多少个特殊字符（除数字、字母之外）；</span></span><br><span class="line"><span class="comment"># minclass = N：定义用户密码所需的最少字符类数</span></span><br><span class="line">其中 =-1表示，至少有一个</span><br><span class="line"></span><br><span class="line">sed -i <span class="string">'s/# minlen = 9/minlen = 8/'</span> /etc/security/pwquality.conf</span><br><span class="line">sed -i <span class="string">'s/# dcredit = 1/dcredit = -1/'</span> /etc/security/pwquality.conf</span><br><span class="line">sed -i <span class="string">'s/# ucredit = 1/ucredit = -1/'</span> /etc/security/pwquality.conf</span><br><span class="line">sed -i <span class="string">'s/# lcredit = 1/lcredit = -1/'</span> /etc/security/pwquality.conf</span><br><span class="line">sed -i <span class="string">'s/# ocredit = 1/ocredit = -1/'</span> /etc/security/pwquality.conf</span><br></pre></td></tr></table></figure><p>Centos6 修改<code>/etc/pam.d/system-auth</code>文件, 在<code>password</code>行之上增加下面这行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">password    requisite     pam_cracklib.so try_first_pass retry=2 <span class="built_in">type</span>=A+b+5+! difok=3 minlen=8 dcredit=-1 ucredit=-1 lcredit=-1 ocredit=-1</span><br></pre></td></tr></table></figure><p><strong>2、检查项目 : 禁止ROOT直接SSH登录</strong></p><p>加固建议：编辑配置文件<code>/etc/ssh/sshd_config</code>, 将<code>PermitRootLogin yes</code>改为<code>PermitRootLogin no</code></p><p>(注意：禁止root账户登陆前确保有其他账户可以正常使用)</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s/^#PermitRootLogin yes/PermitRootLogin no/'</span> /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p><strong>3、检查项目 : 登录失败处理功能(SSH连续N次登录失败,自动锁定X秒)</strong></p><p>加固建议：编辑<code>/etc/pam.d/sshd</code>文件, 在非注释行的第一行(即#%PAM-1.0下面)添加以下行</p><p>(deny为连续失败次数，配置为3-8次，unlock_time为解锁时间，配置为600-1800秒)</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">auth required pam_tally2.so deny=5 even_deny_root unlock_time=900 root_unlock_time=900</span><br></pre></td></tr></table></figure><p><strong>4、检查项目 : 设置SSH空闲超时退出时间</strong></p><p>加固建议: 编辑<code>/etc/ssh/sshd_config</code></p><p>将<code>ClientAliveInterval</code> 设置为<code>300到900</code>，即<code>5-15</code>分钟，</p><p>将<code>ClientAliveCountMax</code>设置为<code>0</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ClientAliveInterval 900</span><br><span class="line">ClientAliveCountMax 0</span><br></pre></td></tr></table></figure><p><strong>5、检查项目 : 禁止SSH空密码用户登录</strong></p><p>加固建议: 在<code>/etc/ssh/sshd_config</code>中取消<code>PermitEmptyPasswords no</code>注释符号#</p><p><strong>6、检查项目 : 确保SSH MaxAuthTries设置为3到6之间</strong></p><p>加固建议: 在<code>/etc/ssh/sshd_config</code>中</p><p>取消<code>MaxAuthTries</code>注释符号#，设置最大密码尝试失败次数<code>3-6</code>，建议为5：<code>MaxAuthTries 5</code></p><p><strong>7、检查项目 : SSHD强制使用V2安全协议</strong></p><p>加固建议: 编辑<code>/etc/ssh/sshd_config</code></p><p>文件以按如下方式设置参数：<code>Protocol 2</code></p><p><strong>8、检查项目 : 确保SSH LogLevel设置为INFO</strong></p><p>加固建议: 编辑<code>/etc/ssh/sshd_config</code> 文件以按如下方式设置参数(取消注释): <code>LogLevel INFO</code></p><p><strong>9、检查项目 : 设置密码失效时间</strong></p><p>加固建议: 在 <code>/etc/login.defs</code> 中将 <code>PASS_MAX_DAYS</code> 参数设置为 <code>60-180</code>之间, 建议为<code>90</code>：<code>PASS_MAX_DAYS 90</code></p><p>需同时执行命令设置root密码失效时间： <code>$ chage --maxdays 90 root</code></p><p>chage -l root # 查询用户的密码到期时间等信息</p><p><strong>10、检查项目 : 设置密码修改最小间隔时间</strong></p><p>加固建议: 在 <code>/etc/login.defs</code> 中将 <code>PASS_MIN_DAYS</code> 参数设置为<code>5-14</code>之间, 建议为<code>7</code>：<code>PASS_MIN_DAYS 7</code></p><p>需同时执行命令为 <code>root</code>用户设置：<code>$ chage --mindays 7 root</code></p><p><strong>11、检查项目 : 设置用户权限配置文件的权限</strong></p><p>加固建议: 执行以下5条命令</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chown root:root /etc/passwd /etc/shadow /etc/group /etc/gshadow</span><br><span class="line"></span><br><span class="line">chmod 0644 /etc/group</span><br><span class="line"></span><br><span class="line">chmod 0644 /etc/passwd</span><br><span class="line"></span><br><span class="line">chmod 0400 /etc/shadow</span><br><span class="line"></span><br><span class="line">chmod 0400 /etc/gshadow</span><br></pre></td></tr></table></figure><p><strong>12、检查项目 : 确保root是唯一的UID为0的帐户</strong></p><p>加固建议: 除<code>root</code>以外其他UID为<code>0</code>的用户都应该删除，或者为其分配新的UID</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /etc/passwd | awk -F: <span class="string">'($3 == 0) &#123; print $1 &#125;'</span>|grep -v <span class="string">'^root$'</span></span><br></pre></td></tr></table></figure><p><strong>13、检查项目 : 确保三权分立账户存在</strong></p><p>加固建议: 系统需要存在三个独立账户：<code>运维管理员(op)、审计管理员(audit)、安全管理员(security)</code>, 并有不同的权限</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd audit</span><br><span class="line">usermod -G audit audit</span><br><span class="line">useradd op </span><br><span class="line">usermod -G op op</span><br><span class="line">useradd security </span><br><span class="line">usermod -G security security</span><br></pre></td></tr></table></figure><p><strong>14、检查项目 : 应启用安全审计功能，审计覆盖到每个用户，对重要的用户行为和重要安全事件进行审计</strong></p><p>加固建议：</p><ul><li>启用 <code>auditd</code> 服务</li><li>启用 <code>rsyslog</code> 或 <code>syslog-ng</code> 服务</li><li>确保收集用户的文件删除事件</li><li>确保收集对系统管理范围（sudoers）的更改</li><li>确保收集修改用户/组信息的事件 如使用了第三方日志收集服务，可自行举证并忽略此项。</li></ul><p>安装audit服务</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install audit</span><br><span class="line">chkconfig --level 35 auditd on | systemctl <span class="built_in">enable</span> auditd</span><br></pre></td></tr></table></figure><p>将以下行添加到<code>/etc/audit/rules.d/audit.rules</code>和<code>/etc/audit/audit.rules</code> 文件中</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">-a</span> <span class="string">always,exit</span> <span class="string">-F</span> <span class="string">arch=b64</span> <span class="string">-S</span> <span class="string">unlink</span> <span class="string">-S</span> <span class="string">unlinkat</span> <span class="string">-S</span> <span class="string">rename</span> <span class="string">-S</span> <span class="string">renameat</span> <span class="string">-F</span> <span class="string">auid&gt;=1000</span> <span class="string">-F</span> <span class="string">auid!=4294967295</span> <span class="string">-k</span> <span class="string">delete</span></span><br><span class="line"><span class="string">-a</span> <span class="string">always,exit</span> <span class="string">-F</span> <span class="string">arch=b32</span> <span class="string">-S</span> <span class="string">unlink</span> <span class="string">-S</span> <span class="string">unlinkat</span> <span class="string">-S</span> <span class="string">rename</span> <span class="string">-S</span> <span class="string">renameat</span> <span class="string">-F</span> <span class="string">auid&gt;=1000</span> <span class="string">-F</span> <span class="string">auid!=4294967295</span> <span class="string">-k</span> <span class="string">delete</span></span><br><span class="line"><span class="string">-w</span> <span class="string">/etc/group</span> <span class="string">-p</span> <span class="string">wa</span> <span class="string">-k</span> <span class="string">identity</span></span><br><span class="line"><span class="string">-w</span> <span class="string">/etc/passwd</span> <span class="string">-p</span> <span class="string">wa</span> <span class="string">-k</span> <span class="string">identity</span></span><br><span class="line"><span class="string">-w</span> <span class="string">/etc/gshadow</span> <span class="string">-p</span> <span class="string">wa</span> <span class="string">-k</span> <span class="string">identity</span></span><br><span class="line"><span class="string">-w</span> <span class="string">/etc/shadow</span> <span class="string">-p</span> <span class="string">wa</span> <span class="string">-k</span> <span class="string">identity</span></span><br><span class="line"><span class="string">-w</span> <span class="string">/etc/security/opasswd</span> <span class="string">-p</span> <span class="string">wa</span> <span class="string">-k</span> <span class="string">identity</span></span><br><span class="line"><span class="string">-w</span> <span class="string">/etc/sudoers</span> <span class="string">-p</span> <span class="string">wa</span> <span class="string">-k</span> <span class="string">scope</span></span><br><span class="line"><span class="string">-w</span> <span class="string">/etc/sudoers.d/</span> <span class="string">-p</span> <span class="string">wa</span> <span class="string">-k</span> <span class="string">scope</span></span><br></pre></td></tr></table></figure><p>启动audit服务</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart auditd</span><br></pre></td></tr></table></figure><p>（在通过rsyslog或者filebeat等收集工具将<code>/var/log/audit/audit.log</code>统一收集存储）</p>]]></content>
      
      
      <categories>
          
          <category> 等保 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 等保 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python_docx依次读取word文档中的文本与表格</title>
      <link href="/python/pythonx_docx-read-all-word/"/>
      <url>/python/pythonx_docx-read-all-word/</url>
      
        <content type="html"><![CDATA[<blockquote><p>因为要文档数量太多,所以使用python_docx批量读取word文档中的文本与表格</p></blockquote><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul><li>Mac</li><li>Python 3.5.6</li><li>python_docx</li></ul><h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo pip install -i https://pypi.tuna.tsinghua.edu.cn/simple python_docx</span><br></pre></td></tr></table></figure><h3 id="Python脚本"><a href="#Python脚本" class="headerlink" title="Python脚本"></a>Python脚本</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> docx</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> docx.document <span class="keyword">import</span> Document</span><br><span class="line"><span class="keyword">from</span> docx.oxml.table <span class="keyword">import</span> CT_Tbl</span><br><span class="line"><span class="keyword">from</span> docx.oxml.text.paragraph <span class="keyword">import</span> CT_P</span><br><span class="line"><span class="keyword">from</span> docx.table <span class="keyword">import</span> _Cell, Table</span><br><span class="line"><span class="keyword">from</span> docx.text.paragraph <span class="keyword">import</span> Paragraph</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iter_block_items</span><span class="params">(parent)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Yield each paragraph and table child within *parent*, in document order.</span></span><br><span class="line"><span class="string">    Each returned value is an instance of either Table or Paragraph. *parent*</span></span><br><span class="line"><span class="string">    would most commonly be a reference to a main Document object, but</span></span><br><span class="line"><span class="string">    also works for a _Cell object, which itself can contain paragraphs and tables.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(parent, Document):</span><br><span class="line">        parent_elm = parent.element.body</span><br><span class="line">    <span class="keyword">elif</span> isinstance(parent, _Cell):</span><br><span class="line">        parent_elm = parent._tc</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"something's not right"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> child <span class="keyword">in</span> parent_elm.iterchildren():</span><br><span class="line">        <span class="keyword">if</span> isinstance(child, CT_P):</span><br><span class="line">            <span class="keyword">yield</span> Paragraph(child, parent)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(child, CT_Tbl):</span><br><span class="line">            <span class="keyword">yield</span> Table(child, parent)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_table</span><span class="params">(table)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [[cell.text <span class="keyword">for</span> cell <span class="keyword">in</span> row.cells] <span class="keyword">for</span> row <span class="keyword">in</span> table.rows]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_word</span><span class="params">(word_path)</span>:</span></span><br><span class="line">    doc = docx.Document(word_path)</span><br><span class="line">    <span class="keyword">for</span> block <span class="keyword">in</span> iter_block_items(doc):</span><br><span class="line">        <span class="keyword">if</span> isinstance(block, Paragraph):</span><br><span class="line">            print(<span class="string">"text"</span>, [block.text])</span><br><span class="line">        <span class="keyword">elif</span> isinstance(block, Table):</span><br><span class="line">            print(<span class="string">"table"</span>, read_table(block))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    ROOT_DIR_P = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))  <span class="comment"># 项目根目录</span></span><br><span class="line">    word_path = os.path.join(ROOT_DIR_P, <span class="string">"data/test_to_word.docx"</span>)  <span class="comment"># pdf文件路径及文件名</span></span><br><span class="line">    <span class="comment"># word_path = os.path.join(ROOT_DIR_P, "data/test_to_word2.docx")  # pdf文件路径及文件名</span></span><br><span class="line">    read_word(word_path)</span><br></pre></td></tr></table></figure><h3 id="执行效果"><a href="#执行效果" class="headerlink" title="执行效果"></a>执行效果</h3><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/python/python_docx-word.png" alt="python_docx-word"></p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/python/python_docx-result.png" alt="python_docx-result"></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> docx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac用Python批量将doc转换为docx</title>
      <link href="/python/libreoffice-doc-to-docx/"/>
      <url>/python/libreoffice-doc-to-docx/</url>
      
        <content type="html"><![CDATA[<blockquote><p>因为要批量处理文档,但python_docx不支持doc格式,所以使用Python批量将doc转换为docx</p></blockquote><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul><li><p>Mac</p></li><li><p>Python 3.5.6</p></li></ul><h3 id="安装LibreOffice"><a href="#安装LibreOffice" class="headerlink" title="安装LibreOffice"></a>安装LibreOffice</h3><p><a href="https://www.libreoffice.org/download/download/" target="_blank" rel="noopener">下载地址</a></p><p>安装后将软件放到Applications中</p><h3 id="执行测试"><a href="#执行测试" class="headerlink" title="执行测试"></a>执行测试</h3><p>执行命令后目录下将会出现一个1146.docx的文件，然后就可以使用python_docx处理word了</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ /Applications/LibreOffice.app/Contents/MacOS/soffice --headless --convert-to docx /Users/see/documents/1146.doc --outdir /Users/see/documents/</span><br></pre></td></tr></table></figure><h3 id="Python批量执行"><a href="#Python批量执行" class="headerlink" title="Python批量执行"></a>Python批量执行</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line">source = <span class="string">"/Users/see/documents/doc"</span></span><br><span class="line">dest = <span class="string">"/Users/see/documents/docx"</span></span><br><span class="line">g = os.walk(source)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> path,dir_list,file_list <span class="keyword">in</span> g:</span><br><span class="line">  <span class="keyword">for</span> file_name <span class="keyword">in</span> file_list:</span><br><span class="line">    file = (os.path.join(path, file_name) )</span><br><span class="line">    <span class="keyword">print</span> (file)</span><br><span class="line">    output = subprocess.check_output([<span class="string">"/Applications/LibreOffice.app/Contents/MacOS/soffice"</span>,<span class="string">"--headless"</span>,<span class="string">"--convert-to"</span>,<span class="string">"docx"</span>,file,<span class="string">"--outdir"</span>,dest])</span><br></pre></td></tr></table></figure><p>执行脚本即可</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> docx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>脚本自动化压缩图片+上传PicGo指定目录+jsDelivrCDN</title>
      <link href="/hexo/hexo-picgo-cdn-shell/"/>
      <url>/hexo/hexo-picgo-cdn-shell/</url>
      
        <content type="html"><![CDATA[<blockquote><p>   ​    因PicGo只能将所有图片上传到单个目录下,强迫症的我感觉管理比较<code>混乱</code>,所以写了个脚本自动<code>压缩图片</code>并调用PicGo API上传到Github<code>指定目录</code>下,配合jsDelivr 为图片增加<code>CDN</code>功能</p><p>   ​    适合自己的才是最好的,每个人习惯不同,所以这里仅是自己的做法。</p></blockquote><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><blockquote><p>效果是每种类型的图片全部分目录存储</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-github%E7%9B%AE%E5%BD%95%E5%B1%95%E7%A4%BA.png" alt="hexo-picgo-github目录展示"></p><h3 id="所需环境"><a href="#所需环境" class="headerlink" title="所需环境"></a>所需环境</h3><table><thead><tr><th align="center">名称</th><th align="center">用途</th><th align="center">参考</th></tr></thead><tbody><tr><td align="center">Github新仓库</td><td align="center">存放图片的图床</td><td align="center"><a href="https://help.github.com/cn/github/getting-started-with-github/create-a-repo" target="_blank" rel="noopener">链接</a></td></tr><tr><td align="center">PicGo</td><td align="center">上传图片的图床软件</td><td align="center"><a href="https://picgo.github.io/PicGo-Doc/zh/guide/advance.html#picgo-server%E7%9A%84%E4%BD%BF%E7%94%A8" target="_blank" rel="noopener">链接</a></td></tr><tr><td align="center">Exiftool</td><td align="center">图片元信息查询工具</td><td align="center"><a href="https://www.jianshu.com/p/d76457799de1" target="_blank" rel="noopener">链接</a></td></tr><tr><td align="center">Imageoptim</td><td align="center">图片压缩工具</td><td align="center"><a href="https://imageoptim.com/howto.html" target="_blank" rel="noopener">链接1</a>,<a href="https://www.npmjs.com/package/imageoptim-cli" target="_blank" rel="noopener">链接2</a></td></tr></tbody></table><h3 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h3><ol><li><p>创建好新的Github图床仓库</p></li><li><p>申请Github的<code>Access Token</code></p></li><li><p>配置好PicGo的<code>Github图床参数</code>  #以上三步可以参考<a href="https://segmentfault.com/a/1190000020240864" target="_blank" rel="noopener">沧海一粟</a></p></li><li><p>在<code>PicGo设置</code> –&gt; <code>设置Server</code> 里打开Server, 默认监听<code>127.0.0.1:36677</code></p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-%E5%BC%80%E5%90%AFServer%E7%9B%91%E5%90%AC.png" alt="hexo-picgo-开启Server监听"></p></li></ol><ol start="5"><li><p>安装图片压缩工具</p><ol><li>安装imageoptim<code>客户端</code>, 去官网下载安装 <a href="https://imageoptim.com/howto.html" target="_blank" rel="noopener">下载地址</a></li><li>安装imageoptim<code>命令行工具</code></li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g imageoptim-cli</span><br></pre></td></tr></table></figure></li><li><p>安装exiftool</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brew install exiftool</span><br></pre></td></tr></table></figure></li><li><p>部署<code>upload-images.sh</code>脚本 (见下文)</p></li></ol><h3 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h3><blockquote><p>图片URL 结构为： <a href="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-开启Server监听.png" target="_blank" rel="noopener">https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-开启Server监听.png</a></p><p> <a href="https://cdn.jsdelivr.net/gh/：" target="_blank" rel="noopener">https://cdn.jsdelivr.net/gh/：</a> CDN地址</p><p> sungaomeng：Github用户名</p><p> blog-images：Github图床仓库名称</p><p> img：图片一级目录(脚本里写死了,可自行修改)</p><p> hexo：执行脚本时的<code>$1</code></p><p> *.png：图片名</p></blockquote><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192:blog See$ cat upload-images.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> != 2 ] ; <span class="keyword">then</span></span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"USAGE: <span class="variable">$0</span> from to"</span></span><br><span class="line"> <span class="built_in">echo</span> <span class="string">" e.g.: <span class="variable">$0</span> GithubFolder ImageFile"</span></span><br><span class="line"> <span class="built_in">exit</span> 1;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">Folder=<span class="variable">$1</span></span><br><span class="line">File=<span class="variable">$2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#文件压缩</span></span><br><span class="line"><span class="comment">#防止多次压缩浪费时间,判断文件是否包含imageoptim标签,如果不存在则压缩并打上imageoptim标签</span></span><br><span class="line"><span class="keyword">if</span> ! $(exiftool <span class="variable">$File</span>|grep imageoptim &gt;/dev/null)</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  imageoptim <span class="variable">$File</span></span><br><span class="line">  exiftool -artist=imageoptim <span class="variable">$File</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#判断配置的目录跟传参的目录是否匹配</span></span><br><span class="line"><span class="keyword">if</span> ! $(grep <span class="string">'"path": "img/'</span><span class="variable">$Folder</span><span class="string">'/"'</span> ~/Library/Application\ Support/picgo/data.json &gt; /dev/null)</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  <span class="comment">#修改上传目录</span></span><br><span class="line">   sed -i <span class="string">""</span> <span class="string">"/\"path\": /s/img\/.*,/img\/<span class="variable">$Folder</span>\/\",/"</span> ~/Library/Application\ Support/picgo/data.json</span><br><span class="line"></span><br><span class="line">  <span class="comment">#重启picgo</span></span><br><span class="line">  pkill PicGo;sleep 0.5;open -a picgo</span><br><span class="line">  sleep 3</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#上传文件</span></span><br><span class="line">Result=$(curl -s -X POST \</span><br><span class="line">  http://127.0.0.1:36677/upload \</span><br><span class="line">  -H <span class="string">'cache-control: no-cache'</span> \</span><br><span class="line">  -H <span class="string">'content-type: application/json'</span> \</span><br><span class="line">  -H <span class="string">'postman-token: 7cff6cbb-e90f-584c-9621-034df7c9d21f'</span> \</span><br><span class="line">  -d <span class="string">'&#123;</span></span><br><span class="line"><span class="string"> "list": [</span></span><br><span class="line"><span class="string">     "'</span><span class="variable">$File</span><span class="string">'"</span></span><br><span class="line"><span class="string">     ]</span></span><br><span class="line"><span class="string">&#125;'</span>)</span><br><span class="line"></span><br><span class="line">ImageUrl=$(<span class="built_in">echo</span> <span class="variable">$Result</span>|awk -F<span class="string">'"'</span> <span class="string">'&#123;print $6&#125;'</span>)</span><br><span class="line">ImageName=$(<span class="built_in">echo</span> <span class="variable">$ImageUrl</span>|awk -F<span class="string">'[/|\.]'</span> <span class="string">'&#123;print $11&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"![<span class="variable">$ImageName</span>](<span class="variable">$ImageUrl</span>)"</span></span><br></pre></td></tr></table></figure><h3 id="执行过程"><a href="#执行过程" class="headerlink" title="执行过程"></a>执行过程</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192:blog See$ sh -x upload-images.sh  hexo ~/Downloads/hexo-picgo-开启Server监听.png</span><br><span class="line">+ <span class="string">'['</span> 2 <span class="string">'!='</span> 2 <span class="string">']'</span></span><br><span class="line">+ Folder=hexo</span><br><span class="line">+ File=$<span class="string">'/Users/see/Downloads/hexo-picgo-开启Server监听.png'</span></span><br><span class="line">++ exiftool $<span class="string">'/Users/see/Downloads/hexo-picgo-开启Server监听.png'</span></span><br><span class="line">++ grep imageoptim</span><br><span class="line">+ imageoptim $<span class="string">'/Users/see/Downloads/hexo-picgo-开启Server监听.png'</span></span><br><span class="line">i Running ImageOptim...</span><br><span class="line">✓ /Users/see/Downloads/hexo-picgo-开启Server监听.png was: 146kB now: 68.7kB saving: 77.3kB (52.96%)</span><br><span class="line">✓ TOTAL was: 146kB now: 68.7kB saving: 77.3kB (52.96%)</span><br><span class="line">✓ Finished</span><br><span class="line">+ exiftool -artist=imageoptim $<span class="string">'/Users/see/Downloads/hexo-picgo-开启Server监听.png'</span></span><br><span class="line">    1 image files updated</span><br><span class="line">++ grep <span class="string">'"path": "img/hexo/"'</span> <span class="string">'/Users/see/Library/Application Support/picgo/data.json'</span></span><br><span class="line">+ sed -i <span class="string">''</span> <span class="string">'/"path": /s/img\/.*\//img\/hexo\//'</span> <span class="string">'/Users/see/Library/Application Support/picgo/data.json'</span></span><br><span class="line">+ pkill PicGo</span><br><span class="line">+ sleep 0.5</span><br><span class="line">+ open -a picgo</span><br><span class="line">+ sleep 3</span><br><span class="line">+ curl -X POST http://127.0.0.1:36677/upload -H <span class="string">'cache-control: no-cache'</span> -H <span class="string">'content-type: application/json'</span> -H <span class="string">'postman-token: 7cff6cbb-e90f-584c-9621-034df7c9d21f'</span> -d <span class="string">'&#123;</span></span><br><span class="line"><span class="string"> "list": [</span></span><br><span class="line"><span class="string">     "/Users/see/Downloads/hexo-picgo-开启Server监听.png"</span></span><br><span class="line"><span class="string">     ]</span></span><br><span class="line"><span class="string">&#125;'</span></span><br><span class="line">+ Result=<span class="string">'&#123;"success":true,"result":["https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-开启Server监听.png"]&#125;'</span></span><br><span class="line">++ awk <span class="string">'-F"'</span> <span class="string">'&#123;print $6&#125;'</span></span><br><span class="line">++ <span class="built_in">echo</span> <span class="string">'&#123;"success":true,"result":["https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-开启Server监听.png"]&#125;'</span></span><br><span class="line">+ ImageUrl=$<span class="string">'https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-开启Server监听.png'</span></span><br><span class="line">++ <span class="built_in">echo</span> $<span class="string">'https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-开启Server监听.png'</span></span><br><span class="line">++ awk <span class="string">'-F[/|\.]'</span> <span class="string">'&#123;print $11&#125;'</span></span><br><span class="line">+ ImageName=$<span class="string">'hexo-picgo-开启Server监听.png'</span></span><br><span class="line">+ <span class="built_in">echo</span> <span class="string">'![Actions-Recovery配置](https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-开启Server监听.png)'</span></span><br><span class="line"></span><br><span class="line">![hexo-picgo-开启Server监听](https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/hexo/hexo-picgo-开启Server监听.png)</span><br><span class="line"></span><br><span class="line"><span class="comment">#最终输出Markdown格式URL</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> PicGo </tag>
            
            <tag> Shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python自动修复Shadowsocks科学上网服务</title>
      <link href="/python/check-lb-auto-repair/"/>
      <url>/python/check-lb-auto-repair/</url>
      
        <content type="html"><![CDATA[<blockquote><p><code>Python</code>自动修复基于阿里搭建的<code>Shadowsocks</code>科学上网服务</p><p>由于阿里经常封杀SS协议, 导致上网非常不稳定, 所以写了个脚本定时自动修复</p><p>但目前发现<strong>封的特别快</strong>, 要想拥有一个<strong>特别稳定</strong>的环境, 建议还是用<strong>微软Azure</strong>,  利用<code>虚拟网络网关</code>打通<code>国际Azure香港节点</code>和<code>国内Azure北京节点</code>, 但这个收费就高了, 每个月得两三千, 如果不是业务强需求还是别搞了</p></blockquote><h5 id="本项目地址-GitHub"><a href="#本项目地址-GitHub" class="headerlink" title="本项目地址 GitHub"></a>本项目地址 <a href="https://github.com/sungaomeng/ssproxy-repair" target="_blank" rel="noopener">GitHub</a></h5><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul><li><p>在阿里云新加坡地区购买了一台低配ECS,搭建了Ss服务端</p></li><li><p>由于阿里云经常封杀SS协议对应的公网入口，所以我把入口调整为临时的公网负载均衡 (这样封杀的时候就是封杀的负载均衡了)</p></li><li><p>脚本检测到负载均衡的端口或者IP被封后, 会自动创建一个新的负载均衡并建立监听端口, 然后更新DNS及Hosts记录并删除旧负载均衡</p></li><li><p>一套流程下来, 虽然有一定的延时, 但基本能自动化操作修复, 不用人为干预了。</p><h3 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h3></li><li><p>全部基于阿里云</p></li><li><p>阿里云ECS、负载均衡、云解析DNS</p><h3 id="脚本流程"><a href="#脚本流程" class="headerlink" title="脚本流程"></a>脚本流程</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">├── README.md</span><br><span class="line">├── requirements.txt</span><br><span class="line">├── check.py <span class="comment"># 检查相关函数, 检查域名的端口是否正常,通过域名解析IP</span></span><br><span class="line">├── dns.py   <span class="comment"># 阿里云云解析DNS相关函数, 查询/修改DNS记录, 更新本地Hosts</span></span><br><span class="line">├── main.py  <span class="comment"># 主程序入口,集合其他脚本函数</span></span><br><span class="line">└── slb.py   <span class="comment"># 阿里云负载均衡相关函数, 创建/删除负载均衡,创建/启动监听端口,添加后端服务器</span></span><br><span class="line"></span><br><span class="line">0 directories, 6 files</span><br></pre></td></tr></table></figure></li></ul><ol><li><p><code>main.py</code>中定义阿里云相关变量及<code>host</code>变量 (负载均衡公网IP对应的域名 或者直接写IP，如果写IP请注释DNS相关函数调用，建议用域名)</p></li><li><p>检查域名对应端口是否正常，正常则<code>退出</code>，否则<code>新建负载均衡</code>、<code>添加后端服务器</code>、<code>建立监听</code>、<code>启动监听</code></p></li><li><p>等待<code>10s</code>后<strong>再次检查</strong>新负载均衡的IP对应端口是否正常，正常则<code>删除旧负载均衡</code>并<code>更新DNS</code>及<code>本地Hosts</code>后退出，否则打印log后退出</p><blockquote><p>更新本地Hosts的原因是 方式再下一轮检测LB时DNS还没完全更新, 导致一直创建删除LB</p></blockquote></li></ol><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><ul><li>Python 3 (我的环境是3.5.2)</li><li>Crontab</li><li>以及一些python依赖见<code>requirements.txt</code></li></ul><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/sungaomeng/ssproxy-repair.git</span><br><span class="line">$ pip install -r ssproxy-repair/requirements.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 校时</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"* * * * * /usr/sbin/ntpdate ntp.aliyun.com"</span> &gt;&gt; /var/spool/<span class="variable">$User</span></span><br><span class="line"><span class="comment"># 每半小时执行一次检查</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"*/30 * * * * /usr/bin/python /root/ssproxy-repair/main.py &gt;&gt; /tmp/ssproxy-repair.log 2&gt;&amp;1"</span> &gt;&gt; /var/spool/<span class="variable">$User</span></span><br></pre></td></tr></table></figure><h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>目前并没有输出到log, 仅是打印到前台</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Domain:ss.roobo.net HostIp:161.**.**.186 Port:8388 is not open, return code：35</span><br><span class="line">Prepare to create a new load balancing, Please wait ...</span><br><span class="line">New LoadBalancer:lb-t4nupa5f9w2ynfzsqkjo1 create successful.</span><br><span class="line">New LoadBalancer:lb-t4nupa5f9w2ynfzsqkjo1 add backendserver:i-t4n190***y3d0 successful.</span><br><span class="line">New LoadBalancer:lb-t4nupa5f9w2ynfzsqkjo1 create listener port:8388 successful.</span><br><span class="line">New LoadBalancer:lb-t4nupa5f9w2ynfzsqkjo1 start listener port:8388 successful.</span><br><span class="line">Wait 10 seconds to check the new load balancing again ...</span><br><span class="line">New LoadBalancer:161.**.**.196 Port:8388 is open</span><br><span class="line">Old LoadBalancer:lb-t4n9hdg5***houyedj delete successful.</span><br><span class="line">DNS update record successful domain:ss.test.com, old ip:161.**.**.186, new ip:161.**.**.196</span><br><span class="line">Hosts update record successful domain:ss.test.com, new ip:161.**.**.196</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Shadowsocks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zabbix告警收敛/合并/压缩</title>
      <link href="/zabbix/zabbix-alarm-convergence-compression/"/>
      <url>/zabbix/zabbix-alarm-convergence-compression/</url>
      
        <content type="html"><![CDATA[<h1 id="zabbix告警收敛-合并-压缩"><a href="#zabbix告警收敛-合并-压缩" class="headerlink" title="zabbix告警收敛/合并/压缩"></a>zabbix告警收敛/合并/压缩</h1><blockquote><p>由于报警短信、邮件太多导致运维人员精神高度紧张、时间长了容易忽略重要告警，引起不必要的麻烦。为了解决这个问题我在网上开始搜索 <code>告警收敛/告警合并/告警压缩</code>相关的文章尝试解决，最终受益于”<code>简述</code>“大神的这篇文章 “<a href="https://www.jianshu.com/p/b29cf0682b58" target="_blank" rel="noopener">zabbix 告警 | 告警收敛</a>“ 的思路，于是基于大神的代码主体框架进行了大量修改并已应用于我们公司环境中一年以上。</p></blockquote><p>下面为大家分享下整体的流程以及代码。</p><h2 id="一、架构图"><a href="#一、架构图" class="headerlink" title="一、架构图"></a>一、架构图</h2><p>①产生的所有告警均由<code>zabbix</code>的<code>actions</code>调用脚本推入缓存<code>redis</code>当中；<br>②脚本将每分钟(<code>crontab</code>)去<code>redis</code>中拉取数据，根据定义好的一系列规则进行分析、合并；<br>③根据预先定义好的规则将报警通过定义好的方式发送给相关人员；<br><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="zabbix收敛-流程图"></p><h2 id="二、设置Zabbix"><a href="#二、设置Zabbix" class="headerlink" title="二、设置Zabbix"></a>二、设置Zabbix</h2><h3 id="1-配置Media-types"><a href="#1-配置Media-types" class="headerlink" title="1. 配置Media types"></a>1. 配置Media types</h3><ul><li>仅传递<code>subject</code></li><li>我这里定义了<code>3个Mediatype</code> 分别用于发送<strong>邮件、短信、企业微信</strong>(具体可自行调整) （3个除了Name不一样之外其他配置(<code>Script name</code>/<code>Script parameters</code>)保持一致）</li><li>脚本 “<code>zabbix-police/police.py</code>” 主要功能是将Subject(Eventid)写入<code>Redis</code>，后面会写到<br><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-Mediatype%E9%85%8D%E7%BD%AE.png" alt="Media type 配置"><br><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-%E5%A4%9A%E4%B8%AAMediatypes.png" alt="zabbix收敛-多个Mediatypes"></li></ul><h3 id="2-配置Actions"><a href="#2-配置Actions" class="headerlink" title="2. 配置Actions"></a>2. 配置Actions</h3><ul><li>我这里以<strong>每个<code>Trigger severity</code>一个<code>Actions</code></strong>举例。（可以根据不同的HostGroup或者其他条件自行配置多个actions）</li><li><code>Default subject</code> 之所以用 “<code>{EVENT.ID}_1、{EVENT.ID}_0</code>“为的是保持唯一性，<strong>1代表故障、0代表恢复</strong></li><li>Default sbject<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;EVENT.ID&#125;_1</span><br></pre></td></tr></table></figure></li><li>Default message<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">triggervalue|&#123;TRIGGER.VALUE&#125;</span><br><span class="line">hostname|&#123;HOSTNAME1&#125;</span><br><span class="line">ipaddress|&#123;IPADDRESS&#125;</span><br><span class="line">hostgroup|&#123;TRIGGER.HOSTGROUP.NAME&#125;</span><br><span class="line">triggerstatus|&#123;TRIGGER.STATUS&#125;</span><br><span class="line">triggerseverity|&#123;TRIGGER.SEVERITY&#125;</span><br><span class="line">triggername|&#123;TRIGGER.NAME&#125;</span><br><span class="line">triggerkey|&#123;TRIGGER.KEY1&#125;</span><br><span class="line">triggeritems|&#123;ITEM.NAME&#125;</span><br><span class="line">itemvalue|&#123;ITEM.VALUE&#125;</span><br><span class="line">eventid|&#123;EVENT.ID&#125;</span><br><span class="line">action|&#123;ACTION.NAME&#125;</span><br><span class="line">eventage|&#123;EVENT.AGE&#125;</span><br><span class="line">eventtime|&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;</span><br></pre></td></tr></table></figure></li><li>Recovery subject<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;EVENT.ID&#125;_0</span><br></pre></td></tr></table></figure></li><li>Recovery message<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">triggervalue|&#123;TRIGGER.VALUE&#125;</span><br><span class="line">hostname|&#123;HOSTNAME1&#125;</span><br><span class="line">ipaddress|&#123;IPADDRESS&#125;</span><br><span class="line">hostgroup|&#123;TRIGGER.HOSTGROUP.NAME&#125;</span><br><span class="line">triggerstatus|&#123;TRIGGER.STATUS&#125;</span><br><span class="line">triggerseverity|&#123;TRIGGER.SEVERITY&#125;</span><br><span class="line">triggername|&#123;TRIGGER.NAME&#125;</span><br><span class="line">triggerkey|&#123;TRIGGER.KEY1&#125;</span><br><span class="line">triggeritems|&#123;ITEM.NAME&#125;</span><br><span class="line">itemvalue|&#123;ITEM.VALUE&#125;</span><br><span class="line">eventid|&#123;EVENT.ID&#125;</span><br><span class="line">action|&#123;ACTION.NAME&#125;</span><br><span class="line">eventage|&#123;EVENT.AGE&#125;</span><br><span class="line">eventtime|&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-%E5%A4%9A%E4%B8%AAActions.png" alt="zabbix收敛-多个Actions"><br><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-Actions-%E6%9D%A1%E4%BB%B6%E9%85%8D%E7%BD%AE.png" alt="zabbix收敛-Actions-条件配置"><br><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-Actions-Operations%E9%85%8D%E7%BD%AE.png" alt="zabbix收敛-Actions-Operations配置"><br><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-Actions-Recovery%E9%85%8D%E7%BD%AE.png" alt="zabbix收敛-Actions-Recovery配置"></p><h2 id="三、配置-Zabbix-服务器"><a href="#三、配置-Zabbix-服务器" class="headerlink" title="三、配置 Zabbix 服务器"></a>三、配置 Zabbix 服务器</h2><h3 id="1-安装环境"><a href="#1-安装环境" class="headerlink" title="1. 安装环境"></a>1. 安装环境</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载代码</span></span><br><span class="line">/etc/zabbix/alertscripts</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/sungaomeng/zabbix-police.git</span><br><span class="line"><span class="comment">#安装依赖</span></span><br><span class="line">yum install gcc python-devel</span><br><span class="line">pip install -r zabbix-police/requirements.txt</span><br></pre></td></tr></table></figure><h3 id="2-脚本"><a href="#2-脚本" class="headerlink" title="2. 脚本"></a>2. 脚本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#文件分布</span></span><br><span class="line">[root@zabbix-server01 alertscripts]$ tree zabbix-police </span><br><span class="line">zabbix-police</span><br><span class="line">├── police.py    <span class="comment">#Action调用此函数, 用于将EventID写入Redis</span></span><br><span class="line">├── allpolice.py <span class="comment">#综合函数, 总入口, 用于整合其他脚本, 定时被Crontab调用</span></span><br><span class="line">├── dbread.py    <span class="comment">#数据库查询函数, 用于查询Redis、Mysql, 获取EventID、获取告警具体信息、Mediatype脚本对应关系、查询告警接收人等信息</span></span><br><span class="line">├── police.conf  <span class="comment">#定义配置文件, 包括mysql、redis、wechat、email、sms、logfile等配置</span></span><br><span class="line">├── modconf.py   <span class="comment">#加载配置函数, 用于加载配置文件</span></span><br><span class="line">├── operation.py <span class="comment">#操作函数, 用于1. 接收dbread.py返回的告警、恢复信息, 进行合并、压缩处理, 并返回处理结果 2. 定义各告警发送调用函数</span></span><br><span class="line">├── send_wechat.py <span class="comment">#告警发送-微信函数</span></span><br><span class="line">├── send_sms.py    <span class="comment">#告警发送-短信函数</span></span><br><span class="line">├── send_email.py  <span class="comment">#告警发送-邮件函数</span></span><br><span class="line">├── requirements.txt <span class="comment">#依赖</span></span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure><h3 id="3-Crontab"><a href="#3-Crontab" class="headerlink" title="3. Crontab"></a>3. Crontab</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@zabbix-server01 zabbix-police]$ crontab -l </span><br><span class="line">* * * * * /usr/bin/python /etc/zabbix/alertscripts/zabbix-police/allpolice.py</span><br></pre></td></tr></table></figure><h2 id="四、告警效果"><a href="#四、告警效果" class="headerlink" title="四、告警效果"></a>四、告警效果</h2><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6.png" alt="zabbix收敛-邮件告警"></p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E5%91%8A%E8%AD%A6.png" alt="zabbix收敛-企业微信告警"><br><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/zabbix/zabbix%E6%94%B6%E6%95%9B-%E7%9F%AD%E4%BF%A1%E5%91%8A%E8%AD%A6.png" alt="zabbix收敛-短信告警"></p>]]></content>
      
      
      <categories>
          
          <category> Zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus-Operator 安装</title>
      <link href="/prometheus/install-prometheus-operator/"/>
      <url>/prometheus/install-prometheus-operator/</url>
      
        <content type="html"><![CDATA[<blockquote><p>记录自己安装 Prometheus Operator 的过程</p></blockquote><h3 id="一、Prometheus-Operator-介绍"><a href="#一、Prometheus-Operator-介绍" class="headerlink" title="一、Prometheus Operator 介绍"></a>一、Prometheus Operator 介绍</h3><p>kubernetes的监控系统Prometheus 应该都比较了解, 简述以下几点吧</p><h4 id="1-Prometheus-简介"><a href="#1-Prometheus-简介" class="headerlink" title="1. Prometheus 简介"></a>1. Prometheus 简介</h4><h5 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h5><p>&nbsp;Prometheus 由多个组件组成，但是其中许多组件是可选的：</p><ul><li>Prometheus Server：用于抓取指标、存储时间序列数据</li><li>exporter：暴露指标让任务来抓</li><li>pushgateway：push 的方式将指标数据推送到该网关</li><li>alertmanager：处理报警的报警组件</li><li>adhoc：用于数据查询<h5 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h5>下图是 Prometheus 官方提供的架构及其一些相关的生态系统组件：<br><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/prometheus/prometheus-%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="prometheus-架构图"></li></ul><h4 id="2-Operator-简介"><a href="#2-Operator-简介" class="headerlink" title="2. Operator 简介"></a>2. Operator 简介</h4><p>Operator 是 CoreOS 推出的旨在简化复杂有状态应用管理的框架，它是一个感知应用状态的控制器，通过扩展 Kubernetes API 来自动创建、管理和配置应用实例。</p><p>你可以在 <a href="https://www.operatorhub.io/" target="_blank" rel="noopener">OperatorHub.io</a> 上查看 Kubernetes 社区推荐的一些 Operator 范例。</p><h4 id="operator-架构图"><a href="#operator-架构图" class="headerlink" title="operator 架构图"></a>operator 架构图</h4><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/prometheus/prometheus-operator-%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="prometheus-operator-架构图"></p><h3 id="二、安装依赖"><a href="#二、安装依赖" class="headerlink" title="二、安装依赖"></a>二、安装依赖</h3><h4 id="安装Helm"><a href="#安装Helm" class="headerlink" title="安装Helm"></a>安装Helm</h4><h5 id="1-下载Helm"><a href="#1-下载Helm" class="headerlink" title="1. 下载Helm"></a>1. 下载Helm</h5><p>Hlem版本我使用的是当前2版本中的最新版 2.16.7，因为官方建议使用2.14以上版本, 不然会有CRD相关问题, 具体见Github <a href="https://github.com/helm/charts/tree/master/stable/prometheus-operator" target="_blank" rel="noopener">prometheus-operator</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://storage.googleapis.com/kubernetes-helm/helm-v2.16.7-linux-amd64.tar.gz</span><br><span class="line">tar zxvf helm-v2.16.7-linux-amd64.tar.gz</span><br><span class="line">mv linux-amd64/helm linux-amd64/tiller /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">helm version</span><br></pre></td></tr></table></figure><h5 id="2-创建RBAC"><a href="#2-创建RBAC" class="headerlink" title="2. 创建RBAC"></a>2. 创建RBAC</h5><p>创建文件rbac-tiller.yaml , 内容为下</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure><p>创建RBAC</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f rbac-tiller.yaml</span><br></pre></td></tr></table></figure><h5 id="2-初始化Helm"><a href="#2-初始化Helm" class="headerlink" title="2. 初始化Helm"></a>2. 初始化Helm</h5><p>因为默认下载gcr.io仓库的镜像, 由于墙的原因下载失败, 所以我下载后传到了我司仓库</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm init --service-account tiller --tiller-image registry.cn-beijing.aliyuncs.com/roobo/tiller:v2.16.7</span><br><span class="line">$ helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:<span class="string">"v2.16.7"</span>, GitCommit:<span class="string">"5f2584fd3d35552c4af26036f0c464191287986b"</span>, GitTreeState:<span class="string">"clean"</span>&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:<span class="string">"v2.16.7"</span>, GitCommit:<span class="string">"5f2584fd3d35552c4af26036f0c464191287986b"</span>, GitTreeState:<span class="string">"clean"</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="三、安装Prometheus-Operator"><a href="#三、安装Prometheus-Operator" class="headerlink" title="三、安装Prometheus-Operator"></a>三、安装Prometheus-Operator</h3><h4 id="1-创建Namespace"><a href="#1-创建Namespace" class="headerlink" title="1. 创建Namespace"></a>1. 创建Namespace</h4><p>(将相关PODs都创建到此NS下)</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubelet create ns monitoring</span><br></pre></td></tr></table></figure><h4 id="2-安装-prometheus-operator"><a href="#2-安装-prometheus-operator" class="headerlink" title="2. 安装 prometheus-operator"></a>2. 安装 prometheus-operator</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install --namespace monitoring  --name prometheus-operator stable/prometheus-operator</span><br></pre></td></tr></table></figure><h4 id="3-查看相关PODs"><a href="#3-查看相关PODs" class="headerlink" title="3. 查看相关PODs"></a>3. 查看相关PODs</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8smaster-01 ~]<span class="comment"># kubectl -n monitoring get po</span></span><br><span class="line">NAME                                                     READY     STATUS    RESTARTS   AGE</span><br><span class="line">alertmanager-prometheus-operator-alertmanager-0           2/2       Running   0          53m</span><br><span class="line">prometheus-operator-grafana-69bfccc949-h9s7x              2/2       Running   0          53m</span><br><span class="line">prometheus-operator-kube-state-metrics-7ddcbdb744-xzh9w   1/1       Running   0          53m</span><br><span class="line">prometheus-operator-operator-6d4f47dc49-9g9jr             2/2       Running   0          53m</span><br><span class="line">prometheus-operator-prometheus-node-exporter-h9c2p        1/1       Running   0          53m</span><br><span class="line">prometheus-operator-prometheus-node-exporter-jw2hn        1/1       Running   0          53m</span><br><span class="line">prometheus-operator-prometheus-node-exporter-mqq4p        1/1       Running   0          53m</span><br><span class="line">prometheus-operator-prometheus-node-exporter-zxcg5        1/1       Running   0          53m</span><br><span class="line">prometheus-prometheus-operator-prometheus-0               3/3       Running   1          53m</span><br><span class="line"></span><br><span class="line">[root@k8smaster-01 ~]<span class="comment"># kubectl -n monitoring get svc</span></span><br><span class="line">NAME                                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">alertmanager-operated                          ClusterIP   None            &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   53m</span><br><span class="line">prometheus-operated                            ClusterIP   None            &lt;none&gt;        9090/TCP                     53m</span><br><span class="line">prometheus-operator-alertmanager               ClusterIP   10.254.13.40    &lt;none&gt;        9093/TCP                     54m</span><br><span class="line">prometheus-operator-grafana                    ClusterIP   10.254.0.159    &lt;none&gt;        80/TCP                       54m</span><br><span class="line">prometheus-operator-kube-state-metrics         ClusterIP   10.254.43.177   &lt;none&gt;        8080/TCP                     54m</span><br><span class="line">prometheus-operator-operator                   ClusterIP   10.254.38.46    &lt;none&gt;        8080/TCP,443/TCP             54m</span><br><span class="line">prometheus-operator-prometheus                 ClusterIP   10.254.27.218   &lt;none&gt;        9090/TCP                     54m</span><br><span class="line">prometheus-operator-prometheus-node-exporter   ClusterIP   10.254.60.8     &lt;none&gt;        9100/TCP                     54m</span><br><span class="line"></span><br><span class="line">[root@k8smaster-01 ~]<span class="comment"># kubectl get crd</span></span><br><span class="line">NAME                                    CREATED AT</span><br><span class="line">alertmanagers.monitoring.coreos.com     2020-05-10T06:38:44Z</span><br><span class="line">podmonitors.monitoring.coreos.com       2020-05-10T06:38:51Z</span><br><span class="line">prometheuses.monitoring.coreos.com      2020-05-10T06:38:56Z</span><br><span class="line">prometheusrules.monitoring.coreos.com   2020-05-10T06:39:02Z</span><br><span class="line">servicemonitors.monitoring.coreos.com   2020-05-10T06:39:07Z</span><br><span class="line">thanosrulers.monitoring.coreos.com      2020-05-10T06:39:12Z</span><br></pre></td></tr></table></figure><h4 id="4-创建Ingress"><a href="#4-创建Ingress" class="headerlink" title="4. 创建Ingress"></a>4. 创建Ingress</h4><p>默认情况下Grafana并不能直接访问, 可以将svc改为NodePort方式或者创建Ingress 通过域名的方式访问到, 这里以Ingress举例</p><h5 id="Yaml文件"><a href="#Yaml文件" class="headerlink" title="Yaml文件"></a>Yaml文件</h5><p>(将$DOMAIN修改为自己的域名)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-prometheus-operator-grafana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">$DOMAIN</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">prometheus-operator-grafana</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><h3 id="四、效果图"><a href="#四、效果图" class="headerlink" title="四、效果图"></a>四、效果图</h3><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/prometheus/prometheus-grafana-%E9%A6%96%E9%A1%B5%E6%95%88%E6%9E%9C%E5%9B%BE.png" alt="prometheus-grafana-首页效果图"></p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/prometheus/prometheus-grafana-pod%E6%95%88%E6%9E%9C%E5%9B%BE.png" alt="prometheus-grafana-pod效果图"></p><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/prometheus/prometheus-grafana-cluter%E6%95%88%E6%9E%9C%E5%9B%BE.png" alt="prometheus-grafana-cluter效果图"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里云经典网络私有DNS服务(内网DNS)方案</title>
      <link href="/dns/aliyun-classic-network-private-dns/"/>
      <url>/dns/aliyun-classic-network-private-dns/</url>
      
        <content type="html"><![CDATA[<blockquote><p>分享在阿里云经典网络里建立私有DNS服务的整个历程和方法<br>因为在阿里云经典网络里是没有私有DNS服务的,  只有专有网络有,  但我们迁移至专有网络是一个漫长的过程, 所以临时通过这种方案解决DNS需求</p></blockquote><h3 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h3><ul><li>有内网Host需求的全部通过绑定Hosts访问(/etc/hosts)</li></ul><h3 id="痛点"><a href="#痛点" class="headerlink" title="痛点"></a>痛点</h3><ul><li>需要手动修改hosts文件</li><li>维护麻烦易出错</li><li>docker环境还需要单独给每个pod添加hosts适配,不能做到统一管理</li></ul><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><ul><li><p>统一管理域名映射关系</p></li><li><p>最好是WEB界面管理</p></li><li><p>基础服务要保证稳定</p></li><li><p>支持”<a href="https://help.aliyun.com/document_detail/107125.html" target="_blank" rel="noopener">递归解析代理</a>“</p><ul><li>因为我们有相同域名内外网解析到不同IP的场景(最开始没有规划好)</li><li>比如api.aliyun.com <ul><li>公网解析到的是1.1.1.1(公网负载均衡)</li><li>内网配置的hosts是10.1.1.1(内网负载均衡)</li></ul></li></ul></li></ul><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>  起初想自建BIND提供DNS服务,不过简单测试了下BIND,发现BIND并不能满足我的需求:<strong>不支持递归解析代理功能</strong>, 因为BIND的Zone是由本地完全代理解析的,如果本地Zone配置里不存在对应的记录就会返回不存在,不会再去公网上去找结果并返回.(望大神指点)</p><p>  举个栗子🌰:</p><p>  例如，Zone名称为<strong>aliyun.com</strong>,在<strong>aliyun.com</strong>内配置了三条私有记录，如下表所示：</p><table><thead><tr><th align="left">主机记录</th><th align="left">类型</th><th align="left">TTL</th><th align="left">记录值</th></tr></thead><tbody><tr><td align="left">host01</td><td align="left">A</td><td align="left">60</td><td align="left">10.0.0.1</td></tr><tr><td align="left">host02</td><td align="left">A</td><td align="left">60</td><td align="left">10.0.0.2</td></tr><tr><td align="left">host03</td><td align="left">A</td><td align="left">60</td><td align="left">10.0.0.3</td></tr></tbody></table><ul><li>在VPC内查询 <code>host01.aliyun.com</code>,<code>host02.aliyun.com</code> 或者 <code>host03.aliyun.com</code>时，分别返回私有记录<code>10.0.0.1</code>,<code>10.0.0.2</code>,<code>10.0.0.3</code>。</li><li>在VPC内查询 <code>www.aliyun.com</code>, <code>api.aliyun.com</code> ,<code>rds.aliyun.com</code>等公共域名时，进行<strong>递归查询</strong>，以互联网实际域名解析结果为最终DNS解析结果。</li></ul><p>​    现在各大云厂商都支持内网DNS解析，阿里云现在也出了<code>PrivateZone</code>服务,不过是<code>收费版</code>,但PrivateZone有一个限制就是<strong>只能专有网络(VPC)使用</strong>,这就比较坑了,不过综合看了下PrivateZone的功能,发现完全<strong>满足我的需求</strong>,于是想方设法让让它支持经典网络</p><p>​    (这里解释下为什么非得要支持经典网络: 我们最开始就是使用经典网络,90%业务都在上面,计划迁移到VPC但还没开始实施,所以先解决DNS问题再说吧)</p><p>​    经过与阿里云沟通,发现他们官方没有什么建议可以实现,于是自己搞吧~</p><h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p><img src="https://cdn.jsdelivr.net/gh/sungaomeng/blog-images/img/dns/%E9%98%BF%E9%87%8C%E4%BA%91%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E7%A7%81%E6%9C%89DNS%E6%9C%8D%E5%8A%A1%E6%96%B9%E6%A1%88.png" alt="阿里云经典网络私有DNS服务方案"></p><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul><li>PrivateZone绑定VPC后,该VPC内的主机都可以支持自定义解析</li><li>通过在VPC里搭建BIND 代理到PrivateZone服务</li></ul><h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><h4 id="购买硬件资源"><a href="#购买硬件资源" class="headerlink" title="购买硬件资源"></a>购买硬件资源</h4><ol><li>创建一个专有网络(VPC)</li><li>创建一个DNS服务(PrivateZone)</li><li>创建阿里云服务器(ECS)搭建BIND服务,最低两台(主从架构)</li><li>创建一个负载均衡(SLB)监听UDP53</li><li>创建一台阿里云服务器(经典网络)(DNS 客户端)</li></ol><h4 id="Ansible安装BIND9-主从架构"><a href="#Ansible安装BIND9-主从架构" class="headerlink" title="Ansible安装BIND9 主从架构"></a>Ansible安装BIND9 主从架构</h4><p>以下为安装过程,具体见<a href="https://github.com/sungaomeng/ansible-dns.git" target="_blank" rel="noopener">GITHUB</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install ansible</span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;sungaomeng&#x2F;ansible-dns.git</span><br><span class="line">cd ansible-dns</span><br><span class="line">ansible all -m ping</span><br><span class="line">ansible-playbook deploy.yml</span><br></pre></td></tr></table></figure><p>注意在执行playbook前要修改ansible/hosts 配置</p><ol><li><p>forwarder_list</p><ul><li><p>转发dns的地址列表</p></li><li><p>将值修改为bind机器/etc/resolv.conf 中的nameserver地址</p></li></ul></li></ol><ol start="2"><li><p>internal_list</p><ul><li>内部网络地址列表，表示允许递归查询的客户端列表，一般为内部服务器ip所在的网段</li><li>将值修改为客户端IP段</li></ul></li><li><p>masters/slaves</p><ul><li>BIND主从IP地址</li></ul></li><li><p>ansible_ssh_port/user/pass</p><ul><li>如果没有配置SSH互信就指定SSH信息</li></ul></li></ol><h3 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h3><h4 id="querperf安装"><a href="#querperf安装" class="headerlink" title="querperf安装"></a>querperf安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://downloads.isc.org/isc/bind9/9.9.4/bind-9.9.4.tar.gz</span><br><span class="line">tar zxvf bind-9.9.4.tar.gz</span><br><span class="line">cd bind-9.9.4/contrib/queryperf</span><br><span class="line">./configure</span><br><span class="line">make</span><br></pre></td></tr></table></figure><h4 id="创建测试文件"><a href="#创建测试文件" class="headerlink" title="创建测试文件"></a>创建测试文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ./querytest.txt</span><br><span class="line">写入以下内容</span><br><span class="line">www.baidu.com A</span><br><span class="line">执行 :1,$y回车p</span><br><span class="line">复制到1w行~</span><br></pre></td></tr></table></figure><h4 id="执行测试"><a href="#执行测试" class="headerlink" title="执行测试"></a>执行测试</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./queryperf -q 20 -d ./querytest.txt -s 192.168.50.158 -l 100</span><br></pre></td></tr></table></figure><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">压测条件:</span><br><span class="line">  1. 时间: 100秒</span><br><span class="line">  2. 并发数: 120</span><br><span class="line">  3. 压测对象: SLB-&gt;单台2核4G DNS服务器</span><br><span class="line">结果:</span><br><span class="line">  1. CPU 68%</span><br><span class="line">  2. Mem 1.5%</span><br><span class="line">  3. QPS 2.2W</span><br><span class="line">  4. RTT average: 0.003891 sec</span><br><span class="line"> </span><br><span class="line">压测条件:</span><br><span class="line"> 1. 时间: 100秒</span><br><span class="line"> 2. 并发数: 160</span><br><span class="line"> 3. 压测对象: SLB-&gt;单台2核4G DNS服务器</span><br><span class="line">结果:</span><br><span class="line">  1. CPU 75%</span><br><span class="line">  2. Mem 1.5%</span><br><span class="line">  3. QPS 3.1W</span><br><span class="line">  4. RTT average: 0.004834 sec</span><br></pre></td></tr></table></figure><p><strong>（生产环境共有3台服务通过SLB提供服务,以上结果需要*3才是线上的瓶颈）</strong></p><h3 id="切换"><a href="#切换" class="headerlink" title="切换"></a>切换</h3><p>将经典网络ECS的/etc/resolv.conf nameserver地址改为负载均衡地址即可</p>]]></content>
      
      
      <categories>
          
          <category> DNS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DNS </tag>
            
            <tag> Aliyun </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql实时同步-CanalHA集群并输出至Kafka</title>
      <link href="/canal/install-canal-to-kafka-HACluster/"/>
      <url>/canal/install-canal-to-kafka-HACluster/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Mysql实时同步方案-通过阿里开源的Canal工具实时监听Mysql数据并输出至Kafka</p></blockquote><h3 id="Canal-简介"><a href="#Canal-简介" class="headerlink" title="Canal 简介"></a>Canal 简介</h3><p>   阿里云开源的基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费</p><p>早期阿里巴巴因为杭州和美国双机房部署，存在跨机房同步的业务需求，实现方式主要是基于业务 trigger 获取增量变更。从 2010 年开始，业务逐步尝试数据库日志解析获取增量变更进行同步，由此衍生出了大量的数据库增量订阅和消费业务。</p><p>基于日志增量订阅和消费的业务包括</p><ul><li>数据库镜像</li><li>数据库实时备份</li><li>索引构建和实时维护(拆分异构索引、倒排索引等)</li><li>业务 cache 刷新</li><li>带业务逻辑的增量数据处理</li></ul><p>当前的 canal 支持源端 MySQL 版本包括 5.1.x , 5.5.x , 5.6.x , 5.7.x , 8.0.x</p><h3 id="Canal-工作原理"><a href="#Canal-工作原理" class="headerlink" title="Canal 工作原理"></a>Canal 工作原理</h3><ul><li>canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议</li><li>MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )</li><li>canal 解析 binary log 对象(原始为 byte 流)</li><li>canal是使用zookeeper来保证HA的<ul><li>关于HA 见官网说明 “HA机制设计”部分 <a href="https://github.com/alibaba/canal/wiki/%E7%AE%80%E4%BB%8B" target="_blank" rel="noopener">https://github.com/alibaba/canal/wiki/%E7%AE%80%E4%BB%8B</a></li></ul></li><li>Git: <a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">https://github.com/alibaba/canal</a></li></ul><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><table><thead><tr><th>软件</th><th>服务器地址</th></tr></thead><tbody><tr><td>Canal 01节点</td><td>10.31.150.42</td></tr><tr><td>Canal 02节点</td><td>10.80.81.39</td></tr><tr><td>Kafka/Zookeeper</td><td>192.168.52.146</td></tr><tr><td>Mysql</td><td>****.mysql.rds.aliyuncs.com</td></tr></tbody></table><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><ul><li><p>对于自建 MySQL , 需要先开启 Binlog 写入功能，配置 binlog-format 为 ROW 模式，my.cnf 中配置如下</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">log-bin&#x3D;mysql-bin # 开启 binlog</span><br><span class="line">binlog-format&#x3D;ROW # 选择 ROW 模式</span><br><span class="line">server_id&#x3D;1 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复</span><br></pre></td></tr></table></figure><blockquote><p>注意：针对阿里云 RDS for MySQL , 默认打开了 binlog , 并且账号默认具有 binlog dump 权限 , 不需要任何权限或者 binlog 设置,可以直接跳过这一步</p></blockquote></li><li><p>授权 canal 链接 MySQL 账号具有作为 MySQL slave 的权限, 如果已有账户可直接 grant</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE USER canal IDENTIFIED BY &#39;canal&#39;;  </span><br><span class="line">GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#39;canal&#39;@&#39;%&#39;;</span><br><span class="line">-- GRANT ALL PRIVILEGES ON *.* TO &#39;canal&#39;@&#39;%&#39; ;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure></li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul><li><p>下载 canal, 访问 <a href="[https://github.com/alibaba/canal/releases]">release</a> 页面, 选择需要的包下载, 如以 v1.1.3 版本为例 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;canal&#x2F;releases&#x2F;download&#x2F;canal-1.1.3&#x2F;canal.deployer-1.1.3.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>解压缩</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;usr&#x2F;local&#x2F;canal</span><br><span class="line">tar zxvf canal.deployer-$version.tar.gz  -C &#x2F;usr&#x2F;local&#x2F;canal</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>配置修改</p><blockquote><p>conf/example/instance.properties</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">以下为需要修改的配置</span><br><span class="line">canal.instance.master.address&#x3D;****.mysql.rds.aliyuncs.com:3306 #改为需要同步的数据库地址</span><br><span class="line">canal.instance.dbUsername&#x3D;canal  #改为数据库账户</span><br><span class="line">canal.instance.dbPassword&#x3D;****   #改为数据库密码</span><br><span class="line"></span><br><span class="line"># table regex</span><br><span class="line">canal.instance.filter.regex&#x3D;DBname.DBtable,DBname.DBtable #需要同步的表,多个表用逗号相隔,也可指定库下的全部表</span><br><span class="line"># table black regex</span><br><span class="line">canal.instance.filter.black.regex&#x3D;</span><br><span class="line"></span><br><span class="line"># mq config</span><br><span class="line">canal.mq.topic&#x3D;test #指定同步到kafka的哪个topic中</span><br><span class="line"># dynamic topic route by schema or table regex</span><br><span class="line">#canal.mq.dynamicTopic&#x3D;mytest1.user,mytest2\\..*,.*\\..*</span><br><span class="line">canal.mq.partition&#x3D;0 #默认输出到kafka topic的哪个partition中</span><br><span class="line"># hash partition config</span><br><span class="line">canal.mq.partitionsNum&#x3D;15 #topic的partition总数,如果canal.mq.partitionHash不启用,则此项没用</span><br><span class="line">canal.mq.partitionHash&#x3D;.*\\..*:id #使用id作为hash将数据分布到$partitionsNum个分区中</span><br><span class="line">#################################################</span><br></pre></td></tr></table></figure><blockquote><p>关于mq config</p><pre><code>mq相关参数见官方说明：https://github.com/alibaba/canal/wiki/Canal-Kafka-RocketMQ-QuickStart</code></pre><p>关于topic:</p><pre><code>可以指定正则将不同的数据输出到不同的表 canal.mq.dynamicTopic如果没有指定则默认输出到canal.mq.topic表中</code></pre><p>关于partition:</p><pre><code>可以根据hash算法将数据分布到多个partition中 canal.mq.partitionHash如果不指定则默认输出到canal.mq.partition=0 0分区中,这样会导致只有0分区有数据因为我司对数据顺序没有要求,为了提高吞吐量,所以将id作为hash 将数据均匀的分布到了15个partition中</code></pre></blockquote></li></ul><blockquote><p>conf/canal.properties</p></blockquote>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">以下为需要修改的配置</span><br><span class="line">canal.id &#x3D; 1</span><br><span class="line">canal.zkServers &#x3D; 192.168.52.146:2181  #修改为zookeeper集群的地址,可以写lb 也可以所有节点</span><br><span class="line">canal.serverMode &#x3D; kafka</span><br><span class="line">canal.mq.servers &#x3D; 192.168.52.146:9092 #修改为kafka集群的地址,可以写lb 也可以所有节点</span><br></pre></td></tr></table></figure><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><ul><li><p>启动第一台机器 canal02</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;local&#x2F;canal&#x2F;bin&#x2F;startup.sh</span><br></pre></td></tr></table></figure><p>查看日志</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">OpenJDK 64-Bit Server VM warning: ignoring option PermSize&#x3D;96m; support was removed in 8.0</span><br></pre></td></tr></table></figure><p>zookeeper状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] ls &#x2F;otter&#x2F;canal&#x2F;cluster</span><br><span class="line">[10.31.150.42:11111]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] get &#x2F;otter&#x2F;canal&#x2F;destinations&#x2F;example&#x2F;running</span><br><span class="line">&#123;&quot;active&quot;:true,&quot;address&quot;:&quot;10.31.150.42:11111&quot;,&quot;cid&quot;:1&#125;</span><br></pre></td></tr></table></figure><p>kafka状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ &#x2F;data01&#x2F;server&#x2F;kafka&#x2F;bin&#x2F;kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list 192.168.52.146:9092 --topic test --time -1</span><br><span class="line">test:0:98791</span><br><span class="line">test:1:2689</span><br><span class="line">test:2:2727</span><br><span class="line">test:3:2831</span><br><span class="line">test:4:2740</span><br><span class="line">test:5:2464</span><br><span class="line">test:6:2782</span><br><span class="line">test:7:2846</span><br><span class="line">test:8:3229</span><br><span class="line">test:9:3183</span><br><span class="line">test:10:2698</span><br><span class="line">test:11:2801</span><br><span class="line">test:12:3252</span><br><span class="line">test:13:2347</span><br><span class="line">test:14:2990</span><br><span class="line"></span><br><span class="line">每个分区都产生了数据</span><br></pre></td></tr></table></figure></li><li><p>启动第二台机器 canal01</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;local&#x2F;canal&#x2F;bin&#x2F;startup.sh</span><br></pre></td></tr></table></figure><p>查看日志 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@offline-gateway-canal-01 canal]# cat logs&#x2F;canal&#x2F;canal.log </span><br><span class="line"> OpenJDK 64-Bit Server VM warning: ignoring option PermSize&#x3D;96m; support was removed in 8.0</span><br><span class="line"> OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;256m; support was removed in 8.0</span><br><span class="line"> OpenJDK 64-Bit Server VM warning: UseCMSCompactAtFullCollection is deprecated and will likely be removed in a future release.</span><br><span class="line"> 2019-07-18 16:00:29.563 [main] INFO  com.alibaba.otter.canal.deployer.CanalLauncher - ## set default uncaught exception handler</span><br><span class="line"> 2019-07-18 16:00:29.601 [main] INFO  com.alibaba.otter.canal.deployer.CanalLauncher - ## load canal configurations</span><br><span class="line"> 2019-07-18 16:00:29.608 [main] INFO  c.a.o.c.d.monitor.remote.RemoteConfigLoaderFactory - ## load local canal configurations</span><br><span class="line"> 2019-07-18 16:00:29.622 [main] INFO  com.alibaba.otter.canal.deployer.CanalStater - ## start the canal server.</span><br><span class="line"> 2019-07-18 16:00:29.789 [main] INFO  com.alibaba.otter.canal.deployer.CanalController - ## start the canal server[10.31.150.42:11111]</span><br><span class="line"> 2019-07-18 16:00:30.433 [main] WARN  o.s.beans.GenericTypeAwarePropertyDescriptor - Invalid JavaBean property &#39;connectionCharset&#39; being accessed! Ambiguous write methods found next to actually used [public void com.alibaba.otter.canal.parse.inbound.mysql.AbstractMysqlEventParser.setConnectionCharset(java.nio.charset.Charset)]: [public void com.alibaba.otter.canal.parse.inbound.mysql.AbstractMysqlEventParser.setConnectionCharset(java.lang.String)]</span><br><span class="line"> 2019-07-18 16:00:30.655 [main] ERROR com.alibaba.druid.pool.DruidDataSource - testWhileIdle is true, validationQuery not set</span><br><span class="line"> 2019-07-18 16:00:30.892 [main] WARN  c.a.o.canal.parse.inbound.mysql.dbsync.LogEventConvert - --&gt; init table filter : ^.*\..*$</span><br><span class="line"> 2019-07-18 16:00:30.892 [main] WARN  c.a.o.canal.parse.inbound.mysql.dbsync.LogEventConvert - --&gt; init table black filter : </span><br><span class="line"> 2019-07-18 16:00:30.899 [main] INFO  com.alibaba.otter.canal.deployer.CanalStater - ## the canal server is running now ......</span><br><span class="line"> 2019-07-18 16:00:30.906 [destination &#x3D; metrics , address &#x3D; null , EventParser] ERROR c.a.o.c.p.inbound.mysql.rds.RdsBinlogEventParserProxy - parse events has an error</span><br><span class="line"> com.alibaba.otter.canal.parse.exception.CanalParseException: illegal connection is null</span><br><span class="line"> 2019-07-18 16:00:30.979 [canal-instance-scan-0] INFO  c.a.o.canal.deployer.monitor.SpringInstanceConfigMonitor - auto notify stop metrics successful.</span><br></pre></td></tr></table></figure><p>zookeeper状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] ls &#x2F;otter&#x2F;canal&#x2F;cluster</span><br><span class="line">[10.31.150.42:11111, 10.80.81.39:11111]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] get &#x2F;otter&#x2F;canal&#x2F;destinations&#x2F;example&#x2F;running</span><br><span class="line">&#123;&quot;active&quot;:true,&quot;address&quot;:&quot;10.80.81.39:11111&quot;,&quot;cid&quot;:1&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p>​    启动第一台时开始订阅binlog并实时输出到kafka, 并将信息注册到zookeeper</p><p>​    启动第二胎时第二台从zookeeper获取到example已经被注册, 所以等待下次再查询状态</p><p>​    第一台stop之后, 第二台从zk检查到example没有被注册, 所以上任, 开始订阅binlog并输出到kafka, 并将信息注册到zk</p>]]></content>
      
      
      <categories>
          
          <category> Canal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Canal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>遍历HDFS,获取所有文件列表</title>
      <link href="/hadoop/traverse-hdfs-all-files/"/>
      <url>/hadoop/traverse-hdfs-all-files/</url>
      
        <content type="html"><![CDATA[<blockquote><p>在文件里太多的情况下直接hdfs ls会导致内存溢出, 无法获取所有文件列表，这里通过java的方式遍历HDFS,获取所有文件列表输出到文件</p></blockquote><h3 id="Jar-包地址"><a href="#Jar-包地址" class="headerlink" title="Jar 包地址"></a>Jar 包地址</h3><p><a href="https://github.com/sungaomeng/blog-images/tree/master/file/hadoop/hdfs-1.0-SNAPSHOT.jar" target="_blank" rel="noopener">GitHub链接</a></p><h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><blockquote><p>下载Jar包后执行以下命令</p><p>/dir1 是HDFS里的目录</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop jar hdfs-1.0-SNAPSHOT.jar &#x2F;dir1 &gt; dir1.txt</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Hdfs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速删除单目录下大量碎文件</title>
      <link href="/shell/quickly-delete-lot-files/"/>
      <url>/shell/quickly-delete-lot-files/</url>
      
        <content type="html"><![CDATA[<blockquote><p>用Shell并发删除一个目录下的大量碎文件,并分享整个删除过程</p></blockquote><h3 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h3><blockquote><p>建议文件量特别多时分开目录存储(按日期或者按产品ID等),不然后续处理会很棘手</p><p>代码多写一点,为后来人多考虑一点。</p></blockquote><h3 id="缘由"><a href="#缘由" class="headerlink" title="缘由"></a>缘由</h3><p>因为生产环境中使用到了阿里云的NAS服务, 有大量碎文件存储到了NAS中</p><p>后来NAS收费太贵,就将历史数据迁移到了OSS中</p><p>迁移完成后需要删除NAS中的碎文件</p><p>大约<strong><code>150T</code>,<code>30亿</code></strong>个文件</p><h3 id="尝试的删除方法"><a href="#尝试的删除方法" class="headerlink" title="尝试的删除方法"></a>尝试的删除方法</h3><ul><li>python</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shutil.rmtree(/nas/data/<span class="number">2019</span><span class="number">-01</span><span class="number">-01</span>/)</span><br></pre></td></tr></table></figure><ul><li>rsync</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rsync -a --delete /opt/empty/ /nas/data/2019-01-01/</span><br></pre></td></tr></table></figure><ul><li>rm</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;nas&#x2F;data&#x2F;2019-01-01&#x2F;</span><br></pre></td></tr></table></figure><p>最终尝试了以上三种方法，发现都非常慢</p><p>通过strace命令发现进程主要在做<strong>getdents</strong>(readdir)操作(获取文件列表)</p><p>另外提一句如果是本地数据还好, 阿里云NAS针对<code>readdir</code>操作做了部分限制, 导致获取文件列表巨慢···</p><blockquote><p>怎么发现的呢？</p><p>  我启动了20个线程去获取20个目录下的文件列表,发现机器与NAS之间的流量始终只能到30Mb, 后来又启动了40个线程也是到30Mb, 然后跟阿里云沟通结果是他们需要单独调整参数才能优化读取操作, 因为调整需要reload nas服务,对线上有影响,我就放弃了没让他们做···</p></blockquote><h3 id="内核参数调优"><a href="#内核参数调优" class="headerlink" title="内核参数调优"></a>内核参数调优</h3><blockquote><p>因为阿里云NAS最终是以NFS的方式提供服务</p><p>所以官方建议调整OS kernel的限制</p><p>修改参数后需要<strong>重新挂载</strong>NAS或者<strong>重启系统</strong></p><p>具体说明见<a href="https://help.aliyun.com/knowledge_detail/53839.html?spm=a2c4g.11186631.2.16.4218622fLlHtQZ" target="_blank" rel="noopener">阿里云文档</a></p></blockquote><ul><li>Kernel 2.6(Centos6)左右的内核限制为128</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;options sunrpc tcp_slot_table_entries&#x3D;128&quot; &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;sunrpc.conf</span><br><span class="line">echo &quot;options sunrpc tcp_max_slot_table_entries&#x3D;128&quot; &gt;&gt;  &#x2F;etc&#x2F;modprobe.d&#x2F;sunrpc.conf</span><br><span class="line">sysctl -w sunrpc.tcp_slot_table_entries&#x3D;128</span><br></pre></td></tr></table></figure><ul><li>Kernel 3(Centos7)的内核限制为65535</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;options sunrpc tcp_slot_table_entries&#x3D;65535&quot; &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;sunrpc.conf</span><br><span class="line">echo &quot;options sunrpc tcp_max_slot_table_entries&#x3D;65535&quot; &gt;&gt;  &#x2F;etc&#x2F;modprobe.d&#x2F;sunrpc.conf</span><br><span class="line">sysctl -w sunrpc.tcp_slot_table_entries&#x3D;65535</span><br></pre></td></tr></table></figure><h3 id="最佳方案"><a href="#最佳方案" class="headerlink" title="最佳方案"></a>最佳方案</h3><blockquote><p><strong>先获取文件列表后并发删除</strong></p></blockquote><h4 id="1-获取文件列表"><a href="#1-获取文件列表" class="headerlink" title="1. 获取文件列表"></a>1. 获取文件列表</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -1 -f DIR</span><br></pre></td></tr></table></figure><blockquote><p>为什么要加后面的两个参数？</p><p>​    默认情况下，<strong><code>ls</code></strong>命令将对其输出进行<code>排序</code>。要做到这一点，它必须首先将每个文件的名称篡改到内存中。面对一个非常大的目录，它将坐在那里，读取文件名，占用越来越多的内存，直到最终按字母数字顺序一次列出所有文件。</p><p>​    而<strong><code>ls -1 -f</code></strong> 则<strong>不执行任何排序</strong>。它只是读取目录并立即显示文件。</p><p>​    具体说明文档请参考<a href="[http://unixetc.co.uk/2012/05/20/large-directory-causes-ls-to-hang/](http://unixetc.co.uk/2012/05/20/large-directory-causes-ls-to-hang/)">大神文档</a></p></blockquote><h4 id="2-切分文件"><a href="#2-切分文件" class="headerlink" title="2.切分文件"></a>2.切分文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">split -l 10000000 -d list split-tmp-</span><br><span class="line"><span class="meta">#</span><span class="bash"> 100w行一个文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件名以<span class="string">"split-tmp-"</span>开头</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件名以数字结尾</span></span><br></pre></td></tr></table></figure><h4 id="3-并发删除"><a href="#3-并发删除" class="headerlink" title="3.并发删除"></a>3.并发删除</h4><p><strong>shell 实现进程并发控制</strong></p><p>关于shell的多进程并发见<a href="https://bbs.51cto.com/thread-1104907-1-1.html" target="_blank" rel="noopener">大神文档</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">定义日志</span></span><br><span class="line">Log=./rm.log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">指定并发数量</span></span><br><span class="line">Nproc=20</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">接受信号2 （ctrl +C)做的操作</span></span><br><span class="line">trap "exec 1000&gt;$-;exec 1000&lt;&amp;-;exit 0" 2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">$$是进程pid</span></span><br><span class="line">Pfifo="/tmp/$$.fifo"</span><br><span class="line">mkfifo $Pfifo</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">以1000为文件描述符打开管道,&lt;&gt;表示可读可写</span></span><br><span class="line">exec 1000&lt;&gt;$Pfifo</span><br><span class="line">rm -f $Pfifo</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">向管道中写入Nproc行,作为令牌</span></span><br><span class="line">for((i=1; i&lt;=$Nproc; i++)); do</span><br><span class="line">    echo</span><br><span class="line">done &gt;&amp;1000</span><br><span class="line"></span><br><span class="line">filenames=`ls split-tmp-*`</span><br><span class="line">for filename in $filenames; do</span><br><span class="line"><span class="meta">#</span><span class="bash">从管道中取出1行作为token，如果管道为空，<span class="built_in">read</span>将会阻塞</span></span><br><span class="line"><span class="meta">#</span><span class="bash">man bash可以知道-u是从fd中读取一行</span></span><br><span class="line">    read -u1000</span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">    #所要执行的任务</span><br><span class="line">        DirPrefix=/nas/data</span><br><span class="line">        while read line;do</span><br><span class="line">            rm -I $DirPrefix/$line || echo "`date +%F-%T` rm -rf $DirPrefix/$line failed" | tee &gt;&gt; $Log</span><br><span class="line">        done &lt; $filename  &amp;&amp; &#123;</span><br><span class="line">            echo "`date +%F-%T` $filename done" | tee &gt;&gt; $Log</span><br><span class="line">        &#125; || &#123;</span><br><span class="line">            echo "`date +%F-%T` $filename error" | tee &gt;&gt; $Log</span><br><span class="line">        &#125;</span><br><span class="line">        sleep 5</span><br><span class="line">    #归还token</span><br><span class="line">        echo &gt;&amp;1000</span><br><span class="line">    &#125;&amp;</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">等待所有子进程结束</span></span><br><span class="line">wait </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">关闭管道</span></span><br><span class="line">exec 1000&gt;&amp;-</span><br><span class="line">exec 1000&lt;&amp;-</span><br></pre></td></tr></table></figure><h4 id="另外说一个其他的删除，针对以下格式"><a href="#另外说一个其他的删除，针对以下格式" class="headerlink" title="另外说一个其他的删除，针对以下格式"></a>另外说一个其他的删除，针对以下格式</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data&#x2F;年-月-日&#x2F;[0-1023]&#x2F;file</span><br></pre></td></tr></table></figure><p>针对这种单个目录下可能只有一两万个文件的情况</p><p>可以用python并发删除</p><p>实测: 每分钟删除NAS里2.6w个文件</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">target_path = <span class="string">"/data/"</span></span><br><span class="line"></span><br><span class="line">pathnames = os.listdir(target_path)</span><br><span class="line">today = datetime.datetime.now()</span><br><span class="line">month_ago = today + datetime.timedelta(days=<span class="number">-30</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dirdel</span><span class="params">(tpath)</span>:</span></span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"start delete:"</span>,tpath</span><br><span class="line">    shutil.rmtree(tpath)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"deleted: %s in %s"</span>%(tpath,time.time()-t1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date_path <span class="keyword">in</span> pathnames:</span><br><span class="line">    tmp_path = target_path+date_path</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(tmp_path):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> (datetime.datetime.strptime(date_path, <span class="string">"%Y-%m-%d"</span>)&lt;month_ago):</span><br><span class="line">        print(tmp_path)</span><br><span class="line">        <span class="keyword">while</span> len(threading.enumerate())&gt;<span class="number">40</span>:</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"waiting..."</span></span><br><span class="line">            time.sleep(<span class="number">30</span>)</span><br><span class="line">        threading.Thread(target=dirdel, args=(tmp_path,)).start()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>filebeat-限制CPU使用</title>
      <link href="/efk/filebeat/limit-cpu/"/>
      <url>/efk/filebeat/limit-cpu/</url>
      
        <content type="html"><![CDATA[<h3 id="缘由"><a href="#缘由" class="headerlink" title="缘由"></a>缘由</h3><p>日志量大的时时候filebeat会占用非常高的CPU,为了防止影响业务稳定,决定对filebeat的CPU进行限制核数</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="限制使用的cpu核数"><a href="#限制使用的cpu核数" class="headerlink" title="限制使用的cpu核数"></a>限制使用的cpu核数</h4><p>​    filebeat.yml文件中可以指定”max_procs”参数</p><p>​    max_procs: 限制filebeat的进程数量,其实就是内核数</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">max_procs: 1</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- input_type: log</span><br><span class="line">  #include_lines: [&quot;^\\[[0-9]&#123;4&#125;&quot;]</span><br><span class="line">  tail_files: true</span><br><span class="line">  paths:</span><br><span class="line">    - &#x2F;var&#x2F;log&#x2F;*.log</span><br><span class="line">  fields:</span><br><span class="line">    device: pudding1s</span><br><span class="line">  fields_under_root: true</span><br><span class="line">  document_type: log</span><br></pre></td></tr></table></figure><h4 id="降低filebeat进程优先级"><a href="#降低filebeat进程优先级" class="headerlink" title="降低filebeat进程优先级"></a>降低filebeat进程优先级</h4><h5 id="启动时指定进程优先级"><a href="#启动时指定进程优先级" class="headerlink" title="启动时指定进程优先级"></a>启动时指定进程优先级</h5><p>​    使用nice命令</p><p>​    使用方法: nice -n 命令</p><p>​    优先级由 -20~19这个范围来表示优先级大小，数值越小，优先级越高(默认0)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /etc/init.d/filebeat </span></span><br><span class="line">···</span><br><span class="line">start() &#123; </span><br><span class="line">    [ -x $filebeat ] || exit 5 </span><br><span class="line">    [ -f $FILEBEAT_CONF_FILE ] || exit 6 </span><br><span class="line">    echo -n $"Starting $prog: " </span><br><span class="line">    #daemon $filebeat -c $FILEBEAT_CONF_FILE </span><br><span class="line">    nice -n 10 nohup $filebeat -c $FILEBEAT_CONF_FILE &gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line">    retval=$? </span><br><span class="line">    echo </span><br><span class="line">    [ $retval -eq 0 ] &amp;&amp; touch $lockfile </span><br><span class="line">    return $retval </span><br><span class="line">&#125; </span><br><span class="line">···</span><br></pre></td></tr></table></figure><h5 id="启动后手动调整进程优先级"><a href="#启动后手动调整进程优先级" class="headerlink" title="启动后手动调整进程优先级"></a>启动后手动调整进程优先级</h5><p>​    使用renice 命令</p><p>​    使用方法: renice 优先级  进程PID</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FilebeatPid&#x3D;&#96;ps -ef |grep filebeat |grep -v grep |awk &#39;&#123;print $2&#125;&#39;&#96;</span><br><span class="line">renice 10 $FilebeatPid</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> EFK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EFK </tag>
            
            <tag> Filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>filebeat-重新收取某个日志文件</title>
      <link href="/efk/filebeat/reload-log/"/>
      <url>/efk/filebeat/reload-log/</url>
      
        <content type="html"><![CDATA[<h3 id="缘由"><a href="#缘由" class="headerlink" title="缘由"></a>缘由</h3><p>filebeat想重新收取某个文件,或者从指定位置重新收取某个文件</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ul><li><p>全部重新收取</p><p>  即：删除<code>registry</code>文件并重启filebeat</p><blockquote><p>PS: 这种方法会将所有文件重新收取</p></blockquote></li><li><p>重新收取某个文件</p><p>  即：修改registry文件中对应文件的<code>offset</code>信息并重启filebeat</p><blockquote><p><code>offset</code>修改为<code>0</code>则代表从头开始</p><p>PS: 关于<code>registry</code>文件的格式参见”<a href="https://blog.opsolo.com/efk/filebeat/filebeat-registry文件内容解析" target="_blank" rel="noopener">registry文件内容解析</a>“</p></blockquote></li><li><p>从指定位置收取某个文件</p><blockquote><p>指定<code>offset</code>值, 从指定的<code>offset</code>位置收取</p></blockquote></li></ul><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">    <span class="attr">"source"</span>:<span class="string">"/var/log/php/laravel-2019-05-19.log"</span>,</span><br><span class="line">    <span class="attr">"offset"</span>:<span class="number">1632</span>,</span><br><span class="line">    <span class="attr">"FileStateOS"</span>:&#123;</span><br><span class="line">        <span class="attr">"inode"</span>:<span class="number">4353086</span>,</span><br><span class="line">        <span class="attr">"device"</span>:<span class="number">64529</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"timestamp"</span>:<span class="string">"2019-05-19T12:35:34.724025571+08:00"</span>,</span><br><span class="line">    <span class="attr">"ttl"</span>:<span class="number">-1</span></span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> EFK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EFK </tag>
            
            <tag> Filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>filebeat-registry文件内容解析</title>
      <link href="/efk/filebeat/registry-content-analysis/"/>
      <url>/efk/filebeat/registry-content-analysis/</url>
      
        <content type="html"><![CDATA[<h3 id="filebeat中registry文件的作用"><a href="#filebeat中registry文件的作用" class="headerlink" title="filebeat中registry文件的作用"></a>filebeat中registry文件的作用</h3><p>registry文件中存放的被采集的所有日志文件的相关信息</p><h3 id="文件内容解析"><a href="#文件内容解析" class="headerlink" title="文件内容解析"></a>文件内容解析</h3><h4 id="内容样例"><a href="#内容样例" class="headerlink" title="内容样例"></a>内容样例</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">    <span class="attr">"source"</span>:<span class="string">"/var/log/php/laravel-2019-05-19.log"</span>,</span><br><span class="line">    <span class="attr">"offset"</span>:<span class="number">1632</span>,</span><br><span class="line">    <span class="attr">"FileStateOS"</span>:&#123;</span><br><span class="line">        <span class="attr">"inode"</span>:<span class="number">4353086</span>,</span><br><span class="line">        <span class="attr">"device"</span>:<span class="number">64529</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"timestamp"</span>:<span class="string">"2019-05-19T12:35:34.724025571+08:00"</span>,</span><br><span class="line">    <span class="attr">"ttl"</span>:<span class="number">-1</span></span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure><h4 id="字段说明"><a href="#字段说明" class="headerlink" title="字段说明"></a>字段说明</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source 日志文件的完整路径</span><br><span class="line">offset　已经采集到日志的哪个字节位置</span><br><span class="line">FileStateOS　　操作系统相关</span><br><span class="line">　　inode　　   日志文件的inode号</span><br><span class="line">　　device     日志所在磁盘的磁盘编号</span><br><span class="line">timestamp　日志最后一次发生变化的时间戳</span><br><span class="line">ttl　　    采集失效时间。(-1表示只要日志存在，就一直采集该日志)</span><br></pre></td></tr></table></figure><h5 id="FileStateOS信息"><a href="#FileStateOS信息" class="headerlink" title="FileStateOS信息"></a>FileStateOS信息</h5><p>filestatOS可以通过stat命令获取</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@test /]# stat /var/log/php/laravel-2019-05-19.log</span><br><span class="line">  File: `/var/log/php/laravel-2019-05-19.log'</span><br><span class="line">  Size: 1632            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: fc11h/64529d    Inode: 4353086     Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (  500/     www)   Gid: (  500/     www)</span><br><span class="line">Access: 2019-05-19 12:30:27.517385737 +0800</span><br><span class="line">Modify: 2019-05-19 12:30:25.992385735 +0800</span><br><span class="line">Change: 2019-05-19 12:30:25.992385735 +0800</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> EFK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EFK </tag>
            
            <tag> Filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo Gitalk 评论自动初始化</title>
      <link href="/hexo/hexo-gitalk-auto-init/"/>
      <url>/hexo/hexo-gitalk-auto-init/</url>
      
        <content type="html"><![CDATA[<blockquote><p>切换到Gitalk后每次都需要手动去创建issue,为了简化流程,使用Nodejs和GithubAPI去自动初始化</p><p>参考原文：<a href="https://daihaoxin.github.io/post/322747ae.html" target="_blank" rel="noopener">daihaoxin</a></p><p>PS: 基于原博主脚本做了部分修改</p><p>  因Github于2021年禁用了将access_token作为查询参数访问API，所以调整到了Header中,详情见<a href="https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/" target="_blank" rel="noopener">链接</a></p><ol><li>issuesUrl</li><li>requestGetOpt</li></ol></blockquote><h3 id="一、生成sitemap站点地图"><a href="#一、生成sitemap站点地图" class="headerlink" title="一、生成sitemap站点地图"></a>一、生成sitemap站点地图</h3><h4 id="1-安装插件"><a href="#1-安装插件" class="headerlink" title="1. 安装插件"></a>1. 安装插件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br><span class="line">npm install hexo-generator-baidu-sitemap --save</span><br></pre></td></tr></table></figure><h4 id="2-在站点根目录下的-config-yml添加如下代码"><a href="#2-在站点根目录下的-config-yml添加如下代码" class="headerlink" title="2. 在站点根目录下的_config.yml添加如下代码"></a>2. 在站点根目录下的_config.yml添加如下代码</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hexo sitemap网站地图</span></span><br><span class="line"><span class="attr">sitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">sitemap.xml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">baidusitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">baidusitemap.xml</span></span><br></pre></td></tr></table></figure><p>现在在执行<code>hexo generate</code>的时候，在博客根目录下的public文件夹下面，就会生成sitemap.xml和baidusitemap.xml。</p><h3 id="二、获取github接口的调用权限"><a href="#二、获取github接口的调用权限" class="headerlink" title="二、获取github接口的调用权限"></a>二、获取github接口的调用权限</h3><ol><li>创建一个access token <a href="https://github.com/settings/tokens" target="_blank" rel="noopener">点此进入</a></li><li>点击Generate new token按钮</li><li>输入一个描述，为token添加所有的<code>repo</code>权限，然后点击最下方的<code>Generate token</code>按钮，就可以生成一个新的Token</li><li>Token在下面的脚本会用到</li></ol><h3 id="三、部署脚本"><a href="#三、部署脚本" class="headerlink" title="三、部署脚本"></a>三、部署脚本</h3><h4 id="1-安装依赖包"><a href="#1-安装依赖包" class="headerlink" title="1. 安装依赖包"></a>1. 安装依赖包</h4><p>  在你hexo的根目录，执行下面的命令</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install request --save</span><br><span class="line">npm install xml-parser --save</span><br><span class="line">npm install yamljs --save</span><br><span class="line">npm install cheerio --save</span><br><span class="line">npm install md5 --save</span><br></pre></td></tr></table></figure><h4 id="2-创建脚本文件"><a href="#2-创建脚本文件" class="headerlink" title="2. 创建脚本文件"></a>2. 创建脚本文件</h4><p>  在站点根目录下创建comment.js文件，将下面的代码粘贴进文件中，然后修改config中的配置项，其中<code>token</code>就是上一步中获取的值</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env node</span></span><br><span class="line"><span class="keyword">const</span> request = <span class="built_in">require</span>(<span class="string">"request"</span>);</span><br><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">"fs"</span>);</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">"path"</span>);</span><br><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">"url"</span>);</span><br><span class="line"><span class="keyword">const</span> xmlParser = <span class="built_in">require</span>(<span class="string">"xml-parser"</span>);</span><br><span class="line"><span class="keyword">const</span> YAML = <span class="built_in">require</span>(<span class="string">"yamljs"</span>);</span><br><span class="line"><span class="keyword">const</span> cheerio = <span class="built_in">require</span>(<span class="string">"cheerio"</span>);</span><br><span class="line"><span class="keyword">const</span> md5 = <span class="built_in">require</span>(<span class="string">"md5"</span>);</span><br><span class="line"><span class="comment">// 根据自己的情况进行配置</span></span><br><span class="line"><span class="keyword">const</span> config = &#123;</span><br><span class="line">    username: <span class="string">"sungaomeng"</span>, <span class="comment">// GitHub 用户名</span></span><br><span class="line">    token: <span class="string">"********"</span>,  <span class="comment">// GitHub Token</span></span><br><span class="line">    repo: <span class="string">"sungaomeng.github.io"</span>,  <span class="comment">// 存放 issues的git仓库</span></span><br><span class="line">    <span class="comment">// sitemap.xml的路径，commit.js放置在根目录下，无需修改，其他情况自行处理</span></span><br><span class="line">    sitemapUrl: path.resolve(__dirname, <span class="string">"./public/sitemap.xml"</span>),</span><br><span class="line">    kind: <span class="string">"Gitalk"</span>,  <span class="comment">// "Gitalk" or "Gitment"，</span></span><br><span class="line">    baseUrl: <span class="string">"https://opsolo.com/"</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// let issuesUrl = `https://api.github.com/repos/$&#123;config.username&#125;/$&#123;config.repo&#125;/issues?access_token=$&#123;config.token&#125;`;</span></span><br><span class="line"><span class="keyword">let</span> issuesUrl = <span class="string">`https://api.github.com/repos/<span class="subst">$&#123;config.username&#125;</span>/<span class="subst">$&#123;config.repo&#125;</span>/issues?`</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> requestGetOpt = &#123;</span><br><span class="line">    url: <span class="string">`<span class="subst">$&#123;issuesUrl&#125;</span>&amp;page=1&amp;per_page=1000`</span>,</span><br><span class="line">    json: <span class="literal">true</span>,</span><br><span class="line">    headers: &#123;</span><br><span class="line">        <span class="string">"User-Agent"</span>: <span class="string">"github-user"</span>,</span><br><span class="line">        <span class="string">"Authorization"</span>: <span class="string">"Bearer &lt;token&gt;"</span> <span class="comment">// GitHub Token</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">let</span> requestPostOpt = &#123;</span><br><span class="line">    ...requestGetOpt,</span><br><span class="line">    url:issuesUrl,</span><br><span class="line">    method: <span class="string">"POST"</span>,</span><br><span class="line">    form: <span class="string">""</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">"开始初始化评论..."</span>);</span><br><span class="line"></span><br><span class="line">(<span class="keyword">async</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"开始检索链接，请稍等..."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> websiteConfig = YAML.parse(fs.readFileSync(path.resolve(__dirname, <span class="string">"./_config.yml"</span>), <span class="string">"utf8"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> urls = sitemapXmlReader(config.sitemapUrl);</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`共检索到<span class="subst">$&#123;urls.length&#125;</span>个链接`</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">"开始获取已经初始化的issues:"</span>);</span><br><span class="line">        <span class="keyword">let</span> issues = <span class="keyword">await</span> send(requestGetOpt);</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`已经存在<span class="subst">$&#123;issues.length&#125;</span>个issues`</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> notInitIssueLinks = urls.filter(<span class="function">(<span class="params">link</span>) =&gt;</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> !issues.find(<span class="function">(<span class="params">item</span>) =&gt;</span> &#123;</span><br><span class="line">                link = removeProtocol(link);</span><br><span class="line">                <span class="keyword">return</span> item.body.includes(link);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">if</span> (notInitIssueLinks.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">`本次有<span class="subst">$&#123;notInitIssueLinks.length&#125;</span>个链接需要初始化issue：`</span>);</span><br><span class="line">            <span class="built_in">console</span>.log(notInitIssueLinks);</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">"开始提交初始化请求, 大约需要40秒..."</span>);</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * 部署好网站后，直接执行start，新增文章并不会生成评论</span></span><br><span class="line"><span class="comment">             * 经测试，最少需要等待40秒，才可以正确生成， 怀疑跟github的api有关系，没有找到实锤</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            setTimeout(<span class="keyword">async</span> ()=&gt;&#123;</span><br><span class="line">                <span class="keyword">let</span> initRet = <span class="keyword">await</span> notInitIssueLinks.map(<span class="keyword">async</span> (item) =&gt; &#123;</span><br><span class="line">                    <span class="keyword">let</span> html = <span class="keyword">await</span> send(&#123; ...requestGetOpt, <span class="attr">url</span>: item &#125;);</span><br><span class="line">                    <span class="keyword">let</span> title = cheerio.load(html)(<span class="string">"title"</span>).text();</span><br><span class="line">                    <span class="keyword">let</span> pathLabel = url.parse(item).path;</span><br><span class="line">                    pathLabel = md5(config.baseUrl + pathLabel);<span class="comment">//中文过长所以要md5</span></span><br><span class="line">                    <span class="keyword">let</span> body = <span class="string">`<span class="subst">$&#123;item&#125;</span>&lt;br&gt;&lt;br&gt;<span class="subst">$&#123;websiteConfig.description&#125;</span>`</span>;</span><br><span class="line">                    <span class="keyword">let</span> form = <span class="built_in">JSON</span>.stringify(&#123; body, <span class="attr">labels</span>: [config.kind, pathLabel], title &#125;);</span><br><span class="line">                    <span class="keyword">return</span> send(&#123; ...requestPostOpt, form &#125;);</span><br><span class="line">                &#125;);</span><br><span class="line">                <span class="built_in">console</span>.log(<span class="string">`已完成<span class="subst">$&#123;initRet.length&#125;</span>个！`</span>);</span><br><span class="line">                <span class="built_in">console</span>.log(<span class="string">"可以愉快的发表评论了！"</span>);</span><br><span class="line">            &#125;,<span class="number">40000</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">"本次发布无新增页面，无需初始化issue!!"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`初始化issue出错，错误如下：`</span>);</span><br><span class="line">        <span class="built_in">console</span>.log(e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;)();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">sitemapXmlReader</span>(<span class="params">file</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> data = fs.readFileSync(file, <span class="string">"utf8"</span>);</span><br><span class="line">    <span class="keyword">let</span> sitemap = xmlParser(data);</span><br><span class="line">    <span class="keyword">return</span> sitemap.root.children.map(<span class="function"><span class="keyword">function</span> (<span class="params">url</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">let</span> loc = url.children.filter(<span class="function"><span class="keyword">function</span> (<span class="params">item</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> item.name === <span class="string">"loc"</span>;</span><br><span class="line">        &#125;)[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">return</span> loc.content;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">removeProtocol</span>(<span class="params">url</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> url.substr(url.indexOf(<span class="string">":"</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">send</span>(<span class="params">options</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function"><span class="keyword">function</span> (<span class="params">resolve, reject</span>) </span>&#123;</span><br><span class="line">        request(options, <span class="function"><span class="keyword">function</span> (<span class="params">error, response, body</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (!error) &#123;</span><br><span class="line">                resolve(body);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                reject(error);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-执行脚本"><a href="#3-执行脚本" class="headerlink" title="3. 执行脚本"></a>3. 执行脚本</h4><blockquote><p>需要注意的是第一步中的sitemap插件会生成的sitemap.xml会包含<strong>全部的界面</strong>，包括标签页、关于页等，执行上面的代码也会对这些页面生成评论框(也就是issue)</p></blockquote><p>完成上述操作后，执行下面的命令，就可以部署站点，并初始化所有的评论了。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br><span class="line">node ./comment.js</span><br></pre></td></tr></table></figure><p>也可以通过在站点根目录的package.json文件中，新建npm脚本，一个命令搞定清除缓存、生成静态文件、提交git并生成issue的所有操作。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;scripts&quot;: &#123;</span><br><span class="line">    &quot;start&quot;: &quot;hexo clean &amp;&amp; hexo s&quot;,</span><br><span class="line">    &quot;deploy&quot;: &quot;hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy &amp;&amp; node .&#x2F;comment.js&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成文章编写，或者其他的更新操作后，直接执行deploy即可。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm run deploy</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight verilog"><table><tr><td class="code"><pre><span class="line"><span class="number">192</span>:blog See$ ./comment<span class="variable">.js</span></span><br><span class="line">开始初始化评论...</span><br><span class="line">开始检索链接，请稍等...</span><br><span class="line">共检索到<span class="number">15</span>个链接</span><br><span class="line">开始获取已经初始化的issues:</span><br><span class="line">已经存在<span class="number">3</span>个issues</span><br><span class="line">本次有<span class="number">12</span>个链接需要初始化issue：</span><br><span class="line">[</span><br><span class="line">  'https:<span class="comment">//opsolo.com/link/index.html',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/categories/index.html',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/tags/index.html',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/python/check-lb-auto-repair/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/zabbix/zabbix-alarm-convergence-compression/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/prometheus/install-prometheus-operator/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/shell/quickly-delete-lot-files/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/efk/filebeat/limit-cpu/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/efk/filebeat/reload-log/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/hexo/hexo-valine/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/hexo/hexo-github-custom-domin/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/hello-world/'</span></span><br><span class="line">]</span><br><span class="line">开始提交初始化请求, 大约需要<span class="number">40</span>秒...</span><br><span class="line">已完成<span class="number">12</span>个！</span><br><span class="line">可以愉快的发表评论了！</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Nodejs </tag>
            
            <tag> Gitalk </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo开启Valine评论</title>
      <link href="/hexo/hexo-valine/"/>
      <url>/hexo/hexo-valine/</url>
      
        <content type="html"><![CDATA[<blockquote><p>为你的Hexo博客开启Valine评论</p></blockquote><ul><li>注册Leancloud</li><li>添加Class</li></ul><h3 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h3><h4 id="界面无法显示评论框并向你抛了一个异常"><a href="#界面无法显示评论框并向你抛了一个异常" class="headerlink" title="界面无法显示评论框并向你抛了一个异常"></a>界面无法显示评论框并向你抛了一个异常</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; TypeError: Cannot read property &#39;hide&#39; of undefined</span><br><span class="line">&gt;     at r.ErrorHandler (Valine.min.js:12)</span><br><span class="line">&gt;     at r.init (Valine.min.js:12)</span><br><span class="line">&gt;     at new r (Valine.min.js:12)</span><br><span class="line">&gt;     at new i (Valine.min.js:12)</span><br><span class="line">&gt;     at (index):1891</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure><p> 需要修改<code>themes/next/_config.yml</code><br> 将<code>valine.language</code>修改为<code>zh-cn</code><br> 完整配置如下:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">valine:</span><br><span class="line">  enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version.</span><br><span class="line">  appid:  ***</span><br><span class="line">  appkey:  ***</span><br><span class="line">  notify: false # mail notifier, See: https:&#x2F;&#x2F;github.com&#x2F;xCss&#x2F;Valine&#x2F;wiki</span><br><span class="line">  verify: false # Verification code</span><br><span class="line">  placeholder: Just go go # comment box placeholder</span><br><span class="line">  avatar: mm # gravatar style</span><br><span class="line">  guest_info: nick,mail,link # custom comment header</span><br><span class="line">  pageSize: 10 # pagination size</span><br><span class="line">  language: zh-cn # language, available values: en, zh-cn</span><br><span class="line">  visitor: false</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo Github 自定义域名</title>
      <link href="/hexo/hexo-github-custom-domin/"/>
      <url>/hexo/hexo-github-custom-domin/</url>
      
        <content type="html"><![CDATA[<blockquote><p>为搭建在Github上的Hexo网站配置自己独有的域名</p></blockquote><h3 id="修改Github-Settings"><a href="#修改Github-Settings" class="headerlink" title="修改Github Settings"></a>修改Github Settings</h3><p><code>Settings</code> -&gt;<code>GitHub Pages</code> -&gt; <code>Custom domain</code></p><p>输入自定义域名后点击 “Save”</p><h3 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h3><h4 id="hexo-deploy后站点404"><a href="#hexo-deploy后站点404" class="headerlink" title="hexo deploy后站点404"></a>hexo deploy后站点404</h4><p> 虽然在Github里设置了自定义域名,但每次hexo deploy后站点就404了<br> 去github <code>settings</code>里查看域名配置发现被还原为默认的了</p><h4 id="解决方法：将域名保存到-source-CNAME中"><a href="#解决方法：将域名保存到-source-CNAME中" class="headerlink" title="解决方法：将域名保存到./source/CNAME中"></a>解决方法：将域名保存到<code>./source/CNAME</code>中</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat .&#x2F;source&#x2F;CNAME</span><br><span class="line">opsolo.com</span><br></pre></td></tr></table></figure><p>保存后再次hexo deploy 就不会被还原了</p>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ansible自动化安装kubernetes</title>
      <link href="/k8s/ansible-kubernetes-autoinstall/"/>
      <url>/k8s/ansible-kubernetes-autoinstall/</url>
      
        <content type="html"><![CDATA[<blockquote><p>生产环境一般不使用kubeadm等工具去搭建kubernetes集群，还是二进制文件搭建更可靠些，所以单独写了一套ansible playbook 自动化安装kubernetes集群<br>这个playbook验证过以下版本(1.11.0/3/5/6)</p></blockquote><h5 id="本项目地址-GitHub"><a href="#本项目地址-GitHub" class="headerlink" title="本项目地址 GitHub"></a>本项目地址 <a href="https://github.com/see-sgm/ansible-kubernetes.git" target="_blank" rel="noopener">GitHub</a></h5><h4 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install ansible</span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;see-sgm&#x2F;ansible-kubernetes.git</span><br><span class="line">rsync -avH ansible-kubernetes&#x2F; &#x2F;etc&#x2F;ansible&#x2F;</span><br><span class="line">cd &#x2F;etc&#x2F;ansible&#x2F;</span><br><span class="line"> 1. 修改hosts主机组列表</span><br><span class="line"> 2. 修改group_vars&#x2F;all.yaml里的变量(版本&#x2F;url&#x2F;VIP等)</span><br><span class="line">ansible all -m ping</span><br><span class="line">ansible-playbook k8s-all.yaml</span><br><span class="line">或者单个指定每个step步骤</span><br></pre></td></tr></table></figure><h4 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. prometheus</span><br><span class="line">2. remove</span><br></pre></td></tr></table></figure><h4 id="see"><a href="#see" class="headerlink" title="see:"></a>see:</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;jicki.me&#x2F;kubernetes&#x2F;2018&#x2F;06&#x2F;29&#x2F;kubernetes-1.11.0.html</span><br><span class="line">https:&#x2F;&#x2F;www.ctolib.com&#x2F;zhangguanzhang-Kubernetes-ansible.html</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;erichll&#x2F;ansible-etcd3</span><br></pre></td></tr></table></figure><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">此playbook 仅用来安装kubernetes,安装的信息如下：</span><br><span class="line">1. kubernetes master&#x2F;slave集群</span><br><span class="line">2. etcd集群</span><br><span class="line">3. ingress</span><br><span class="line">4. dashboard</span><br><span class="line">前置的磁盘初始化自行配置(可参考下面的ansible命令)</span><br><span class="line">dashboard 默认使用自建tls证书,可以自行调整tls和域名</span><br><span class="line">本文的Master HA 采用的是云厂商的负载均衡器(LB),如果没有你也可以自建Haporxy 或者 使用Nginx 代理</span><br></pre></td></tr></table></figure><h4 id="给机器挂载数据盘"><a href="#给机器挂载数据盘" class="headerlink" title="给机器挂载数据盘"></a>给机器挂载数据盘</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible all -m shell -a &quot;fdisk -l&quot; </span><br><span class="line">ansible all -m filesystem -a &#39;fstype&#x3D;ext4 dev&#x3D;&#x2F;dev&#x2F;sdc&#39;</span><br><span class="line">ansible all -m shell -a &quot;blkid &#x2F;dev&#x2F;sdc |awk &#39;&#123;print \$2&#125;&#39;| xargs -I &#123;&#125; echo &#39;&#123;&#125; &#x2F;var&#x2F;lib&#x2F;docker ext4 defaults 0 0&#39; &gt;&gt; &#x2F;etc&#x2F;fstab&quot;</span><br><span class="line">ansible all -m shell -a &quot;mkdir &#x2F;var&#x2F;lib&#x2F;docker; mount -a &quot;</span><br><span class="line">ansible all -m shell -a &quot;df -hT&quot;</span><br></pre></td></tr></table></figure><p>如果内网网卡不是eth0的话需要修改 roles/k8s-step6-install-k8sslave/templates/flanneld.j2 改网卡名字</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> Ansible </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
