<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Python检测负载均衡并自动更新</title>
      <link href="/python/check-lb-auto-repair/"/>
      <url>/python/check-lb-auto-repair/</url>
      
        <content type="html"><![CDATA[<h2 id="Python检测负载均衡并自动更新"><a href="#Python检测负载均衡并自动更新" class="headerlink" title="Python检测负载均衡并自动更新"></a>Python检测负载均衡并自动更新</h2><h5 id="项目地址-GitHub"><a href="#项目地址-GitHub" class="headerlink" title="项目地址 GitHub"></a>项目地址 <a href="https://github.com/sungaomeng/ssproxy-repair" target="_blank" rel="noopener">GitHub</a></h5><h3 id="脚本说明"><a href="#脚本说明" class="headerlink" title="脚本说明"></a>脚本说明</h3><p>这个脚本是用来自动修复基于阿里云搭建的Ss服务</p><ul><li><p>在阿里云新加坡地区购买了一台低配ECS,搭建了Ss服务端</p></li><li><p>由于阿里云经常封杀端口或者公网IP，所以我前面用一个公网负载均衡作为入口 (这样封杀的时候就是封杀的负载均衡了)</p></li><li><p>脚本检测到负载均衡的端口或者IP被封后, 会自动创建一个新的负载均衡并建立监听端口, 然后更新DNS及Hosts记录并删除旧负载均衡</p></li><li><p>一套流程下来, 虽然有一定的延时, 但基本能自动化操作修复, 不用人为干预了。</p><h3 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h3></li><li><p>全部基于阿里云</p></li><li><p>阿里云ECS、负载均衡、云解析DNS</p><h3 id="脚本流程"><a href="#脚本流程" class="headerlink" title="脚本流程"></a>脚本流程</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">├── README.md</span><br><span class="line">├── requirements.txt</span><br><span class="line">├── check.py <span class="comment"># 检查相关函数, 检查域名的端口是否正常,通过域名解析IP</span></span><br><span class="line">├── dns.py   <span class="comment"># 阿里云云解析DNS相关函数, 查询/修改DNS记录, 更新本地Hosts</span></span><br><span class="line">├── main.py  <span class="comment"># 主程序入口,集合其他脚本函数</span></span><br><span class="line">└── slb.py   <span class="comment"># 阿里云负载均衡相关函数, 创建/删除负载均衡,创建/启动监听端口,添加后端服务器</span></span><br><span class="line"></span><br><span class="line">0 directories, 6 files</span><br></pre></td></tr></table></figure></li></ul><ol><li>main.py中定义阿里云相关变量 及 “host” 变量 (负载均衡公网IP对应的域名 或者直接写IP，如果写IP请注释DNS相关函数调用，建议域名)</li><li>检查域名对应端口是否正常，正常则退出，否则新建负载均衡、添加后端服务器、建立监听、启动监听</li><li>等待10s后再次检查新负载均衡的IP对应端口是否正常，正常则删除旧负载均衡并更新DNS后退出，否则打印log后退出</li></ol><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><ul><li>Python 3 (我的环境是3.5.2)</li><li>Crontab</li><li>以及一些python依赖见requirements.txt</li></ul><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/sungaomeng/ssproxy-repair.git</span><br><span class="line">$ pip install -r ssproxy-repair/requirements.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 校时</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"* * * * * /usr/sbin/ntpdate ntp.aliyun.com"</span> &gt;&gt; /var/spool/<span class="variable">$User</span></span><br><span class="line"><span class="comment"># 每半小时执行一次检查</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"*/30 * * * * /usr/bin/python /root/ssproxy-repair/main.py &gt;&gt; /tmp/ssproxy-repair.log 2&gt;&amp;1"</span> &gt;&gt; /var/spool/<span class="variable">$User</span></span><br></pre></td></tr></table></figure><h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>目前并没有输出到log, 仅是打印到前台</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Domain:ss.roobo.net HostIp:161.**.**.186 Port:8388 is not open, return code：35</span><br><span class="line">Prepare to create a new load balancing, Please wait ...</span><br><span class="line">New LoadBalancer:lb-t4nupa5f9w2ynfzsqkjo1 create successful.</span><br><span class="line">New LoadBalancer:lb-t4nupa5f9w2ynfzsqkjo1 add backendserver:i-t4n190***y3d0 successful.</span><br><span class="line">New LoadBalancer:lb-t4nupa5f9w2ynfzsqkjo1 create listener port:8388 successful.</span><br><span class="line">New LoadBalancer:lb-t4nupa5f9w2ynfzsqkjo1 start listener port:8388 successful.</span><br><span class="line">Wait 10 seconds to check the new load balancing again ...</span><br><span class="line">New LoadBalancer:161.**.**.196 Port:8388 is open</span><br><span class="line">Old LoadBalancer:lb-t4n9hdg5***houyedj delete successful.</span><br><span class="line">DNS update record successful domain:ss.test.com, old ip:161.**.**.186, new ip:161.**.**.196</span><br><span class="line">Hosts update record successful domain:ss.test.com, new ip:161.**.**.196</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Shadowsocks </tag>
            
            <tag> wall </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zabbix告警收敛</title>
      <link href="/zabbix/zabbix-alarm-convergence-compression/"/>
      <url>/zabbix/zabbix-alarm-convergence-compression/</url>
      
        <content type="html"><![CDATA[<p>  由于报警短信、邮件太多导致运维人员精神高度紧张、时间长了容易对重要告警忽略，引起不必要的麻烦。为了解决这个问题我在网上开始搜索告警收敛相关的文章尝试解决，最终受益于”简述”大神的这篇文章 “<a href="https://www.jianshu.com/p/b29cf0682b58" target="_blank" rel="noopener">zabbix 告警 | 告警收敛</a>“ 的思路，于是基于大神的代码进行了部分修改并已应用于我们公司环境中一年以上。</p><p>下面为大家分享下整体的流程以及代码。</p><h2 id="一、架构图"><a href="#一、架构图" class="headerlink" title="一、架构图"></a>一、架构图</h2><p>①产生的所有告警均由zabbix的actions调用脚本推入缓存redis当中；<br>②脚本将每分钟(crontab)去redis中拉取数据，根据定义好的一系列规则进行分析、合并；<br>③根据预先定义好的规则将报警通过定义好的方式发送给相关人员；<br><img src="https://upload-images.jianshu.io/upload_images/6840999-d2f2ac64b0a907d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="zabbix收敛流程图.png"></p><h2 id="二、设置Zabbix"><a href="#二、设置Zabbix" class="headerlink" title="二、设置Zabbix"></a>二、设置Zabbix</h2><h4 id="1-配置Media-types"><a href="#1-配置Media-types" class="headerlink" title="1. 配置Media types"></a>1. 配置Media types</h4><ul><li>仅传递 subject</li><li>我这里定义了3个Mediatype 分别用于发送邮件、短信、企业微信(具体可自行调整) （3个除了Name不一样之外其他配置(Script name/Script parameters)保持一致）</li><li>脚本 “zabbix-police/police.py” 主要功能是将Subject(Eventid)写入Redis，后面会写到<br><img src="https://upload-images.jianshu.io/upload_images/6840999-6f2c47f7073877af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Media type 配置"><br><img src="https://upload-images.jianshu.io/upload_images/6840999-a893afe5c3e975a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="多个Media types"><h4 id="2-配置Actions"><a href="#2-配置Actions" class="headerlink" title="2. 配置Actions"></a>2. 配置Actions</h4></li><li>我这里以每个Trigger severity一个Actions举例。（可以根据不同的HostGroup或者其他条件自行配置多个actions）</li><li>Default subject 之所以用 “{EVENT.ID}_1、{EVENT.ID}_0”为的是保持唯一性，1代表故障、0代表恢复</li><li>Default sbject<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;EVENT.ID&#125;_1</span><br></pre></td></tr></table></figure></li><li>Default message<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">triggervalue|&#123;TRIGGER.VALUE&#125;</span><br><span class="line">hostname|&#123;HOSTNAME1&#125;</span><br><span class="line">ipaddress|&#123;IPADDRESS&#125;</span><br><span class="line">hostgroup|&#123;TRIGGER.HOSTGROUP.NAME&#125;</span><br><span class="line">triggerstatus|&#123;TRIGGER.STATUS&#125;</span><br><span class="line">triggerseverity|&#123;TRIGGER.SEVERITY&#125;</span><br><span class="line">triggername|&#123;TRIGGER.NAME&#125;</span><br><span class="line">triggerkey|&#123;TRIGGER.KEY1&#125;</span><br><span class="line">triggeritems|&#123;ITEM.NAME&#125;</span><br><span class="line">itemvalue|&#123;ITEM.VALUE&#125;</span><br><span class="line">eventid|&#123;EVENT.ID&#125;</span><br><span class="line">action|&#123;ACTION.NAME&#125;</span><br><span class="line">eventage|&#123;EVENT.AGE&#125;</span><br><span class="line">eventtime|&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;</span><br></pre></td></tr></table></figure></li><li>Recovery subject<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;EVENT.ID&#125;_0</span><br></pre></td></tr></table></figure></li><li>Recovery message<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">triggervalue|&#123;TRIGGER.VALUE&#125;</span><br><span class="line">hostname|&#123;HOSTNAME1&#125;</span><br><span class="line">ipaddress|&#123;IPADDRESS&#125;</span><br><span class="line">hostgroup|&#123;TRIGGER.HOSTGROUP.NAME&#125;</span><br><span class="line">triggerstatus|&#123;TRIGGER.STATUS&#125;</span><br><span class="line">triggerseverity|&#123;TRIGGER.SEVERITY&#125;</span><br><span class="line">triggername|&#123;TRIGGER.NAME&#125;</span><br><span class="line">triggerkey|&#123;TRIGGER.KEY1&#125;</span><br><span class="line">triggeritems|&#123;ITEM.NAME&#125;</span><br><span class="line">itemvalue|&#123;ITEM.VALUE&#125;</span><br><span class="line">eventid|&#123;EVENT.ID&#125;</span><br><span class="line">action|&#123;ACTION.NAME&#125;</span><br><span class="line">eventage|&#123;EVENT.AGE&#125;</span><br><span class="line">eventtime|&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://upload-images.jianshu.io/upload_images/6840999-e0b7ec8cc74a3e94.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="多个Actions"><br><img src="https://upload-images.jianshu.io/upload_images/6840999-358cc0018d2f9d37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Actions-条件配置"><br><img src="https://upload-images.jianshu.io/upload_images/6840999-d671fa5034d09cbd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Actions-Operations配置"><br><img src="https://upload-images.jianshu.io/upload_images/6840999-5dbf6e040c89b9fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Actions-Recovery配置"></p><h2 id="三、配置-Zabbix-服务器"><a href="#三、配置-Zabbix-服务器" class="headerlink" title="三、配置 Zabbix 服务器"></a>三、配置 Zabbix 服务器</h2><h4 id="1-安装环境"><a href="#1-安装环境" class="headerlink" title="1. 安装环境"></a>1. 安装环境</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载代码</span></span><br><span class="line">/etc/zabbix/alertscripts</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/sungaomeng/zabbix-police.git</span><br><span class="line"><span class="comment">#安装依赖</span></span><br><span class="line">yum install gcc python-devel</span><br><span class="line">pip install -r zabbix-police/requirements.txt</span><br></pre></td></tr></table></figure><h4 id="2-脚本"><a href="#2-脚本" class="headerlink" title="2. 脚本"></a>2. 脚本</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#文件分布</span></span><br><span class="line">[root@zabbix-server01 alertscripts]<span class="comment"># tree zabbix-police </span></span><br><span class="line">zabbix-police</span><br><span class="line">├── police.py    <span class="comment">#Action调用此函数, 用于将EventID写入Redis</span></span><br><span class="line">├── allpolice.py <span class="comment">#综合函数, 总入口, 用于整合其他脚本, 定时被Crontab调用</span></span><br><span class="line">├── dbread.py    <span class="comment">#数据库查询函数, 用于查询Redis、Mysql, 获取EventID、获取告警具体信息、Mediatype脚本对应关系、查询告警接收人等信息</span></span><br><span class="line">├── police.conf  <span class="comment">#定义配置文件, 包括mysql、redis、wechat、email、sms、logfile等配置</span></span><br><span class="line">├── modconf.py   <span class="comment">#加载配置函数, 用于加载配置文件</span></span><br><span class="line">├── operation.py <span class="comment">#操作函数, 用于1. 接收dbread.py返回的告警、恢复信息, 进行合并、压缩处理, 并返回处理结果 2. 定义各告警发送调用函数</span></span><br><span class="line">├── send_wechat.py <span class="comment">#告警发送-微信函数</span></span><br><span class="line">├── send_sms.py    <span class="comment">#告警发送-短信函数</span></span><br><span class="line">├── send_email.py  <span class="comment">#告警发送-邮件函数</span></span><br><span class="line">├── requirements.txt <span class="comment">#依赖</span></span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure><h4 id="3-Crontab"><a href="#3-Crontab" class="headerlink" title="3. Crontab"></a>3. Crontab</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@zabbix-server01 zabbix-police]<span class="comment"># crontab -l </span></span><br><span class="line">* * * * * /usr/bin/python /etc/zabbix/alertscripts/zabbix-police/allpolice.py</span><br></pre></td></tr></table></figure><h2 id="四、告警效果"><a href="#四、告警效果" class="headerlink" title="四、告警效果"></a>四、告警效果</h2><p><img src="https://upload-images.jianshu.io/upload_images/6840999-51ce6a1e78579a96.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="zabbix告警收敛-邮件"></p><p><img src="https://upload-images.jianshu.io/upload_images/6840999-75da6dcdc1b5e56e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="zabbix告警收敛-企业微信告警"><br><img src="https://upload-images.jianshu.io/upload_images/6840999-8fffe6cdf32a80af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="zabbix告警-短信"></p>]]></content>
      
      
      <categories>
          
          <category> Zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus-Operator 安装</title>
      <link href="/prometheus/install-prometheus-operator/"/>
      <url>/prometheus/install-prometheus-operator/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Prometheus-Operator-介绍"><a href="#一、Prometheus-Operator-介绍" class="headerlink" title="一、Prometheus Operator 介绍"></a>一、Prometheus Operator 介绍</h2><p>kubernetes的监控系统Prometheus 相信大家应该都比较了解, 这里不做过多介绍, 简单了解一下几点吧</p><h4 id="1-Prometheus-简介"><a href="#1-Prometheus-简介" class="headerlink" title="1. Prometheus 简介"></a>1. Prometheus 简介</h4><h5 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h5><p>&nbsp;Prometheus 由多个组件组成，但是其中许多组件是可选的：</p><ul><li>Prometheus Server：用于抓取指标、存储时间序列数据</li><li>exporter：暴露指标让任务来抓</li><li>pushgateway：push 的方式将指标数据推送到该网关</li><li>alertmanager：处理报警的报警组件</li><li>adhoc：用于数据查询<h5 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h5>下图是 Prometheus 官方提供的架构及其一些相关的生态系统组件：<br><img src="https://upload-images.jianshu.io/upload_images/6840999-0ac10e4495ae39e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="prometheus-architecture.png"></li></ul><h4 id="2-Operator-简介"><a href="#2-Operator-简介" class="headerlink" title="2. Operator 简介"></a>2. Operator 简介</h4><p>Operator 是 CoreOS 推出的旨在简化复杂有状态应用管理的框架，它是一个感知应用状态的控制器，通过扩展 Kubernetes API 来自动创建、管理和配置应用实例。</p><p>你可以在 <a href="https://www.operatorhub.io/" target="_blank" rel="noopener">OperatorHub.io</a> 上查看 Kubernetes 社区推荐的一些 Operator 范例。</p><h4 id="operator-架构图"><a href="#operator-架构图" class="headerlink" title="operator 架构图"></a>operator 架构图</h4><p><img src="https://upload-images.jianshu.io/upload_images/6840999-1c17359ea85c78a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="prometheus-operator架构图"></p><h2 id="二、安装依赖"><a href="#二、安装依赖" class="headerlink" title="二、安装依赖"></a>二、安装依赖</h2><h4 id="安装Helm"><a href="#安装Helm" class="headerlink" title="安装Helm"></a>安装Helm</h4><h5 id="1-下载Helm"><a href="#1-下载Helm" class="headerlink" title="1. 下载Helm"></a>1. 下载Helm</h5><p>Hlem版本我使用的是当前2版本中的最新版 2.16.7，因为官方建议使用2.14以上版本, 不然会有CRD相关问题, 具体见Github <a href="https://github.com/helm/charts/tree/master/stable/prometheus-operator" target="_blank" rel="noopener">prometheus-operator</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://storage.googleapis.com/kubernetes-helm/helm-v2.16.7-linux-amd64.tar.gz</span><br><span class="line">tar zxvf helm-v2.16.7-linux-amd64.tar.gz</span><br><span class="line">mv linux-amd64/helm linux-amd64/tiller /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">helm version</span><br></pre></td></tr></table></figure><h5 id="2-创建RBAC"><a href="#2-创建RBAC" class="headerlink" title="2. 创建RBAC"></a>2. 创建RBAC</h5><p>创建文件rbac-tiller.yaml , 内容为下</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure><p>创建RBAC</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f rbac-tiller.yaml</span><br></pre></td></tr></table></figure><h5 id="2-初始化Helm"><a href="#2-初始化Helm" class="headerlink" title="2. 初始化Helm"></a>2. 初始化Helm</h5><p>因为默认下载gcr.io仓库的镜像, 由于墙的原因下载失败, 所以我下载后传到了我司仓库</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm init --service-account tiller --tiller-image registry.cn-beijing.aliyuncs.com/roobo/tiller:v2.16.7</span><br><span class="line">$ helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:<span class="string">"v2.16.7"</span>, GitCommit:<span class="string">"5f2584fd3d35552c4af26036f0c464191287986b"</span>, GitTreeState:<span class="string">"clean"</span>&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:<span class="string">"v2.16.7"</span>, GitCommit:<span class="string">"5f2584fd3d35552c4af26036f0c464191287986b"</span>, GitTreeState:<span class="string">"clean"</span>&#125;</span><br></pre></td></tr></table></figure><h2 id="三、安装Prometheus-Operator"><a href="#三、安装Prometheus-Operator" class="headerlink" title="三、安装Prometheus-Operator"></a>三、安装Prometheus-Operator</h2><h4 id="1-创建Namespace"><a href="#1-创建Namespace" class="headerlink" title="1. 创建Namespace"></a>1. 创建Namespace</h4><p>(将相关PODs都创建到此NS下)</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubelet create ns monitoring</span><br></pre></td></tr></table></figure><h4 id="2-安装-prometheus-operator"><a href="#2-安装-prometheus-operator" class="headerlink" title="2. 安装 prometheus-operator"></a>2. 安装 prometheus-operator</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install --namespace monitoring  --name prometheus-operator stable/prometheus-operator</span><br></pre></td></tr></table></figure><h4 id="3-查看相关PODs"><a href="#3-查看相关PODs" class="headerlink" title="3. 查看相关PODs"></a>3. 查看相关PODs</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8smaster-01 ~]<span class="comment"># kubectl -n monitoring get po</span></span><br><span class="line">NAME                                                     READY     STATUS    RESTARTS   AGE</span><br><span class="line">alertmanager-prometheus-operator-alertmanager-0           2/2       Running   0          53m</span><br><span class="line">prometheus-operator-grafana-69bfccc949-h9s7x              2/2       Running   0          53m</span><br><span class="line">prometheus-operator-kube-state-metrics-7ddcbdb744-xzh9w   1/1       Running   0          53m</span><br><span class="line">prometheus-operator-operator-6d4f47dc49-9g9jr             2/2       Running   0          53m</span><br><span class="line">prometheus-operator-prometheus-node-exporter-h9c2p        1/1       Running   0          53m</span><br><span class="line">prometheus-operator-prometheus-node-exporter-jw2hn        1/1       Running   0          53m</span><br><span class="line">prometheus-operator-prometheus-node-exporter-mqq4p        1/1       Running   0          53m</span><br><span class="line">prometheus-operator-prometheus-node-exporter-zxcg5        1/1       Running   0          53m</span><br><span class="line">prometheus-prometheus-operator-prometheus-0               3/3       Running   1          53m</span><br><span class="line"></span><br><span class="line">[root@k8smaster-01 ~]<span class="comment"># kubectl -n monitoring get svc</span></span><br><span class="line">NAME                                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">alertmanager-operated                          ClusterIP   None            &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   53m</span><br><span class="line">prometheus-operated                            ClusterIP   None            &lt;none&gt;        9090/TCP                     53m</span><br><span class="line">prometheus-operator-alertmanager               ClusterIP   10.254.13.40    &lt;none&gt;        9093/TCP                     54m</span><br><span class="line">prometheus-operator-grafana                    ClusterIP   10.254.0.159    &lt;none&gt;        80/TCP                       54m</span><br><span class="line">prometheus-operator-kube-state-metrics         ClusterIP   10.254.43.177   &lt;none&gt;        8080/TCP                     54m</span><br><span class="line">prometheus-operator-operator                   ClusterIP   10.254.38.46    &lt;none&gt;        8080/TCP,443/TCP             54m</span><br><span class="line">prometheus-operator-prometheus                 ClusterIP   10.254.27.218   &lt;none&gt;        9090/TCP                     54m</span><br><span class="line">prometheus-operator-prometheus-node-exporter   ClusterIP   10.254.60.8     &lt;none&gt;        9100/TCP                     54m</span><br><span class="line"></span><br><span class="line">[root@k8smaster-01 ~]<span class="comment"># kubectl get crd</span></span><br><span class="line">NAME                                    CREATED AT</span><br><span class="line">alertmanagers.monitoring.coreos.com     2020-05-10T06:38:44Z</span><br><span class="line">podmonitors.monitoring.coreos.com       2020-05-10T06:38:51Z</span><br><span class="line">prometheuses.monitoring.coreos.com      2020-05-10T06:38:56Z</span><br><span class="line">prometheusrules.monitoring.coreos.com   2020-05-10T06:39:02Z</span><br><span class="line">servicemonitors.monitoring.coreos.com   2020-05-10T06:39:07Z</span><br><span class="line">thanosrulers.monitoring.coreos.com      2020-05-10T06:39:12Z</span><br></pre></td></tr></table></figure><h4 id="4-创建Ingress"><a href="#4-创建Ingress" class="headerlink" title="4. 创建Ingress"></a>4. 创建Ingress</h4><p>默认情况下Grafana并不能直接访问, 可以将svc改为NodePort方式或者创建Ingress 通过域名的方式访问到, 这里以Ingress举例</p><h5 id="Yaml文件"><a href="#Yaml文件" class="headerlink" title="Yaml文件"></a>Yaml文件</h5><p>(将$DOMAIN修改为自己的域名)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-prometheus-operator-grafana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">$DOMAIN</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">prometheus-operator-grafana</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><h2 id="四、效果图"><a href="#四、效果图" class="headerlink" title="四、效果图"></a>四、效果图</h2><p><img src="https://upload-images.jianshu.io/upload_images/6840999-da3df79ebd9f6c00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="首页"></p><p><img src="https://upload-images.jianshu.io/upload_images/6840999-e2d9a84543a942df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Pod"></p><p><img src="https://upload-images.jianshu.io/upload_images/6840999-f3c62891e3bf5201.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Cluster"></p>]]></content>
      
      
      <categories>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里云经典网络私有DNS服务(内网DNS)方案</title>
      <link href="/dns/aliyun-classic-network-private-dns/"/>
      <url>/dns/aliyun-classic-network-private-dns/</url>
      
        <content type="html"><![CDATA[<h2 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h2><ul><li>有内网Host需求的全部通过绑定Hosts访问(/etc/hosts)</li></ul><h2 id="痛点"><a href="#痛点" class="headerlink" title="痛点"></a>痛点</h2><ul><li>需要手动修改hosts文件</li><li>维护麻烦易出错</li><li>docker环境还需要单独给每个pod添加hosts适配,不能做到统一管理</li></ul><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul><li><p>统一管理域名映射关系</p></li><li><p>最好是WEB界面管理</p></li><li><p>基础服务要保证稳定</p></li><li><p>支持”<a href="https://help.aliyun.com/document_detail/107125.html" target="_blank" rel="noopener">递归解析代理</a>“</p><ul><li>因为我们有相同域名内外网解析到不同IP的场景(最开始没有规划好)</li><li>比如api.aliyun.com <ul><li>公网解析到的是1.1.1.1(公网负载均衡)</li><li>内网配置的hosts是10.1.1.1(内网负载均衡)</li></ul></li></ul></li></ul><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>  起初想自建BIND提供DNS服务,不过简单测试了下BIND,发现BIND并不能满足我的需求:<strong>不支持递归解析代理功能</strong>, 因为BIND的Zone是由本地完全代理解析的,如果本地Zone配置里不存在对应的记录就会返回不存在,不会再去公网上去找结果并返回.(望大神指点)</p><p>  举个栗子🌰:</p><p>  例如，Zone名称为<strong>aliyun.com</strong>,在<strong>aliyun.com</strong>内配置了三条私有记录，如下表所示：</p><table><thead><tr><th align="left">主机记录</th><th align="left">类型</th><th align="left">TTL</th><th align="left">记录值</th></tr></thead><tbody><tr><td align="left">host01</td><td align="left">A</td><td align="left">60</td><td align="left">10.0.0.1</td></tr><tr><td align="left">host02</td><td align="left">A</td><td align="left">60</td><td align="left">10.0.0.2</td></tr><tr><td align="left">host03</td><td align="left">A</td><td align="left">60</td><td align="left">10.0.0.3</td></tr></tbody></table><ul><li>在VPC内查询 <strong>host01.aliyun.com,host02.aliyun.com 或者 host03.aliyun.com</strong>时，分别返回私有记录<strong>10.0.0.1,10.0.0.2,10.0.0.3</strong>。</li><li>在VPC内查询 <a href="http://www.aliyun.com" target="_blank" rel="noopener">www.aliyun.com</a>, api.aliyun.com ,rds.aliyun.com**等公共域名时，进行递归查询，以互联网实际域名解析结果为最终DNS响应结果。</li></ul><p>​    现在各大云厂商都支持内网DNS解析，阿里云现在也出了<strong>PrivateZone</strong>服务,不过是<strong>收费版</strong>,但PrivateZone有一个限制就是<strong>只能专有网络(VPC)使用</strong>,这就比较坑了,不过综合看了下PrivateZone的功能,发现完全<strong>满足我的需求</strong>,于是想方设法让让它支持经典网络</p><p>​    (这里解释下为什么非得要支持经典网络: 我们最开始就是使用经典网络,80%业务都在上面,计划迁移到VPC但还没开始实施,所以先解决DNS问题再说吧)</p><p>​    经过与阿里云沟通,发现他们官方没有什么建议可以实现,于是自己搞吧~</p><h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p><img src="https://upload-images.jianshu.io/upload_images/6840999-32d13a23e972e6c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="阿里云经典网络私有DNS服务方案.png"></p><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul><li>PrivateZone绑定VPC后,该VPC内的主机都可以支持自定义解析</li><li>通过在VPC里搭建BIND 代理到PrivateZone服务</li></ul><h2 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h2><h3 id="购买硬件资源"><a href="#购买硬件资源" class="headerlink" title="购买硬件资源"></a>购买硬件资源</h3><ol><li>创建一个专有网络(VPC)</li><li>创建一个DNS服务(PrivateZone)</li><li>创建阿里云服务器(ECS)搭建BIND服务,最低两台(主从架构)</li><li>创建一个负载均衡(SLB)监听UDP53</li><li>创建一台阿里云服务器(经典网络)(DNS 客户端)</li></ol><h3 id="Ansible安装BIND9-主从架构"><a href="#Ansible安装BIND9-主从架构" class="headerlink" title="Ansible安装BIND9 主从架构"></a>Ansible安装BIND9 主从架构</h3><p>以下为安装过程,具体见<a href="https://github.com/sungaomeng/ansible-dns.git" target="_blank" rel="noopener">GITHUB</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install ansible</span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;sungaomeng&#x2F;ansible-dns.git</span><br><span class="line">cd ansible-dns</span><br><span class="line">ansible all -m ping</span><br><span class="line">ansible-playbook deploy.yml</span><br></pre></td></tr></table></figure><p>注意在执行playbook前要修改ansible/hosts 配置</p><ol><li><p>forwarder_list</p><ul><li><p>转发dns的地址列表</p></li><li><p>将值修改为bind机器/etc/resolv.conf 中的nameserver地址</p></li></ul></li></ol><ol start="2"><li><p>internal_list</p><ul><li>内部网络地址列表，表示允许递归查询的客户端列表，一般为内部服务器ip所在的网段</li><li>将值修改为客户端IP段</li></ul></li><li><p>masters/slaves</p><ul><li>BIND主从IP地址</li></ul></li><li><p>ansible_ssh_port/user/pass</p><ul><li>如果没有配置SSH互信就指定SSH信息</li></ul></li></ol><h2 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h2><h3 id="querperf安装"><a href="#querperf安装" class="headerlink" title="querperf安装"></a>querperf安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://downloads.isc.org/isc/bind9/9.9.4/bind-9.9.4.tar.gz</span><br><span class="line">tar zxvf bind-9.9.4.tar.gz</span><br><span class="line">cd bind-9.9.4/contrib/queryperf</span><br><span class="line">./configure</span><br><span class="line">make</span><br></pre></td></tr></table></figure><h3 id="创建测试文件"><a href="#创建测试文件" class="headerlink" title="创建测试文件"></a>创建测试文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ./querytest.txt</span><br><span class="line">写入以下内容</span><br><span class="line">www.baidu.com A</span><br><span class="line">执行 :1,$y回车p</span><br><span class="line">复制到1w行~</span><br></pre></td></tr></table></figure><h3 id="执行测试"><a href="#执行测试" class="headerlink" title="执行测试"></a>执行测试</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./queryperf -q 20 -d ./querytest.txt -s 192.168.50.158 -l 100</span><br></pre></td></tr></table></figure><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">压测条件:</span><br><span class="line">  1. 时间: 100秒</span><br><span class="line">  2. 并发数: 120</span><br><span class="line">  3. 压测对象: SLB-&gt;单台2核4G DNS服务器</span><br><span class="line">结果:</span><br><span class="line">  1. CPU 68%</span><br><span class="line">  2. Mem 1.5%</span><br><span class="line">  3. QPS 2.2W</span><br><span class="line">  4. RTT average: 0.003891 sec</span><br><span class="line"> </span><br><span class="line">压测条件:</span><br><span class="line"> 1. 时间: 100秒</span><br><span class="line"> 2. 并发数: 160</span><br><span class="line"> 3. 压测对象: SLB-&gt;单台2核4G DNS服务器</span><br><span class="line">结果:</span><br><span class="line">  1. CPU 75%</span><br><span class="line">  2. Mem 1.5%</span><br><span class="line">  3. QPS 3.1W</span><br><span class="line">  4. RTT average: 0.004834 sec</span><br></pre></td></tr></table></figure><p><strong>（生产环境共有3台服务通过SLB提供服务,以上结果需要*3才是线上的瓶颈）</strong></p><h2 id="切换"><a href="#切换" class="headerlink" title="切换"></a>切换</h2><p>将经典网络ECS的/etc/resolv.conf nameserver地址改为负载均衡地址即可</p>]]></content>
      
      
      <categories>
          
          <category> DNS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DNS </tag>
            
            <tag> aliyun </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安装Canal HA集群并输出至Kafka</title>
      <link href="/canal/install-canal-to-kafka-HACluster/"/>
      <url>/canal/install-canal-to-kafka-HACluster/</url>
      
        <content type="html"><![CDATA[<h4 id="canal"><a href="#canal" class="headerlink" title="canal"></a>canal</h4><p>   canal [kə’næl]**，译意为水道/管道/沟渠，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费</p><p>早期阿里巴巴因为杭州和美国双机房部署，存在跨机房同步的业务需求，实现方式主要是基于业务 trigger 获取增量变更。从 2010 年开始，业务逐步尝试数据库日志解析获取增量变更进行同步，由此衍生出了大量的数据库增量订阅和消费业务。</p><p>基于日志增量订阅和消费的业务包括</p><ul><li>数据库镜像</li><li>数据库实时备份</li><li>索引构建和实时维护(拆分异构索引、倒排索引等)</li><li>业务 cache 刷新</li><li>带业务逻辑的增量数据处理</li></ul><p>当前的 canal 支持源端 MySQL 版本包括 5.1.x , 5.5.x , 5.6.x , 5.7.x , 8.0.x</p><h4 id="canal-工作原理"><a href="#canal-工作原理" class="headerlink" title="canal 工作原理"></a>canal 工作原理</h4><ul><li>canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议</li><li>MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )</li><li>canal 解析 binary log 对象(原始为 byte 流)</li></ul><p>Git: <a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">https://github.com/alibaba/canal</a></p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul><li><p>canal</p><ul><li>canal01 10.31.150.42</li><li>canal02 10.80.81.39</li></ul></li><li><p>kafka/zk</p><ul><li>192.168.52.146</li></ul></li><li><p>mysql</p><ul><li>****.mysql.rds.aliyuncs.com</li></ul></li></ul><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li>对于自建 MySQL , 需要先开启 Binlog 写入功能，配置 binlog-format 为 ROW 模式，my.cnf 中配置如下</li></ul>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">log-bin&#x3D;mysql-bin # 开启 binlog</span><br><span class="line">binlog-format&#x3D;ROW # 选择 ROW 模式</span><br><span class="line">server_id&#x3D;1 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复</span><br></pre></td></tr></table></figure><ul><li>注意：针对阿里云 RDS for MySQL , 默认打开了 binlog , 并且账号默认具有 binlog dump 权限 , 不需要任何权限或者 binlog 设置,可以直接跳过这一步</li></ul><ul><li><p>授权 canal 链接 MySQL 账号具有作为 MySQL slave 的权限, 如果已有账户可直接 grant</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE USER canal IDENTIFIED BY &#39;canal&#39;;  </span><br><span class="line">GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#39;canal&#39;@&#39;%&#39;;</span><br><span class="line">-- GRANT ALL PRIVILEGES ON *.* TO &#39;canal&#39;@&#39;%&#39; ;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure></li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul><li><p>下载 canal, 访问 <a href="[https://github.com/alibaba/canal/releases]">release</a> 页面, 选择需要的包下载, 如以 v1.1.3 版本为例 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;canal&#x2F;releases&#x2F;download&#x2F;canal-1.1.3&#x2F;canal.deployer-1.1.3.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>解压缩</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;usr&#x2F;local&#x2F;canal</span><br><span class="line">tar zxvf canal.deployer-$version.tar.gz  -C &#x2F;usr&#x2F;local&#x2F;canal</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>配置修改</p><ul><li><p>conf/example/instance.properties</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi conf&#x2F;example&#x2F;instance.properties</span><br><span class="line">#################################################</span><br><span class="line">## mysql serverId , v1.0.26+ will autoGen</span><br><span class="line"># canal.instance.mysql.slaveId&#x3D;</span><br><span class="line"></span><br><span class="line"># enable gtid use true&#x2F;false</span><br><span class="line">canal.instance.gtidon&#x3D;false</span><br><span class="line"></span><br><span class="line"># position info</span><br><span class="line">canal.instance.master.address&#x3D;****.mysql.rds.aliyuncs.com:3306 #改为需要同步的数据库地址</span><br><span class="line">canal.instance.master.journal.name&#x3D;</span><br><span class="line">canal.instance.master.position&#x3D;</span><br><span class="line">canal.instance.master.timestamp&#x3D;</span><br><span class="line">canal.instance.master.gtid&#x3D;</span><br><span class="line"></span><br><span class="line"># rds oss binlog</span><br><span class="line">canal.instance.rds.accesskey&#x3D;</span><br><span class="line">canal.instance.rds.secretkey&#x3D;</span><br><span class="line">canal.instance.rds.instanceId&#x3D;</span><br><span class="line"></span><br><span class="line"># table meta tsdb info</span><br><span class="line">canal.instance.tsdb.enable&#x3D;true</span><br><span class="line">#canal.instance.tsdb.url&#x3D;jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;canal_tsdb</span><br><span class="line">#canal.instance.tsdb.dbUsername&#x3D;canal</span><br><span class="line">#canal.instance.tsdb.dbPassword&#x3D;canal</span><br><span class="line"></span><br><span class="line">#canal.instance.standby.address &#x3D;</span><br><span class="line">#canal.instance.standby.journal.name &#x3D;</span><br><span class="line">#canal.instance.standby.position &#x3D;</span><br><span class="line">#canal.instance.standby.timestamp &#x3D;</span><br><span class="line">#canal.instance.standby.gtid&#x3D;</span><br><span class="line"></span><br><span class="line"># username&#x2F;password</span><br><span class="line">canal.instance.dbUsername&#x3D;canal  #改为数据库账户</span><br><span class="line">canal.instance.dbPassword&#x3D;****   #改为数据库密码</span><br><span class="line">canal.instance.connectionCharset &#x3D; UTF-8</span><br><span class="line"># enable druid Decrypt database password</span><br><span class="line">canal.instance.enableDruid&#x3D;false</span><br><span class="line">#canal.instance.pwdPublicKey&#x3D;MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5&#x2F;zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2&#x2F;JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line"># table regex</span><br><span class="line">canal.instance.filter.regex&#x3D;DBname.DBtable,DBname.DBtable #需要同步的表,多个表用逗号相隔,也可指定库下的全部表</span><br><span class="line"># table black regex</span><br><span class="line">canal.instance.filter.black.regex&#x3D;</span><br><span class="line"></span><br><span class="line"># mq config</span><br><span class="line">canal.mq.topic&#x3D;test #指定同步到kafka的哪个topic中</span><br><span class="line"># dynamic topic route by schema or table regex</span><br><span class="line">#canal.mq.dynamicTopic&#x3D;mytest1.user,mytest2\\..*,.*\\..*</span><br><span class="line">canal.mq.partition&#x3D;0 #默认输出到kafka topic的哪个partition中</span><br><span class="line"># hash partition config</span><br><span class="line">canal.mq.partitionsNum&#x3D;15 #topic的partition总数,如果canal.mq.partitionHash不启用,则此项没用</span><br><span class="line">canal.mq.partitionHash&#x3D;.*\\..*:id #使用id作为hash将数据分布到$partitionsNum个分区中</span><br><span class="line">#################################################</span><br></pre></td></tr></table></figure></li><li><p>关于mq config</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mq相关参数见官方说明：https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;canal&#x2F;wiki&#x2F;Canal-Kafka-RocketMQ-QuickStart</span><br><span class="line">关于topic:</span><br><span class="line">    可以指定正则将不同的数据输出到不同的表 canal.mq.dynamicTopic</span><br><span class="line">  如果没有指定则默认输出到canal.mq.topic表中</span><br><span class="line">    </span><br><span class="line">  关于partition:</span><br><span class="line">    可以根据hash算法将数据分布到多个partition中 canal.mq.partitionHash</span><br><span class="line">  如果不指定则默认输出到canal.mq.partition&#x3D;0 0分区中,这样会导致只有0分区有数据</span><br><span class="line">    因为我司对数据顺序没有要求,为了提高吞吐量,所以将id作为hash 将数据均匀的分布到了15个partition中</span><br><span class="line">  hash前：</span><br><span class="line">    $ &#x2F;data01&#x2F;server&#x2F;kafka&#x2F;bin&#x2F;kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list 192.168.52.146:9092 --topic test --time -1</span><br><span class="line">  test:0:37159</span><br><span class="line">    test:1:0</span><br><span class="line">  test:2:0</span><br><span class="line">    test:3:0</span><br><span class="line">  test:4:0</span><br><span class="line">    test:5:0</span><br><span class="line">    test:6:0</span><br><span class="line">    test:7:0</span><br><span class="line">    test:8:0</span><br><span class="line">    test:9:0</span><br><span class="line">    test:10:0</span><br><span class="line">    test:11:0</span><br><span class="line">    test:12:0</span><br><span class="line">    test:13:0</span><br><span class="line">    test:14:0</span><br><span class="line">    </span><br><span class="line">    hash之后:</span><br><span class="line">    $ &#x2F;data01&#x2F;server&#x2F;kafka&#x2F;bin&#x2F;kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list 192.168.52.146:9092 --topic test --time -1</span><br><span class="line">    test:0:98791</span><br><span class="line">    test:1:2689</span><br><span class="line">    test:2:2727</span><br><span class="line">    test:3:2831</span><br><span class="line">    test:4:2740</span><br><span class="line">    test:5:2464</span><br><span class="line">    test:6:2782</span><br><span class="line">    test:7:2846</span><br><span class="line">    test:8:3229</span><br><span class="line">    test:9:3183</span><br><span class="line">    test:10:2698</span><br><span class="line">    test:11:2801</span><br><span class="line">    test:12:3252</span><br><span class="line">    test:13:2347</span><br><span class="line">    test:14:2990</span><br></pre></td></tr></table></figure></li><li><p>conf/canal.properties</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#################################################</span><br><span class="line">#########               common argument         #############</span><br></pre></td></tr></table></figure><p>#################################################<br>#canal.manager.jdbc.url=jdbc:mysql://127.0.0.1:3306/canal_manager?useUnicode=true&amp;characterEncoding=UTF-8<br>#canal.manager.jdbc.username=root<br>#canal.manager.jdbc.password=121212<br>canal.id = 1<br>canal.ip =<br>canal.port = 11111<br>canal.metrics.pull.port = 11112<br>canal.zkServers = 192.168.52.146:2181  #修改为zookeeper集群的地址,可以写lb 也可以所有节点</p><h1 id="flush-data-to-zk"><a href="#flush-data-to-zk" class="headerlink" title="flush data to zk"></a>flush data to zk</h1><p>canal.zookeeper.flush.period = 1000<br>canal.withoutNetty = false</p><h1 id="tcp-kafka-RocketMQ"><a href="#tcp-kafka-RocketMQ" class="headerlink" title="tcp, kafka, RocketMQ"></a>tcp, kafka, RocketMQ</h1><p>canal.serverMode = kafka</p><h1 id="flush-meta-cursor-parse-position-to-file"><a href="#flush-meta-cursor-parse-position-to-file" class="headerlink" title="flush meta cursor/parse position to file"></a>flush meta cursor/parse position to file</h1><p>canal.file.data.dir = ${canal.conf.dir}<br>canal.file.flush.period = 1000</p><h2 id="memory-store-RingBuffer-size-should-be-Math-pow-2-n"><a href="#memory-store-RingBuffer-size-should-be-Math-pow-2-n" class="headerlink" title="memory store RingBuffer size, should be Math.pow(2,n)"></a>memory store RingBuffer size, should be Math.pow(2,n)</h2><p>canal.instance.memory.buffer.size = 16384</p><h2 id="memory-store-RingBuffer-used-memory-unit-size-default-1kb"><a href="#memory-store-RingBuffer-used-memory-unit-size-default-1kb" class="headerlink" title="memory store RingBuffer used memory unit size , default 1kb"></a>memory store RingBuffer used memory unit size , default 1kb</h2><p>canal.instance.memory.buffer.memunit = 1024 </p><h2 id="meory-store-gets-mode-used-MEMSIZE-or-ITEMSIZE"><a href="#meory-store-gets-mode-used-MEMSIZE-or-ITEMSIZE" class="headerlink" title="meory store gets mode used MEMSIZE or ITEMSIZE"></a>meory store gets mode used MEMSIZE or ITEMSIZE</h2><p>canal.instance.memory.batch.mode = MEMSIZE<br>canal.instance.memory.rawEntry = true</p><h2 id="detecing-config"><a href="#detecing-config" class="headerlink" title="detecing config"></a>detecing config</h2><p>canal.instance.detecting.enable = false<br>#canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()<br>canal.instance.detecting.sql = select 1<br>canal.instance.detecting.interval.time = 3<br>canal.instance.detecting.retry.threshold = 3<br>canal.instance.detecting.heartbeatHaEnable = false</p><h1 id="support-maximum-transaction-size-more-than-the-size-of-the-transaction-will-be-cut-into-multiple-transactions-delivery"><a href="#support-maximum-transaction-size-more-than-the-size-of-the-transaction-will-be-cut-into-multiple-transactions-delivery" class="headerlink" title="support maximum transaction size, more than the size of the transaction will be cut into multiple transactions delivery"></a>support maximum transaction size, more than the size of the transaction will be cut into multiple transactions delivery</h1><p>canal.instance.transaction.size =  1024</p><h1 id="mysql-fallback-connected-to-new-master-should-fallback-times"><a href="#mysql-fallback-connected-to-new-master-should-fallback-times" class="headerlink" title="mysql fallback connected to new master should fallback times"></a>mysql fallback connected to new master should fallback times</h1><p>canal.instance.fallbackIntervalInSeconds = 60</p><h1 id="network-config"><a href="#network-config" class="headerlink" title="network config"></a>network config</h1><p>canal.instance.network.receiveBufferSize = 16384<br>canal.instance.network.sendBufferSize = 16384<br>canal.instance.network.soTimeout = 30</p><h1 id="binlog-filter-config"><a href="#binlog-filter-config" class="headerlink" title="binlog filter config"></a>binlog filter config</h1><p>canal.instance.filter.druid.ddl = true<br>canal.instance.filter.query.dcl = false<br>canal.instance.filter.query.dml = false<br>canal.instance.filter.query.ddl = false<br>canal.instance.filter.table.error = false<br>canal.instance.filter.rows = false<br>canal.instance.filter.transaction.entry = false</p><h1 id="binlog-format-image-check"><a href="#binlog-format-image-check" class="headerlink" title="binlog format/image check"></a>binlog format/image check</h1><p>canal.instance.binlog.format = ROW,STATEMENT,MIXED<br>canal.instance.binlog.image = FULL,MINIMAL,NOBLOB</p><h1 id="binlog-ddl-isolation"><a href="#binlog-ddl-isolation" class="headerlink" title="binlog ddl isolation"></a>binlog ddl isolation</h1><p>canal.instance.get.ddl.isolation = false</p><h1 id="parallel-parser-config"><a href="#parallel-parser-config" class="headerlink" title="parallel parser config"></a>parallel parser config</h1><p>canal.instance.parser.parallel = true</p><h2 id="concurrent-thread-number-default-60-available-processors-suggest-not-to-exceed-Runtime-getRuntime-availableProcessors"><a href="#concurrent-thread-number-default-60-available-processors-suggest-not-to-exceed-Runtime-getRuntime-availableProcessors" class="headerlink" title="concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()"></a>concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()</h2><p>#canal.instance.parser.parallelThreadSize = 16</p><h2 id="disruptor-ringbuffer-size-must-be-power-of-2"><a href="#disruptor-ringbuffer-size-must-be-power-of-2" class="headerlink" title="disruptor ringbuffer size, must be power of 2"></a>disruptor ringbuffer size, must be power of 2</h2><p>canal.instance.parser.parallelBufferSize = 256</p><h1 id="table-meta-tsdb-info"><a href="#table-meta-tsdb-info" class="headerlink" title="table meta tsdb info"></a>table meta tsdb info</h1><p>canal.instance.tsdb.enable = true<br>canal.instance.tsdb.dir = ${canal.file.data.dir:../conf}/${canal.instance.destination:}<br>canal.instance.tsdb.url = jdbc:h2:${canal.instance.tsdb.dir}/h2;CACHE_SIZE=1000;MODE=MYSQL;<br>canal.instance.tsdb.dbUsername = canal<br>canal.instance.tsdb.dbPassword = canal</p><h1 id="dump-snapshot-interval-default-24-hour"><a href="#dump-snapshot-interval-default-24-hour" class="headerlink" title="dump snapshot interval, default 24 hour"></a>dump snapshot interval, default 24 hour</h1><p>canal.instance.tsdb.snapshot.interval = 24</p><h1 id="purge-snapshot-expire-default-360-hour-15-days"><a href="#purge-snapshot-expire-default-360-hour-15-days" class="headerlink" title="purge snapshot expire , default 360 hour(15 days)"></a>purge snapshot expire , default 360 hour(15 days)</h1><p>canal.instance.tsdb.snapshot.expire = 360</p><h1 id="aliyun-ak-sk-support-rds-mq"><a href="#aliyun-ak-sk-support-rds-mq" class="headerlink" title="aliyun ak/sk , support rds/mq"></a>aliyun ak/sk , support rds/mq</h1><p>canal.aliyun.accessKey =<br>canal.aliyun.secretKey =</p><p>#################################################<br>#########               destinations            #############<br>#################################################<br>canal.destinations = example</p><h1 id="conf-root-dir"><a href="#conf-root-dir" class="headerlink" title="conf root dir"></a>conf root dir</h1><p>canal.conf.dir = ../conf</p><h1 id="auto-scan-instance-dir-add-remove-and-start-stop-instance"><a href="#auto-scan-instance-dir-add-remove-and-start-stop-instance" class="headerlink" title="auto scan instance dir add/remove and start/stop instance"></a>auto scan instance dir add/remove and start/stop instance</h1><p>canal.auto.scan = true<br>canal.auto.scan.interval = 5</p><p>canal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xml<br>#canal.instance.tsdb.spring.xml = classpath:spring/tsdb/mysql-tsdb.xml</p><p>canal.instance.global.mode = spring<br>canal.instance.global.lazy = false<br>#canal.instance.global.manager.address = 127.0.0.1:1099<br>#canal.instance.global.spring.xml = classpath:spring/memory-instance.xml<br>canal.instance.global.spring.xml = classpath:spring/file-instance.xml<br>#canal.instance.global.spring.xml = classpath:spring/default-instance.xml</p><p>##################################################<br>#########                    MQ                      #############<br>##################################################<br>canal.mq.servers = 192.168.52.146:9092 #修改为kafka集群的地址,可以写lb 也可以所有节点<br>canal.mq.retries = 0<br>canal.mq.batchSize = 16384<br>canal.mq.maxRequestSize = 1048576<br>canal.mq.lingerMs = 100<br>canal.mq.bufferMemory = 33554432<br>canal.mq.canalBatchSize = 50<br>canal.mq.canalGetTimeout = 100<br>canal.mq.flatMessage = true<br>canal.mq.compressionType = none<br>canal.mq.acks = all</p><h1 id="use-transaction-for-kafka-flatMessage-batch-produce"><a href="#use-transaction-for-kafka-flatMessage-batch-produce" class="headerlink" title="use transaction for kafka flatMessage batch produce"></a>use transaction for kafka flatMessage batch produce</h1><p>canal.mq.transaction = false<br>#canal.mq.properties. =</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 关于mq 配置2</span><br></pre></td></tr></table></figure><p>canal是使用zookeeper来保证HA的<br>关于HA 见官网说明 “HA机制设计”部分 <a href="https://github.com/alibaba/canal/wiki/%E7%AE%80%E4%BB%8B" target="_blank" rel="noopener">https://github.com/alibaba/canal/wiki/%E7%AE%80%E4%BB%8B</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">## 启动</span><br><span class="line"></span><br><span class="line">- 启动第一台机器 canal02</span><br></pre></td></tr></table></figure><p>/usr/local/canal/bin/startup.sh</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 查看日志</span><br></pre></td></tr></table></figure><p>OpenJDK 64-Bit Server VM warning: ignoring option PermSize=96m; support was removed in 8.0</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- zookeeper状态</span><br></pre></td></tr></table></figure><p>[zk: localhost:2181(CONNECTED) 2] ls /otter/canal/cluster<br>[10.31.150.42:11111]<br>[zk: localhost:2181(CONNECTED) 3] get /otter/canal/destinations/example/running<br>{“active”:true,”address”:”10.31.150.42:11111”,”cid”:1}</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line">- kafka状态</span><br></pre></td></tr></table></figure><p>$ /data01/server/kafka/bin/kafka-run-class.sh kafka.tools.GetOffsetShell –broker-list 192.168.52.146:9092 –topic test –time -1<br>test:0:98791<br>test:1:2689<br>test:2:2727<br>test:3:2831<br>test:4:2740<br>test:5:2464<br>test:6:2782<br>test:7:2846<br>test:8:3229<br>test:9:3183<br>test:10:2698<br>test:11:2801<br>test:12:3252<br>test:13:2347<br>test:14:2990</p></li></ul><p>每个分区都产生了数据</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line">-  启动第二台机器 canal01</span><br></pre></td></tr></table></figure><p>/usr/local/canal/bin/startup.sh</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 查看日志</span><br></pre></td></tr></table></figure><p> [root@offline-gateway-canal-01 canal]# cat logs/canal/canal.log<br>  OpenJDK 64-Bit Server VM warning: ignoring option PermSize=96m; support was removed in 8.0<br>  OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0<br>  OpenJDK 64-Bit Server VM warning: UseCMSCompactAtFullCollection is deprecated and will likely be removed in a future release.<br>  2019-07-18 16:00:29.563 [main] INFO  com.alibaba.otter.canal.deployer.CanalLauncher - ## set default uncaught exception handler<br>  2019-07-18 16:00:29.601 [main] INFO  com.alibaba.otter.canal.deployer.CanalLauncher - ## load canal configurations<br>  2019-07-18 16:00:29.608 [main] INFO  c.a.o.c.d.monitor.remote.RemoteConfigLoaderFactory - ## load local canal configurations<br>  2019-07-18 16:00:29.622 [main] INFO  com.alibaba.otter.canal.deployer.CanalStater - ## start the canal server.<br>  2019-07-18 16:00:29.789 [main] INFO  com.alibaba.otter.canal.deployer.CanalController - ## start the canal server[10.31.150.42:11111]<br>  2019-07-18 16:00:30.433 [main] WARN  o.s.beans.GenericTypeAwarePropertyDescriptor - Invalid JavaBean property ‘connectionCharset’ being accessed! Ambiguous write methods found next to actually used [public void com.alibaba.otter.canal.parse.inbound.mysql.AbstractMysqlEventParser.setConnectionCharset(java.nio.charset.Charset)]: [public void com.alibaba.otter.canal.parse.inbound.mysql.AbstractMysqlEventParser.setConnectionCharset(java.lang.String)]<br>  2019-07-18 16:00:30.655 [main] ERROR com.alibaba.druid.pool.DruidDataSource - testWhileIdle is true, validationQuery not set<br>  2019-07-18 16:00:30.892 [main] WARN  c.a.o.canal.parse.inbound.mysql.dbsync.LogEventConvert - –&gt; init table filter : ^.<em>..</em>$<br>  2019-07-18 16:00:30.892 [main] WARN  c.a.o.canal.parse.inbound.mysql.dbsync.LogEventConvert - –&gt; init table black filter :<br>  2019-07-18 16:00:30.899 [main] INFO  com.alibaba.otter.canal.deployer.CanalStater - ## the canal server is running now ……<br>  2019-07-18 16:00:30.906 [destination = metrics , address = null , EventParser] ERROR c.a.o.c.p.inbound.mysql.rds.RdsBinlogEventParserProxy - parse events has an error<br>  com.alibaba.otter.canal.parse.exception.CanalParseException: illegal connection is null<br>  2019-07-18 16:00:30.979 [canal-instance-scan-0] INFO  c.a.o.canal.deployer.monitor.SpringInstanceConfigMonitor - auto notify stop metrics successful.</p>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- zookeeper状态</span><br></pre></td></tr></table></figure><p>  [zk: localhost:2181(CONNECTED) 2] ls /otter/canal/cluster<br>  [10.31.150.42:11111, 10.80.81.39:11111]<br>  [zk: localhost:2181(CONNECTED) 3] get /otter/canal/destinations/example/running<br>  {“active”:true,”address”:”10.80.81.39:11111”,”cid”:1}</p><pre><code></code></pre></li></ul><h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><p>​    启动第一台时开始订阅binlog并实时输出到kafka,并将信息注册到zk</p><p>​    启动第二胎时第二台从zk获取到example已经被注册,所以等待下次再查询状态</p><p>​    第一台stop之后,第二台从zk检查到example没有被注册,所以上任开始订阅binlog并输出到kafka,并将信息注册到zk</p>]]></content>
      
      
      <categories>
          
          <category> canal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> canal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速删除单目录下大量碎文件</title>
      <link href="/shell/quickly-delete-lot-files/"/>
      <url>/shell/quickly-delete-lot-files/</url>
      
        <content type="html"><![CDATA[<h2 id="缘由"><a href="#缘由" class="headerlink" title="缘由"></a>缘由</h2><p>生产环境中使用到了阿里云的NAS服务,有大量碎文件存储到了NAS中</p><p>后来NAS收费太贵,将历史数据迁移到了OSS中</p><p>现在需要删除NAS中的碎文件</p><p>大约150T,30亿个文件</p><h2 id="删除过程"><a href="#删除过程" class="headerlink" title="删除过程"></a>删除过程</h2><h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shutil.rmtree(/nas/data/<span class="number">2019</span><span class="number">-01</span><span class="number">-01</span>/)</span><br></pre></td></tr></table></figure><h3 id="rsync"><a href="#rsync" class="headerlink" title="rsync"></a>rsync</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rsync -a --delete /opt/empty/ /nas/data/2019-01-01/</span><br></pre></td></tr></table></figure><h3 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;nas&#x2F;data&#x2F;2019-01-01&#x2F;</span><br></pre></td></tr></table></figure><p>最终尝试了以上三种方法，发现非常非常慢</p><p>通过strace命令发现进程主要在做<strong>getdents</strong>(readdir)操作(获取文件列表)</p><p>另外提一句如果是本地数据还好,阿里云NAS针对readdir操作做了部分限制,导致获取文件列表巨慢···</p><p>怎么发现的呢？</p><p>我启动了20个线程去获取20个目录下的文件列表,发现机器与NAS之间的流量只能到30Mb,后来又启动了40个线程也是到30Mb,然后跟阿里云沟通后他们需要单独调整参数才能优化读取操作,因为调整需要reload nas服务,对线上有影响,我就放弃了没让他们做···</p><h2 id="内核参数调优"><a href="#内核参数调优" class="headerlink" title="内核参数调优"></a>内核参数调优</h2><p>因为阿里云NAS最终是以NFS的方式提供服务</p><p>所以官方建议调整OS kernel的限制</p><h3 id="Kernel-2-6-Centos6-左右的内核限制为128"><a href="#Kernel-2-6-Centos6-左右的内核限制为128" class="headerlink" title="Kernel 2.6(Centos6)左右的内核限制为128"></a>Kernel 2.6(Centos6)左右的内核限制为128</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;options sunrpc tcp_slot_table_entries&#x3D;128&quot; &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;sunrpc.conf</span><br><span class="line">echo &quot;options sunrpc tcp_max_slot_table_entries&#x3D;128&quot; &gt;&gt;  &#x2F;etc&#x2F;modprobe.d&#x2F;sunrpc.conf</span><br><span class="line">sysctl -w sunrpc.tcp_slot_table_entries&#x3D;128</span><br></pre></td></tr></table></figure><h3 id="Kernel-3-Centos7-的内核限制为65535"><a href="#Kernel-3-Centos7-的内核限制为65535" class="headerlink" title="Kernel 3(Centos7)的内核限制为65535"></a>Kernel 3(Centos7)的内核限制为65535</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;options sunrpc tcp_slot_table_entries&#x3D;65535&quot; &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;sunrpc.conf</span><br><span class="line">echo &quot;options sunrpc tcp_max_slot_table_entries&#x3D;65535&quot; &gt;&gt;  &#x2F;etc&#x2F;modprobe.d&#x2F;sunrpc.conf</span><br><span class="line">sysctl -w sunrpc.tcp_slot_table_entries&#x3D;65535</span><br></pre></td></tr></table></figure><p>修改参数后需要<strong>重新挂载</strong>NAS或者<strong>重启系统</strong></p><p>具体说明见<a href="https://help.aliyun.com/knowledge_detail/53839.html?spm=a2c4g.11186631.2.16.4218622fLlHtQZ" target="_blank" rel="noopener">阿里云文档</a></p><h2 id="最佳方案"><a href="#最佳方案" class="headerlink" title="最佳方案"></a>最佳方案</h2><h3 id="先获取文件列表后并发删除"><a href="#先获取文件列表后并发删除" class="headerlink" title="先获取文件列表后并发删除"></a>先获取文件列表后并发删除</h3><h4 id="1-获取文件列表"><a href="#1-获取文件列表" class="headerlink" title="1. 获取文件列表"></a>1. 获取文件列表</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -1 -f DIR</span><br></pre></td></tr></table></figure><p>为什么要加后面的两个参数？</p><p>默认情况下，“ <strong>ls</strong> ”命令将对其输出进行排序。要做到这一点，它必须首先将每个文件的名称篡改到内存中。面对一个非常大的目录，它将坐在那里，读取文件名，占用越来越多的内存，直到最终按字母数字顺序一次列出所有文件。</p><p>而<strong>ls -1 -f</strong> 则不执行任何排序。它只是读取目录并立即显示文件。</p><p>具体测试文档请参考<a href="[http://unixetc.co.uk/2012/05/20/large-directory-causes-ls-to-hang/](http://unixetc.co.uk/2012/05/20/large-directory-causes-ls-to-hang/)">大神文档</a></p><h4 id="2-切分文件"><a href="#2-切分文件" class="headerlink" title="2.切分文件"></a>2.切分文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">split -l 10000000 -d list split-tmp-</span><br><span class="line"><span class="meta">#</span><span class="bash"> 100w行一个文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件名以<span class="string">"split-tmp-"</span>开头</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件名以数字结尾</span></span><br></pre></td></tr></table></figure><h4 id="3-并发删除"><a href="#3-并发删除" class="headerlink" title="3.并发删除"></a>3.并发删除</h4><p><strong>shell 实现进程并发控制</strong></p><p>关于shell的多进程并发见<a href="https://bbs.51cto.com/thread-1104907-1-1.html" target="_blank" rel="noopener">大神文档</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">定义日志</span></span><br><span class="line">Log=./rm.log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">指定并发数量</span></span><br><span class="line">Nproc=20</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">接受信号2 （ctrl +C)做的操作</span></span><br><span class="line">trap "exec 1000&gt;$-;exec 1000&lt;&amp;-;exit 0" 2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">$$是进程pid</span></span><br><span class="line">Pfifo="/tmp/$$.fifo"</span><br><span class="line">mkfifo $Pfifo</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">以1000为文件描述符打开管道,&lt;&gt;表示可读可写</span></span><br><span class="line">exec 1000&lt;&gt;$Pfifo</span><br><span class="line">rm -f $Pfifo</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">向管道中写入Nproc行,作为令牌</span></span><br><span class="line">for((i=1; i&lt;=$Nproc; i++)); do</span><br><span class="line">    echo</span><br><span class="line">done &gt;&amp;1000</span><br><span class="line"></span><br><span class="line">filenames=`ls split-tmp-*`</span><br><span class="line">for filename in $filenames; do</span><br><span class="line"><span class="meta">#</span><span class="bash">从管道中取出1行作为token，如果管道为空，<span class="built_in">read</span>将会阻塞</span></span><br><span class="line"><span class="meta">#</span><span class="bash">man bash可以知道-u是从fd中读取一行</span></span><br><span class="line">    read -u1000</span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">    #所要执行的任务</span><br><span class="line">        DirPrefix=/nas/data</span><br><span class="line">        while read line;do</span><br><span class="line">            rm -I $DirPrefix/$line || echo "`date +%F-%T` rm -rf $DirPrefix/$line failed" | tee &gt;&gt; $Log</span><br><span class="line">        done &lt; $filename  &amp;&amp; &#123;</span><br><span class="line">            echo "`date +%F-%T` $filename done" | tee &gt;&gt; $Log</span><br><span class="line">        &#125; || &#123;</span><br><span class="line">            echo "`date +%F-%T` $filename error" | tee &gt;&gt; $Log</span><br><span class="line">        &#125;</span><br><span class="line">        sleep 5</span><br><span class="line">    #归还token</span><br><span class="line">        echo &gt;&amp;1000</span><br><span class="line">    &#125;&amp;</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">等待所有子进程结束</span></span><br><span class="line">wait </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">关闭管道</span></span><br><span class="line">exec 1000&gt;&amp;-</span><br><span class="line">exec 1000&lt;&amp;-</span><br></pre></td></tr></table></figure><h2 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h2><p>建议文件量特别多时分开目录存储,不然后续处理会很棘手</p><p>代码多写一点,为后来人多考虑一点</p><h3 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data&#x2F;年-月-日&#x2F;[0-1023]&#x2F;file</span><br></pre></td></tr></table></figure><p>针对这种情况,单个目录下可能只有一两万个文件</p><p>可以用python并发删除</p><p>实测: 每分钟删除NAS里2.6w个文件</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">target_path = <span class="string">"/data/"</span></span><br><span class="line"></span><br><span class="line">pathnames = os.listdir(target_path)</span><br><span class="line">today = datetime.datetime.now()</span><br><span class="line">month_ago = today + datetime.timedelta(days=<span class="number">-30</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dirdel</span><span class="params">(tpath)</span>:</span></span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"start delete:"</span>,tpath</span><br><span class="line">    shutil.rmtree(tpath)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"deleted: %s in %s"</span>%(tpath,time.time()-t1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date_path <span class="keyword">in</span> pathnames:</span><br><span class="line">    tmp_path = target_path+date_path</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(tmp_path):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> (datetime.datetime.strptime(date_path, <span class="string">"%Y-%m-%d"</span>)&lt;month_ago):</span><br><span class="line">        print(tmp_path)</span><br><span class="line">        <span class="keyword">while</span> len(threading.enumerate())&gt;<span class="number">40</span>:</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"waiting..."</span></span><br><span class="line">            time.sleep(<span class="number">30</span>)</span><br><span class="line">        threading.Thread(target=dirdel, args=(tmp_path,)).start()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>filebeat-限制CPU使用</title>
      <link href="/efk/filebeat/limit-cpu/"/>
      <url>/efk/filebeat/limit-cpu/</url>
      
        <content type="html"><![CDATA[<h2 id="缘由"><a href="#缘由" class="headerlink" title="缘由"></a>缘由</h2><p>日志量大的时时候filebeat会占用非常高的CPU,为了防止影响业务稳定,决定对filebeat的CPU进行限制核数</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="限制使用的cpu核数"><a href="#限制使用的cpu核数" class="headerlink" title="限制使用的cpu核数"></a>限制使用的cpu核数</h3><p>​    filebeat.yml文件中可以指定”max_procs”参数</p><p>​    max_procs: 限制filebeat的进程数量,其实就是内核数</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">max_procs: 1</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- input_type: log</span><br><span class="line">  #include_lines: [&quot;^\\[[0-9]&#123;4&#125;&quot;]</span><br><span class="line">  tail_files: true</span><br><span class="line">  paths:</span><br><span class="line">    - &#x2F;var&#x2F;log&#x2F;*.log</span><br><span class="line">  fields:</span><br><span class="line">    device: pudding1s</span><br><span class="line">  fields_under_root: true</span><br><span class="line">  document_type: log</span><br></pre></td></tr></table></figure><h3 id="降低filebeat进程优先级"><a href="#降低filebeat进程优先级" class="headerlink" title="降低filebeat进程优先级"></a>降低filebeat进程优先级</h3><h4 id="启动时指定进程优先级"><a href="#启动时指定进程优先级" class="headerlink" title="启动时指定进程优先级"></a>启动时指定进程优先级</h4><p>​    使用nice命令</p><p>​    使用方法: nice -n 命令</p><p>​    优先级由 -20~19这个范围来表示优先级大小，数值越小，优先级越高(默认0)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /etc/init.d/filebeat </span></span><br><span class="line">···</span><br><span class="line">start() &#123; </span><br><span class="line">    [ -x $filebeat ] || exit 5 </span><br><span class="line">    [ -f $FILEBEAT_CONF_FILE ] || exit 6 </span><br><span class="line">    echo -n $"Starting $prog: " </span><br><span class="line">    #daemon $filebeat -c $FILEBEAT_CONF_FILE </span><br><span class="line">    nice -n 10 nohup $filebeat -c $FILEBEAT_CONF_FILE &gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line">    retval=$? </span><br><span class="line">    echo </span><br><span class="line">    [ $retval -eq 0 ] &amp;&amp; touch $lockfile </span><br><span class="line">    return $retval </span><br><span class="line">&#125; </span><br><span class="line">···</span><br></pre></td></tr></table></figure><h4 id="启动后手动调整进程优先级"><a href="#启动后手动调整进程优先级" class="headerlink" title="启动后手动调整进程优先级"></a>启动后手动调整进程优先级</h4><p>​    使用renice 命令</p><p>​    使用方法: renice 优先级  进程PID</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FilebeatPid&#x3D;&#96;ps -ef |grep filebeat |grep -v grep |awk &#39;&#123;print $2&#125;&#39;&#96;</span><br><span class="line">renice 10 $FilebeatPid</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> EFK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EFK </tag>
            
            <tag> filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>filebeat-重新收取某个日志文件</title>
      <link href="/efk/filebeat/reload-log/"/>
      <url>/efk/filebeat/reload-log/</url>
      
        <content type="html"><![CDATA[<h2 id="缘由"><a href="#缘由" class="headerlink" title="缘由"></a>缘由</h2><p>filebeat想重新收取某个文件,或者从指定位置重新收取某个文件</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="全部重新收取"><a href="#全部重新收取" class="headerlink" title="全部重新收取"></a>全部重新收取</h3><p>​    删除registry文件并重启filebeat</p><p>​    PS: 这种方法会将所有文件重新收取</p><h3 id="重新收取单个文件"><a href="#重新收取单个文件" class="headerlink" title="重新收取单个文件"></a>重新收取单个文件</h3><p>​    修改registry文件中对应文件的offset信息并重启filebeat</p><p>​    PS: 关于registry文件的格式参见”<a href="https://blog.opsolo.com/efk/filebeat/filebeat-registry文件内容解析" target="_blank" rel="noopener">registry文件内容解析</a>“</p><p>​    offset修改为0则代表从头开始,或者指定offset从指定位置收取</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">    <span class="attr">"source"</span>:<span class="string">"/var/log/php/laravel-2019-05-19.log"</span>,</span><br><span class="line">    <span class="attr">"offset"</span>:<span class="number">1632</span>,</span><br><span class="line">    <span class="attr">"FileStateOS"</span>:&#123;</span><br><span class="line">        <span class="attr">"inode"</span>:<span class="number">4353086</span>,</span><br><span class="line">        <span class="attr">"device"</span>:<span class="number">64529</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"timestamp"</span>:<span class="string">"2019-05-19T12:35:34.724025571+08:00"</span>,</span><br><span class="line">    <span class="attr">"ttl"</span>:<span class="number">-1</span></span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> EFK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EFK </tag>
            
            <tag> filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>filebeat-registry文件内容解析</title>
      <link href="/efk/filebeat/registry-content-analysis/"/>
      <url>/efk/filebeat/registry-content-analysis/</url>
      
        <content type="html"><![CDATA[<h2 id="filebeat中registry文件的作用"><a href="#filebeat中registry文件的作用" class="headerlink" title="filebeat中registry文件的作用"></a>filebeat中registry文件的作用</h2><p>registry文件中存放的被采集的所有日志文件的相关信息</p><h2 id="文件内容解析"><a href="#文件内容解析" class="headerlink" title="文件内容解析"></a>文件内容解析</h2><h3 id="内容样例"><a href="#内容样例" class="headerlink" title="内容样例"></a>内容样例</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">    <span class="attr">"source"</span>:<span class="string">"/var/log/php/laravel-2019-05-19.log"</span>,</span><br><span class="line">    <span class="attr">"offset"</span>:<span class="number">1632</span>,</span><br><span class="line">    <span class="attr">"FileStateOS"</span>:&#123;</span><br><span class="line">        <span class="attr">"inode"</span>:<span class="number">4353086</span>,</span><br><span class="line">        <span class="attr">"device"</span>:<span class="number">64529</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"timestamp"</span>:<span class="string">"2019-05-19T12:35:34.724025571+08:00"</span>,</span><br><span class="line">    <span class="attr">"ttl"</span>:<span class="number">-1</span></span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure><h3 id="字段说明"><a href="#字段说明" class="headerlink" title="字段说明"></a>字段说明</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source 日志文件的完整路径</span><br><span class="line">offset　已经采集到日志的哪个字节位置</span><br><span class="line">FileStateOS　　操作系统相关</span><br><span class="line">　　inode　　   日志文件的inode号</span><br><span class="line">　　device     日志所在磁盘的磁盘编号</span><br><span class="line">timestamp　日志最后一次发生变化的时间戳</span><br><span class="line">ttl　　    采集失效时间。(-1表示只要日志存在，就一直采集该日志)</span><br></pre></td></tr></table></figure><h4 id="FileStateOS信息"><a href="#FileStateOS信息" class="headerlink" title="FileStateOS信息"></a>FileStateOS信息</h4><p>filestatOS可以通过stat命令获取</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@test /]# stat /var/log/php/laravel-2019-05-19.log</span><br><span class="line">  File: `/var/log/php/laravel-2019-05-19.log'</span><br><span class="line">  Size: 1632            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: fc11h/64529d    Inode: 4353086     Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (  500/     www)   Gid: (  500/     www)</span><br><span class="line">Access: 2019-05-19 12:30:27.517385737 +0800</span><br><span class="line">Modify: 2019-05-19 12:30:25.992385735 +0800</span><br><span class="line">Change: 2019-05-19 12:30:25.992385735 +0800</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> EFK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EFK </tag>
            
            <tag> filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo Gitalk 评论自动初始化</title>
      <link href="/hexo/hexo-gitalk-auto-init/"/>
      <url>/hexo/hexo-gitalk-auto-init/</url>
      
        <content type="html"><![CDATA[<blockquote><p>切换到Gitalk后每次都需要手动去创建issue,为了简化流程,使用Nodejs和GithubAPI去自动初始化</p><p>参考原文：<a href="https://daihaoxin.github.io/post/322747ae.html" target="_blank" rel="noopener">daihaoxin</a></p></blockquote><h3 id="一、生成sitemap站点地图"><a href="#一、生成sitemap站点地图" class="headerlink" title="一、生成sitemap站点地图"></a>一、生成sitemap站点地图</h3><h4 id="1-安装插件"><a href="#1-安装插件" class="headerlink" title="1. 安装插件"></a>1. 安装插件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br><span class="line">npm install hexo-generator-baidu-sitemap --save</span><br></pre></td></tr></table></figure><h4 id="2-在站点根目录下的-config-yml添加如下代码"><a href="#2-在站点根目录下的-config-yml添加如下代码" class="headerlink" title="2. 在站点根目录下的_config.yml添加如下代码"></a>2. 在站点根目录下的_config.yml添加如下代码</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hexo sitemap网站地图</span></span><br><span class="line"><span class="attr">sitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">sitemap.xml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">baidusitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">baidusitemap.xml</span></span><br></pre></td></tr></table></figure><p>现在在执行<code>hexo generate</code>的时候，在博客根目录下的public文件夹下面，就会生成sitemap.xml和baidusitemap.xml。</p><h3 id="二、获取github接口的调用权限"><a href="#二、获取github接口的调用权限" class="headerlink" title="二、获取github接口的调用权限"></a>二、获取github接口的调用权限</h3><ol><li>创建一个access token <a href="https://github.com/settings/tokens" target="_blank" rel="noopener">点此进入</a></li><li>点击Generate new token按钮</li><li>输入一个描述，为token添加所有的<code>repo</code>权限，然后点击最下方的<code>Generate token</code>按钮，就可以生成一个新的Token</li><li>Token在下面的脚本会用到</li></ol><h3 id="三、部署脚本"><a href="#三、部署脚本" class="headerlink" title="三、部署脚本"></a>三、部署脚本</h3><h4 id="1-安装依赖包"><a href="#1-安装依赖包" class="headerlink" title="1. 安装依赖包"></a>1. 安装依赖包</h4><p>  在你hexo的根目录，执行下面的命令</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install request --save</span><br><span class="line">npm install xml-parser --save</span><br><span class="line">npm install yamljs --save</span><br><span class="line">npm install cheerio --save</span><br><span class="line">npm install md5 --save</span><br></pre></td></tr></table></figure><h4 id="2-创建脚本文件"><a href="#2-创建脚本文件" class="headerlink" title="2. 创建脚本文件"></a>2. 创建脚本文件</h4><p>  在站点根目录下创建comment.js文件，将下面的代码粘贴进文件中，然后修改config中的配置项，其中<code>token</code>就是上一步中获取的值</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env node</span></span><br><span class="line"><span class="keyword">const</span> request = <span class="built_in">require</span>(<span class="string">"request"</span>);</span><br><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">"fs"</span>);</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">"path"</span>);</span><br><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">"url"</span>);</span><br><span class="line"><span class="keyword">const</span> xmlParser = <span class="built_in">require</span>(<span class="string">"xml-parser"</span>);</span><br><span class="line"><span class="keyword">const</span> YAML = <span class="built_in">require</span>(<span class="string">"yamljs"</span>);</span><br><span class="line"><span class="keyword">const</span> cheerio = <span class="built_in">require</span>(<span class="string">"cheerio"</span>);</span><br><span class="line"><span class="keyword">const</span> md5 = <span class="built_in">require</span>(<span class="string">"md5"</span>);</span><br><span class="line"><span class="comment">// 根据自己的情况进行配置</span></span><br><span class="line"><span class="keyword">const</span> config = &#123;</span><br><span class="line">    username: <span class="string">"sungaomeng"</span>, <span class="comment">// GitHub 用户名</span></span><br><span class="line">    token: <span class="string">"********"</span>,  <span class="comment">// GitHub Token</span></span><br><span class="line">    repo: <span class="string">"sungaomeng.github.io"</span>,  <span class="comment">// 存放 issues的git仓库</span></span><br><span class="line">    <span class="comment">// sitemap.xml的路径，commit.js放置在根目录下，无需修改，其他情况自行处理</span></span><br><span class="line">    sitemapUrl: path.resolve(__dirname, <span class="string">"./public/sitemap.xml"</span>),</span><br><span class="line">    kind: <span class="string">"Gitalk"</span>,  <span class="comment">// "Gitalk" or "Gitment"，</span></span><br><span class="line">    baseUrl: <span class="string">"https://opsolo.com/"</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">let</span> issuesUrl = <span class="string">`https://api.github.com/repos/<span class="subst">$&#123;config.username&#125;</span>/<span class="subst">$&#123;config.repo&#125;</span>/issues?access_token=<span class="subst">$&#123;config.token&#125;</span>`</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> requestGetOpt = &#123;</span><br><span class="line">    url: <span class="string">`<span class="subst">$&#123;issuesUrl&#125;</span>&amp;page=1&amp;per_page=1000`</span>,</span><br><span class="line">    json: <span class="literal">true</span>,</span><br><span class="line">    headers: &#123;</span><br><span class="line">        <span class="string">"User-Agent"</span>: <span class="string">"github-user"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">let</span> requestPostOpt = &#123;</span><br><span class="line">    ...requestGetOpt,</span><br><span class="line">    url:issuesUrl,</span><br><span class="line">    method: <span class="string">"POST"</span>,</span><br><span class="line">    form: <span class="string">""</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">"开始初始化评论..."</span>);</span><br><span class="line"></span><br><span class="line">(<span class="keyword">async</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"开始检索链接，请稍等..."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> websiteConfig = YAML.parse(fs.readFileSync(path.resolve(__dirname, <span class="string">"./_config.yml"</span>), <span class="string">"utf8"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> urls = sitemapXmlReader(config.sitemapUrl);</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`共检索到<span class="subst">$&#123;urls.length&#125;</span>个链接`</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">"开始获取已经初始化的issues:"</span>);</span><br><span class="line">        <span class="keyword">let</span> issues = <span class="keyword">await</span> send(requestGetOpt);</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`已经存在<span class="subst">$&#123;issues.length&#125;</span>个issues`</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> notInitIssueLinks = urls.filter(<span class="function">(<span class="params">link</span>) =&gt;</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> !issues.find(<span class="function">(<span class="params">item</span>) =&gt;</span> &#123;</span><br><span class="line">                link = removeProtocol(link);</span><br><span class="line">                <span class="keyword">return</span> item.body.includes(link);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">if</span> (notInitIssueLinks.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">`本次有<span class="subst">$&#123;notInitIssueLinks.length&#125;</span>个链接需要初始化issue：`</span>);</span><br><span class="line">            <span class="built_in">console</span>.log(notInitIssueLinks);</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">"开始提交初始化请求, 大约需要40秒..."</span>);</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * 部署好网站后，直接执行start，新增文章并不会生成评论</span></span><br><span class="line"><span class="comment">             * 经测试，最少需要等待40秒，才可以正确生成， 怀疑跟github的api有关系，没有找到实锤</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            setTimeout(<span class="keyword">async</span> ()=&gt;&#123;</span><br><span class="line">                <span class="keyword">let</span> initRet = <span class="keyword">await</span> notInitIssueLinks.map(<span class="keyword">async</span> (item) =&gt; &#123;</span><br><span class="line">                    <span class="keyword">let</span> html = <span class="keyword">await</span> send(&#123; ...requestGetOpt, <span class="attr">url</span>: item &#125;);</span><br><span class="line">                    <span class="keyword">let</span> title = cheerio.load(html)(<span class="string">"title"</span>).text();</span><br><span class="line">                    <span class="keyword">let</span> pathLabel = url.parse(item).path;</span><br><span class="line">                    pathLabel = md5(config.baseUrl + pathLabel);<span class="comment">//中文过长所以要md5</span></span><br><span class="line">                    <span class="keyword">let</span> body = <span class="string">`<span class="subst">$&#123;item&#125;</span>&lt;br&gt;&lt;br&gt;<span class="subst">$&#123;websiteConfig.description&#125;</span>`</span>;</span><br><span class="line">                    <span class="keyword">let</span> form = <span class="built_in">JSON</span>.stringify(&#123; body, <span class="attr">labels</span>: [config.kind, pathLabel], title &#125;);</span><br><span class="line">                    <span class="keyword">return</span> send(&#123; ...requestPostOpt, form &#125;);</span><br><span class="line">                &#125;);</span><br><span class="line">                <span class="built_in">console</span>.log(<span class="string">`已完成<span class="subst">$&#123;initRet.length&#125;</span>个！`</span>);</span><br><span class="line">                <span class="built_in">console</span>.log(<span class="string">"可以愉快的发表评论了！"</span>);</span><br><span class="line">            &#125;,<span class="number">40000</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">"本次发布无新增页面，无需初始化issue!!"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`初始化issue出错，错误如下：`</span>);</span><br><span class="line">        <span class="built_in">console</span>.log(e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;)();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">sitemapXmlReader</span>(<span class="params">file</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> data = fs.readFileSync(file, <span class="string">"utf8"</span>);</span><br><span class="line">    <span class="keyword">let</span> sitemap = xmlParser(data);</span><br><span class="line">    <span class="keyword">return</span> sitemap.root.children.map(<span class="function"><span class="keyword">function</span> (<span class="params">url</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">let</span> loc = url.children.filter(<span class="function"><span class="keyword">function</span> (<span class="params">item</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> item.name === <span class="string">"loc"</span>;</span><br><span class="line">        &#125;)[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">return</span> loc.content;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">removeProtocol</span>(<span class="params">url</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> url.substr(url.indexOf(<span class="string">":"</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">send</span>(<span class="params">options</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function"><span class="keyword">function</span> (<span class="params">resolve, reject</span>) </span>&#123;</span><br><span class="line">        request(options, <span class="function"><span class="keyword">function</span> (<span class="params">error, response, body</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (!error) &#123;</span><br><span class="line">                resolve(body);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                reject(error);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-执行脚本"><a href="#3-执行脚本" class="headerlink" title="3. 执行脚本"></a>3. 执行脚本</h4><blockquote><p>需要注意的是第一步中的sitemap插件会生成的sitemap.xml会包含<strong>全部的界面</strong>，包括标签页、关于页等，执行上面的代码也会对这些页面生成评论框(也就是issue)</p></blockquote><p>完成上述操作后，执行下面的命令，就可以部署站点，并初始化所有的评论了。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br><span class="line">node ./comment.js</span><br></pre></td></tr></table></figure><p>也可以通过在站点根目录的package.json文件中，新建npm脚本，一个命令搞定清除缓存、生成静态文件、提交git并生成issue的所有操作。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;scripts&quot;: &#123;</span><br><span class="line">    &quot;start&quot;: &quot;hexo clean &amp;&amp; hexo s&quot;,</span><br><span class="line">    &quot;deploy&quot;: &quot;hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy &amp;&amp; node .&#x2F;comment.js&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成文章编写，或者其他的更新操作后，直接执行deploy即可。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm run deploy</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight verilog"><table><tr><td class="code"><pre><span class="line"><span class="number">192</span>:blog See$ ./comment<span class="variable">.js</span></span><br><span class="line">开始初始化评论...</span><br><span class="line">开始检索链接，请稍等...</span><br><span class="line">共检索到<span class="number">15</span>个链接</span><br><span class="line">开始获取已经初始化的issues:</span><br><span class="line">已经存在<span class="number">3</span>个issues</span><br><span class="line">本次有<span class="number">12</span>个链接需要初始化issue：</span><br><span class="line">[</span><br><span class="line">  'https:<span class="comment">//opsolo.com/link/index.html',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/categories/index.html',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/tags/index.html',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/python/check-lb-auto-repair/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/zabbix/zabbix-alarm-convergence-compression/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/prometheus/install-prometheus-operator/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/shell/quickly-delete-lot-files/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/efk/filebeat/limit-cpu/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/efk/filebeat/reload-log/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/hexo/hexo-valine/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/hexo/hexo-github-custom-domin/',</span></span><br><span class="line">  'https:<span class="comment">//opsolo.com/hello-world/'</span></span><br><span class="line">]</span><br><span class="line">开始提交初始化请求, 大约需要<span class="number">40</span>秒...</span><br><span class="line">已完成<span class="number">12</span>个！</span><br><span class="line">可以愉快的发表评论了！</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nodejs </tag>
            
            <tag> hexo </tag>
            
            <tag> gitalk </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo开启Valine评论</title>
      <link href="/hexo/hexo-valine/"/>
      <url>/hexo/hexo-valine/</url>
      
        <content type="html"><![CDATA[<h2 id="注册Leancloud"><a href="#注册Leancloud" class="headerlink" title="注册Leancloud"></a>注册Leancloud</h2><h3 id="添加Class"><a href="#添加Class" class="headerlink" title="添加Class"></a>添加Class</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">···</span><br></pre></td></tr></table></figure><h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><h3 id="界面无法显示评论框并向你抛了一个异常"><a href="#界面无法显示评论框并向你抛了一个异常" class="headerlink" title="界面无法显示评论框并向你抛了一个异常"></a>界面无法显示评论框并向你抛了一个异常</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; TypeError: Cannot read property &#39;hide&#39; of undefined</span><br><span class="line">&gt;     at r.ErrorHandler (Valine.min.js:12)</span><br><span class="line">&gt;     at r.init (Valine.min.js:12)</span><br><span class="line">&gt;     at new r (Valine.min.js:12)</span><br><span class="line">&gt;     at new i (Valine.min.js:12)</span><br><span class="line">&gt;     at (index):1891</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure><p> 需要修改themes/next/_config.yml<br> 将valine.language修改为zh-cn<br> 完整配置如下:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">valine:</span><br><span class="line">  enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version.</span><br><span class="line">  appid:  ***</span><br><span class="line">  appkey:  ***</span><br><span class="line">  notify: false # mail notifier, See: https:&#x2F;&#x2F;github.com&#x2F;xCss&#x2F;Valine&#x2F;wiki</span><br><span class="line">  verify: false # Verification code</span><br><span class="line">  placeholder: Just go go # comment box placeholder</span><br><span class="line">  avatar: mm # gravatar style</span><br><span class="line">  guest_info: nick,mail,link # custom comment header</span><br><span class="line">  pageSize: 10 # pagination size</span><br><span class="line">  language: zh-cn # language, available values: en, zh-cn</span><br><span class="line">  visitor: false</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo Github 自定义域名</title>
      <link href="/hexo/hexo-github-custom-domin/"/>
      <url>/hexo/hexo-github-custom-domin/</url>
      
        <content type="html"><![CDATA[<h2 id="修改Github-Settings"><a href="#修改Github-Settings" class="headerlink" title="修改Github Settings"></a>修改Github Settings</h2><p>Settungs -&gt; GitHub Pages -&gt; Custom domain</p><p>输入自定义域名后点击 “Save”</p><h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><h3 id="hexo-deploy后站点404"><a href="#hexo-deploy后站点404" class="headerlink" title="hexo deploy后站点404"></a>hexo deploy后站点404</h3><p> 虽然在Github里设置了自定义域名,但每次hexo deploy后站点就404了<br> 再次去github settings里查看域名配置发现被还原了</p><h4 id="将域名保存到-public-CNAME中"><a href="#将域名保存到-public-CNAME中" class="headerlink" title="将域名保存到./public/CNAME中"></a>将域名保存到./public/CNAME中</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat .&#x2F;public&#x2F;CNAME</span><br><span class="line">blog.opsolo.com</span><br></pre></td></tr></table></figure><p>保存后再次hexo deploy 就不会被还原了</p>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hello-world</title>
      <link href="/hello-world/"/>
      <url>/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-serversadf"><a href="#Run-serversadf" class="headerlink" title="Run serversadf"></a>Run serversadf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> hello-world </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hello-world </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
